# -*- coding: utf-8 -*-
"""
four_choice_lba.py - å››é¸ä¸€LBAç«¶çˆ­å™¨
Sequential Processing LBA - Four-Choice LBA Integration Module

åŠŸèƒ½ï¼š
- å¯¦ç¾å››é¸ä¸€LBAç«¶çˆ­æ©Ÿåˆ¶
- æ•´åˆå·¦å³é€šé“è­‰æ“šè¼¸å‡º
- è¨ˆç®—æœ€çµ‚æ±ºç­–çš„ä¼¼ç„¶å‡½æ•¸
- æ”¯æ´PyTensorå’ŒPyMC
"""

import numpy as np
import pytensor.tensor as pt
from typing import Dict, List, Optional, Tuple

class FourChoiceLBA:
    """å››é¸ä¸€LBAç«¶çˆ­å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å››é¸ä¸€LBAç«¶çˆ­å™¨"""
        
        # å››å€‹é¸é …çš„å°æ‡‰é—œä¿‚
        self.choice_descriptions = {
            0: 'Left\\Right|',   # å·¦å°è§’å³å‚ç›´
            1: 'Left\\Right/',   # å·¦å°è§’å³å°è§’  
            2: 'Left|Right|',    # å·¦å‚ç›´å³å‚ç›´
            3: 'Left|Right/'     # å·¦å‚ç›´å³å°è§’
        }
        
        # æ•´åˆå±¤åƒæ•¸åç¨±
        self.param_names = [
            'integration_drift_0',      # é¸é …0çš„åŸºç¤æ¼‚ç§»ç‡
            'integration_drift_1',      # é¸é …1çš„åŸºç¤æ¼‚ç§»ç‡  
            'integration_drift_2',      # é¸é …2çš„åŸºç¤æ¼‚ç§»ç‡
            'integration_drift_3',      # é¸é …3çš„åŸºç¤æ¼‚ç§»ç‡
            'integration_threshold',    # æ•´åˆå±¤æ±ºç­–é–¾å€¼
            'integration_start_var',    # æ•´åˆå±¤èµ·å§‹é»è®Šç•°
            'integration_ndt',          # æ•´åˆå±¤éæ±ºç­–æ™‚é–“
            'integration_noise'         # æ•´åˆå±¤æ“´æ•£å™ªéŸ³
        ]
        
        print("âœ… åˆå§‹åŒ–å››é¸ä¸€LBAç«¶çˆ­å™¨")
        print(f"   åƒæ•¸æ•¸é‡: {len(self.param_names)}")
        print("   é¸é …å°æ‡‰:")
        for choice, desc in self.choice_descriptions.items():
            print(f"     é¸é … {choice}: {desc}")
    
    def compute_likelihood(self, choices, evidence_inputs, rt_remaining, params):
        """
        è¨ˆç®—å››é¸ä¸€LBAç«¶çˆ­çš„ä¼¼ç„¶å‡½æ•¸
        
        Args:
            choices: æœ€çµ‚é¸æ“‡é™£åˆ— (0, 1, 2, 3)
            evidence_inputs: ä¾†è‡ªé›™é€šé“çš„è­‰æ“šè¼¸å…¥å­—å…¸
            rt_remaining: å‰©é¤˜åæ‡‰æ™‚é–“ï¼ˆç”¨æ–¼æ•´åˆå±¤ï¼‰
            params: æ•´åˆå±¤åƒæ•¸å­—å…¸
            
        Returns:
            log_likelihood: å°æ•¸ä¼¼ç„¶å€¼
        """
        
        # è§£åŒ…åŸºç¤åƒæ•¸
        drift_0 = params['integration_drift_0']
        drift_1 = params['integration_drift_1'] 
        drift_2 = params['integration_drift_2']
        drift_3 = params['integration_drift_3']
        threshold = params['integration_threshold']
        start_var = params['integration_start_var']
        ndt = params['integration_ndt']
        noise = params['integration_noise']
        
        # æ‡‰ç”¨åƒæ•¸é‚Šç•Œç´„æŸ
        drifts = [
            pt.maximum(drift_0, 0.1),
            pt.maximum(drift_1, 0.1),
            pt.maximum(drift_2, 0.1), 
            pt.maximum(drift_3, 0.1)
        ]
        threshold = pt.maximum(threshold, 0.1)
        start_var = pt.maximum(start_var, 0.05)
        ndt = pt.maximum(ndt, 0.05)
        noise = pt.maximum(noise, 0.1)
        
        # è¨ˆç®—æ•´åˆå±¤çš„æ±ºç­–æ™‚é–“
        decision_time = pt.maximum(rt_remaining - ndt, 0.01)
        
        # æ ¹æ“šè­‰æ“šè¼¸å…¥èª¿æ•´æ¼‚ç§»ç‡
        adjusted_drifts = self._adjust_drifts_with_evidence(drifts, evidence_inputs)
        
        # è¨ˆç®—å››é¸ä¸€LBAç«¶çˆ­ä¼¼ç„¶
        log_likelihood = self._compute_4choice_lba_density(
            choices, decision_time, adjusted_drifts, threshold, start_var, noise
        )
        
        return log_likelihood
    
    def _adjust_drifts_with_evidence(self, base_drifts, evidence_inputs):
        """
        æ ¹æ“šé›™é€šé“è­‰æ“šèª¿æ•´å„é¸é …çš„æ¼‚ç§»ç‡
        
        Args:
            base_drifts: åŸºç¤æ¼‚ç§»ç‡åˆ—è¡¨ [drift_0, drift_1, drift_2, drift_3]
            evidence_inputs: è­‰æ“šè¼¸å…¥å­—å…¸
            
        Returns:
            adjusted_drifts: èª¿æ•´å¾Œçš„æ¼‚ç§»ç‡åˆ—è¡¨
        """
        
        adjusted_drifts = []
        
        for i, base_drift in enumerate(base_drifts):
            # ç²å¾—å°æ‡‰é¸é …çš„è­‰æ“šåŠ æˆ
            evidence_boost = evidence_inputs.get(f'choice_{i}', 0.0)
            
            # çµ„åˆåŸºç¤æ¼‚ç§»ç‡å’Œè­‰æ“šåŠ æˆ
            # ä½¿ç”¨ä¹˜æ³•çµ„åˆä»¥ä¿æŒæ­£å€¼
            adjusted_drift = base_drift * (1.0 + evidence_boost * 0.5)
            
            # ç¢ºä¿æœ€å°å€¼
            adjusted_drift = pt.maximum(adjusted_drift, 0.1)
            
            adjusted_drifts.append(adjusted_drift)
        
        return adjusted_drifts
    
    def _compute_4choice_lba_density(self, choices, decision_time, drifts, 
                                   threshold, start_var, noise):
        """
        è¨ˆç®—å››é¸ä¸€LBAå¯†åº¦å‡½æ•¸ - å®Œå…¨å‘é‡åŒ–ç‰ˆæœ¬
        
        é¿å…Pythonå¾ªç’°ï¼Œä½¿ç”¨å®Œå…¨å‘é‡åŒ–çš„PyTensoræ“ä½œ
        """
        
        # é å…ˆè¨ˆç®—æ‰€æœ‰é¸é …çš„å¯†åº¦å’Œå­˜æ´»å‡½æ•¸ï¼ˆå‘é‡åŒ–ï¼‰
        densities_0 = self._compute_lba_density(decision_time, drifts[0], threshold, start_var, noise)
        densities_1 = self._compute_lba_density(decision_time, drifts[1], threshold, start_var, noise)
        densities_2 = self._compute_lba_density(decision_time, drifts[2], threshold, start_var, noise)
        densities_3 = self._compute_lba_density(decision_time, drifts[3], threshold, start_var, noise)
        
        survivals_0 = self._compute_lba_survival(decision_time, drifts[0], threshold, start_var, noise)
        survivals_1 = self._compute_lba_survival(decision_time, drifts[1], threshold, start_var, noise)
        survivals_2 = self._compute_lba_survival(decision_time, drifts[2], threshold, start_var, noise)
        survivals_3 = self._compute_lba_survival(decision_time, drifts[3], threshold, start_var, noise)
        
        # è¨ˆç®—æ¯å€‹é¸é …çš„å®Œæ•´ä¼¼ç„¶ï¼ˆwinner density Ã— all loser survivalsï¼‰
        likelihood_0 = densities_0 * survivals_1 * survivals_2 * survivals_3
        likelihood_1 = densities_1 * survivals_0 * survivals_2 * survivals_3
        likelihood_2 = densities_2 * survivals_0 * survivals_1 * survivals_3
        likelihood_3 = densities_3 * survivals_0 * survivals_1 * survivals_2
        
        # æ ¹æ“šå¯¦éš›é¸æ“‡é¸å–å°æ‡‰çš„ä¼¼ç„¶ï¼ˆå‘é‡åŒ–æ–¹å¼ï¼‰
        trial_likelihoods = (
            pt.eq(choices, 0) * likelihood_0 +
            pt.eq(choices, 1) * likelihood_1 +
            pt.eq(choices, 2) * likelihood_2 +
            pt.eq(choices, 3) * likelihood_3
        )
        
        # ç¢ºä¿æ­£å€¼ä¸¦å–å°æ•¸
        trial_likelihoods = pt.maximum(trial_likelihoods, 1e-12)
        log_likelihoods = pt.log(trial_likelihoods)
        
        # è¿”å›ç¸½å°æ•¸ä¼¼ç„¶
        return pt.sum(log_likelihoods)
    
    def _compute_lba_density(self, t, drift, threshold, start_var, noise):
        """
        è¨ˆç®—å–®ä¸€ç´¯ç©å™¨çš„LBAå¯†åº¦å‡½æ•¸ - æ”¯æ´å‘é‡åŒ–è¼¸å…¥
        
        Args:
            t: æ±ºç­–æ™‚é–“ï¼ˆå¯ä»¥æ˜¯å‘é‡ï¼‰
            drift: æ¼‚ç§»ç‡
            threshold: é–¾å€¼
            start_var: èµ·å§‹é»è®Šç•°
            noise: å™ªéŸ³åƒæ•¸
            
        Returns:
            density: å¯†åº¦å€¼ï¼ˆèˆ‡tç›¸åŒå½¢ç‹€ï¼‰
        """
        
        from pytensor.tensor import erf
        
        sqrt_t = pt.sqrt(t)
        
        # è¨ˆç®—z-scoresï¼ˆå‘é‡åŒ–ï¼‰
        z1 = pt.clip((drift * t - threshold) / (noise * sqrt_t), -4.5, 4.5)
        z2 = pt.clip((drift * t - start_var) / (noise * sqrt_t), -4.5, 4.5)
        
        # PyTensorå…¼å®¹çš„æ­£æ…‹å‡½æ•¸
        def safe_normal_cdf(x):
            return 0.5 * (1 + erf(x / pt.sqrt(2)))
        
        def safe_normal_pdf(x):
            return pt.exp(-0.5 * x**2) / pt.sqrt(2 * pt.pi)
        
        # CDFé …å’ŒPDFé …ï¼ˆå‘é‡åŒ–ï¼‰
        cdf_term = safe_normal_cdf(z1) - safe_normal_cdf(z2)
        pdf_term = (safe_normal_pdf(z1) - safe_normal_pdf(z2)) / (noise * sqrt_t)
        
        # ç¢ºä¿CDFé …ç‚ºæ­£
        cdf_term = pt.maximum(cdf_term, 1e-10)
        
        # å®Œæ•´å¯†åº¦è¨ˆç®—ï¼ˆå‘é‡åŒ–ï¼‰
        density = pt.maximum(
            (drift / start_var) * cdf_term + pdf_term / start_var,
            1e-10
        )
        
        return density
    
    def _compute_lba_survival(self, t, drift, threshold, start_var, noise):
        """
        è¨ˆç®—å–®ä¸€ç´¯ç©å™¨çš„LBAå­˜æ´»å‡½æ•¸ - æ”¯æ´å‘é‡åŒ–è¼¸å…¥
        
        Args:
            t: æ±ºç­–æ™‚é–“ï¼ˆå¯ä»¥æ˜¯å‘é‡ï¼‰
            drift: æ¼‚ç§»ç‡
            threshold: é–¾å€¼
            start_var: èµ·å§‹é»è®Šç•°
            noise: å™ªéŸ³åƒæ•¸
            
        Returns:
            survival: å­˜æ´»æ©Ÿç‡ï¼ˆèˆ‡tç›¸åŒå½¢ç‹€ï¼‰
        """
        
        from pytensor.tensor import erf
        
        sqrt_t = pt.sqrt(t)
        
        # è¨ˆç®—z-scoreï¼ˆå‘é‡åŒ–ï¼‰
        z1 = pt.clip((drift * t - threshold) / (noise * sqrt_t), -4.5, 4.5)
        
        # æ­£æ…‹CDF
        def safe_normal_cdf(x):
            return 0.5 * (1 + erf(x / pt.sqrt(2)))
        
        # å­˜æ´»æ©Ÿç‡ = 1 - CDFï¼ˆå‘é‡åŒ–ï¼‰
        survival = pt.maximum(1 - safe_normal_cdf(z1), 1e-10)
        
        return survival
    
    def combine_channel_evidence(self, left_evidence, right_evidence, 
                               first_side='left'):
        """
        çµ„åˆé›™é€šé“è­‰æ“šå½¢æˆå››å€‹é¸é …çš„è­‰æ“šè¼¸å…¥
        
        Args:
            left_evidence: å·¦é€šé“è­‰æ“šå­—å…¸
            right_evidence: å³é€šé“è­‰æ“šå­—å…¸
            first_side: é¦–å…ˆè™•ç†çš„é€šé“ ('left' æˆ– 'right')
            
        Returns:
            evidence_inputs: å››å€‹é¸é …çš„è­‰æ“šå­—å…¸
        """
        
        # æå–è­‰æ“šå€¼
        left_vertical = left_evidence.get('evidence_vertical', 0.0)
        left_diagonal = left_evidence.get('evidence_diagonal', 0.0)
        right_vertical = right_evidence.get('evidence_vertical', 0.0)
        right_diagonal = right_evidence.get('evidence_diagonal', 0.0)
        
        # è€ƒæ…®è™•ç†é †åºçš„å½±éŸ¿
        if first_side == 'left':
            # å·¦é‚Šå…ˆè™•ç†ï¼Œå¯èƒ½æœ‰æ›´é«˜çš„æ¬Šé‡
            left_weight = 1.1
            right_weight = 1.0
        else:
            # å³é‚Šå…ˆè™•ç†
            left_weight = 1.0
            right_weight = 1.1
        
        # çµ„åˆè­‰æ“šå½¢æˆå››å€‹é¸é …
        evidence_inputs = {
            'choice_0': left_diagonal * left_weight + right_vertical * right_weight,    # \|
            'choice_1': left_diagonal * left_weight + right_diagonal * right_weight,   # \/  
            'choice_2': left_vertical * left_weight + right_vertical * right_weight,   # ||
            'choice_3': left_vertical * left_weight + right_diagonal * right_weight    # |/
        }
        
        # æ­£è¦åŒ–ä»¥é˜²æ­¢éå¤§çš„è­‰æ“šå€¼
        max_evidence = max(evidence_inputs.values())
        if max_evidence > 0:
            scale_factor = min(2.0 / max_evidence, 1.0)  # é™åˆ¶æœ€å¤§è­‰æ“šç‚º2.0
            for key in evidence_inputs:
                evidence_inputs[key] *= scale_factor
        
        return evidence_inputs
    
    def compute_choice_probabilities(self, evidence_inputs, params, rt_mean=None):
        """
        è¨ˆç®—å››é¸ä¸€çš„é¸æ“‡æ©Ÿç‡ï¼ˆç”¨æ–¼æ¨¡å‹é æ¸¬ï¼‰
        
        Args:
            evidence_inputs: è­‰æ“šè¼¸å…¥å­—å…¸
            params: æ•´åˆå±¤åƒæ•¸å­—å…¸
            rt_mean: å¹³å‡åæ‡‰æ™‚é–“
            
        Returns:
            choice_probs: å››å€‹é¸é …çš„é¸æ“‡æ©Ÿç‡
        """
        
        if rt_mean is None:
            rt_mean = 0.8
        
        # è§£åŒ…åƒæ•¸
        base_drifts = [
            float(params['integration_drift_0']),
            float(params['integration_drift_1']),
            float(params['integration_drift_2']),
            float(params['integration_drift_3'])
        ]
        threshold = float(params['integration_threshold'])
        ndt = float(params['integration_ndt'])
        
        # è¨ˆç®—æ±ºç­–æ™‚é–“
        decision_time = max(rt_mean - ndt, 0.1)
        
        # èª¿æ•´æ¼‚ç§»ç‡
        adjusted_drifts = []
        for i, base_drift in enumerate(base_drifts):
            evidence_boost = evidence_inputs.get(f'choice_{i}', 0.0)
            adjusted_drift = base_drift * (1.0 + evidence_boost * 0.5)
            adjusted_drifts.append(max(adjusted_drift, 0.1))
        
        # è¨ˆç®—ç›¸å°å¼·åº¦ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        relative_strengths = []
        for drift in adjusted_drifts:
            # ä½¿ç”¨ç°¡åŒ–çš„æŒ‡æ•¸å‡½æ•¸è¨ˆç®—ç›¸å°å¼·åº¦
            strength = np.exp(drift * decision_time / threshold)
            relative_strengths.append(strength)
        
        # æ­£è¦åŒ–ç‚ºæ©Ÿç‡
        total_strength = sum(relative_strengths)
        choice_probs = [s / total_strength for s in relative_strengths]
        
        return np.array(choice_probs)
    
    def validate_parameters(self, params):
        """
        é©—è­‰æ•´åˆå±¤åƒæ•¸çš„åˆç†æ€§
        
        Args:
            params: åƒæ•¸å­—å…¸
            
        Returns:
            bool: åƒæ•¸æ˜¯å¦åˆç†
            str: é©—è­‰è¨Šæ¯
        """
        
        try:
            # æª¢æŸ¥æ‰€æœ‰å¿…è¦åƒæ•¸æ˜¯å¦å­˜åœ¨
            for param_name in self.param_names:
                if param_name not in params:
                    return False, f"ç¼ºå°‘åƒæ•¸: {param_name}"
            
            # æª¢æŸ¥åƒæ•¸å€¼ç¯„åœ
            for i in range(4):
                drift = float(params[f'integration_drift_{i}'])
                if drift <= 0:
                    return False, f"integration_drift_{i}å¿…é ˆ > 0ï¼Œå¾—åˆ°: {drift}"
            
            threshold = float(params['integration_threshold'])
            if threshold <= 0:
                return False, f"integration_thresholdå¿…é ˆ > 0ï¼Œå¾—åˆ°: {threshold}"
            
            start_var = float(params['integration_start_var'])
            if start_var <= 0 or start_var >= threshold:
                return False, f"integration_start_varå¿…é ˆåœ¨ (0, threshold) ç¯„åœå…§ï¼Œå¾—åˆ°: {start_var}"
            
            ndt = float(params['integration_ndt'])
            if ndt < 0 or ndt > 0.8:
                return False, f"integration_ndtå¿…é ˆåœ¨ [0, 0.8] ç¯„åœå…§ï¼Œå¾—åˆ°: {ndt}"
            
            noise = float(params['integration_noise'])
            if noise <= 0:
                return False, f"integration_noiseå¿…é ˆ > 0ï¼Œå¾—åˆ°: {noise}"
            
            return True, "æ•´åˆå±¤åƒæ•¸é©—è­‰é€šé"
            
        except (ValueError, KeyError) as e:
            return False, f"åƒæ•¸é©—è­‰éŒ¯èª¤: {e}"
    
    def get_default_priors(self):
        """
        ç²å¾—æ•´åˆå±¤åƒæ•¸çš„é è¨­å…ˆé©—åˆ†å¸ƒè¨­å®š
        
        Returns:
            dict: å…ˆé©—åˆ†å¸ƒè¨­å®š
        """
        
        priors = {}
        
        # å››å€‹é¸é …çš„åŸºç¤æ¼‚ç§»ç‡
        for i in range(4):
            priors[f'integration_drift_{i}'] = {
                'distribution': 'Gamma',
                'alpha': 2.0,
                'beta': 2.0,
                'description': f'é¸é …{i}çš„åŸºç¤æ¼‚ç§»ç‡'
            }
        
        # æ•´åˆå±¤å…¶ä»–åƒæ•¸
        priors.update({
            'integration_threshold': {
                'distribution': 'Gamma',
                'alpha': 2.5,
                'beta': 3.0,
                'description': 'æ•´åˆå±¤æ±ºç­–é–¾å€¼'
            },
            'integration_start_var': {
                'distribution': 'Uniform',
                'lower': 0.1,
                'upper': 0.5,
                'description': 'æ•´åˆå±¤èµ·å§‹é»è®Šç•°'
            },
            'integration_ndt': {
                'distribution': 'Uniform',
                'lower': 0.05,
                'upper': 0.3,
                'description': 'æ•´åˆå±¤éæ±ºç­–æ™‚é–“'
            },
            'integration_noise': {
                'distribution': 'Gamma',
                'alpha': 2.0,
                'beta': 6.0,
                'description': 'æ•´åˆå±¤æ“´æ•£å™ªéŸ³'
            }
        })
        
        return priors

# ä¾¿åˆ©å‡½æ•¸
def create_four_choice_lba():
    """å‰µå»ºå››é¸ä¸€LBAç«¶çˆ­å™¨"""
    return FourChoiceLBA()

def test_four_choice_lba():
    """æ¸¬è©¦å››é¸ä¸€LBAåŠŸèƒ½"""
    
    print("ğŸ§ª æ¸¬è©¦å››é¸ä¸€LBAç«¶çˆ­å™¨...")
    
    try:
        # å‰µå»ºæ¸¬è©¦è³‡æ–™
        n_trials = 50
        np.random.seed(42)
        
        choices = np.random.choice([0, 1, 2, 3], size=n_trials)
        rt_remaining = np.random.uniform(0.2, 0.8, size=n_trials)
        
        # å‰µå»ºå››é¸ä¸€LBA
        four_choice_lba = FourChoiceLBA()
        
        # æ¸¬è©¦åƒæ•¸
        test_params = {
            'integration_drift_0': 1.2,
            'integration_drift_1': 1.1,
            'integration_drift_2': 1.0,
            'integration_drift_3': 1.3,
            'integration_threshold': 0.8,
            'integration_start_var': 0.2,
            'integration_ndt': 0.15,
            'integration_noise': 0.25
        }
        
        # æ¸¬è©¦åƒæ•¸é©—è­‰
        valid, message = four_choice_lba.validate_parameters(test_params)
        print(f"   åƒæ•¸é©—è­‰: {message}")
        
        if not valid:
            print("âŒ åƒæ•¸é©—è­‰å¤±æ•—")
            return False
        
        # æ¸¬è©¦è­‰æ“šçµ„åˆ
        left_evidence = {'evidence_vertical': 0.8, 'evidence_diagonal': 1.2}
        right_evidence = {'evidence_vertical': 1.0, 'evidence_diagonal': 0.9}
        
        evidence_inputs = four_choice_lba.combine_channel_evidence(
            left_evidence, right_evidence, 'left'
        )
        print(f"   è­‰æ“šçµ„åˆ: {len(evidence_inputs)} å€‹é¸é …")
        
        # æ¸¬è©¦é¸æ“‡æ©Ÿç‡è¨ˆç®—
        choice_probs = four_choice_lba.compute_choice_probabilities(
            evidence_inputs, test_params
        )
        print(f"   é¸æ“‡æ©Ÿç‡: {choice_probs}")
        print(f"   æ©Ÿç‡ç¸½å’Œ: {np.sum(choice_probs):.3f}")
        
        # æ¸¬è©¦å…ˆé©—è¨­å®š
        priors = four_choice_lba.get_default_priors()
        print(f"   å…ˆé©—åˆ†å¸ƒæ•¸é‡: {len(priors)}")
        
        print("âœ… å››é¸ä¸€LBAæ¸¬è©¦æˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"âŒ å››é¸ä¸€LBAæ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # å¦‚æœç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆï¼Œé€²è¡Œæ¸¬è©¦
    test_four_choice_lba()
