# -*- coding: utf-8 -*-
"""
compare_predictions_analysis.py - æ¯”è¼ƒPyMCé æ¸¬èˆ‡å¯¦éš›è³‡æ–™
Compare PyMC ParallelAND predictions with actual data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def analyze_prediction_accuracy():
    """åˆ†æPyMCé æ¸¬æº–ç¢ºåº¦"""
    
    print("ğŸ“Š åˆ†æPyMC ParallelANDé æ¸¬çµæœ...")
    
    # è®€å–é æ¸¬çµæœ
    predictions_df = pd.read_csv("pymc_parallel_and_predictions_p31.csv")
    fit_metrics_df = pd.read_csv("pymc_parallel_and_fit_metrics_p31.csv")
    posterior_df = pd.read_csv("pymc_parallel_and_posterior_means_p31.csv")
    
    print(f"   ç¸½è©¦é©—æ•¸: {len(predictions_df)}")
    print(f"   RTç›¸é—œä¿‚æ•¸: {fit_metrics_df['rt_correlation'].iloc[0]:.4f}")
    print(f"   RT RMSE: {fit_metrics_df['rt_rmse'].iloc[0]:.4f}")
    print(f"   å¹³å‡å¯¦éš›RT: {fit_metrics_df['mean_actual_rt'].iloc[0]:.4f}")
    print(f"   å¹³å‡é æ¸¬RT: {fit_metrics_df['mean_predicted_rt'].iloc[0]:.4f}")
    
    # è©³ç´°åˆ†æ
    actual_rts = predictions_df['actual_rt'].values
    predicted_rts = predictions_df['predicted_rt'].values
    
    # çµ±è¨ˆæª¢é©—
    t_stat, t_pval = stats.ttest_rel(actual_rts, predicted_rts)
    correlation, corr_pval = stats.pearsonr(actual_rts, predicted_rts)
    
    print(f"\nğŸ“ˆ çµ±è¨ˆåˆ†æ:")
    print(f"   é…å°tæª¢é©—: t={t_stat:.4f}, p={t_pval:.4f}")
    print(f"   çš®çˆ¾æ£®ç›¸é—œ: r={correlation:.4f}, p={corr_pval:.4f}")
    
    # åˆ†ææ•ˆæœdrift rates
    print(f"\nğŸ§  ä¼°è¨ˆçš„drift rates:")
    for param in ['left_v_vertical', 'left_v_nonvertical', 'right_v_vertical', 'right_v_nonvertical']:
        value = posterior_df[param].iloc[0]
        print(f"   {param}: {value:.4f}")
    
    # åˆ†æParallelANDæ•ˆæœ
    effective_drifts = predictions_df['effective_drift'].values
    left_drifts = predictions_df['left_drift'].values  
    right_drifts = predictions_df['right_drift'].values
    
    print(f"\nâš¡ ParallelANDåˆ†æ:")
    print(f"   å¹³å‡æœ‰æ•ˆdrift rate: {np.mean(effective_drifts):.4f}")
    print(f"   å¹³å‡å·¦å´drift rate: {np.mean(left_drifts):.4f}")
    print(f"   å¹³å‡å³å´drift rate: {np.mean(right_drifts):.4f}")
    
    # æª¢æŸ¥æœ€å°å€¼è¦å‰‡
    min_matches = np.sum(effective_drifts == np.minimum(left_drifts, right_drifts))
    print(f"   æ­£ç¢ºæ‡‰ç”¨æœ€å°å€¼è¦å‰‡: {min_matches}/{len(effective_drifts)} ({min_matches/len(effective_drifts)*100:.1f}%)")
    
    return {
        'predictions_df': predictions_df,
        'fit_metrics': fit_metrics_df.iloc[0].to_dict(),
        'posterior_means': posterior_df.iloc[0].to_dict(),
        'statistical_tests': {
            't_statistic': t_stat,
            't_pvalue': t_pval,
            'correlation': correlation,
            'correlation_pvalue': corr_pval
        }
    }

def plot_detailed_comparison():
    """è©³ç´°æ¯”è¼ƒåœ–è¡¨"""
    
    predictions_df = pd.read_csv("pymc_parallel_and_predictions_p31.csv")
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    actual_rts = predictions_df['actual_rt']
    predicted_rts = predictions_df['predicted_rt']
    
    # RT scatter plot
    axes[0, 0].scatter(actual_rts, predicted_rts, alpha=0.6, s=20)
    axes[0, 0].plot([actual_rts.min(), actual_rts.max()], 
                   [actual_rts.min(), actual_rts.max()], 'r--', alpha=0.8)
    axes[0, 0].set_xlabel('å¯¦éš›RT')
    axes[0, 0].set_ylabel('é æ¸¬RT')
    axes[0, 0].set_title('RTé æ¸¬æº–ç¢ºåº¦')
    
    # RT residuals
    residuals = predicted_rts - actual_rts
    axes[0, 1].scatter(actual_rts, residuals, alpha=0.6, s=20)
    axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.8)
    axes[0, 1].set_xlabel('å¯¦éš›RT')
    axes[0, 1].set_ylabel('æ®˜å·® (é æ¸¬-å¯¦éš›)')
    axes[0, 1].set_title('é æ¸¬æ®˜å·®')
    
    # RT histograms
    axes[0, 2].hist(actual_rts, bins=30, alpha=0.7, label='å¯¦éš›RT', density=True)
    axes[0, 2].hist(predicted_rts, bins=30, alpha=0.7, label='é æ¸¬RT', density=True)
    axes[0, 2].set_xlabel('RT')
    axes[0, 2].set_ylabel('å¯†åº¦')
    axes[0, 2].set_title('RTåˆ†å¸ƒæ¯”è¼ƒ')
    axes[0, 2].legend()
    
    # Drift rate analysis
    left_drifts = predictions_df['left_drift']
    right_drifts = predictions_df['right_drift']
    effective_drifts = predictions_df['effective_drift']
    
    axes[1, 0].scatter(left_drifts, right_drifts, alpha=0.6, s=20)
    axes[1, 0].set_xlabel('å·¦å´drift rate')
    axes[1, 0].set_ylabel('å³å´drift rate')
    axes[1, 0].set_title('å·¦å³drift rateé—œä¿‚')
    
    # Effective drift distribution
    axes[1, 1].hist(effective_drifts, bins=20, alpha=0.7, color='green')
    axes[1, 1].set_xlabel('æœ‰æ•ˆdrift rate (æœ€å°å€¼)')
    axes[1, 1].set_ylabel('é »ç‡')
    axes[1, 1].set_title('æœ‰æ•ˆdrift rateåˆ†å¸ƒ')
    
    # Response pattern
    response_counts = predictions_df['response'].value_counts().sort_index()
    axes[1, 2].bar(response_counts.index, response_counts.values, alpha=0.7)
    axes[1, 2].set_xlabel('åæ‡‰é¡å‹')
    axes[1, 2].set_ylabel('é »ç‡')
    axes[1, 2].set_title('åæ‡‰æ¨¡å¼åˆ†å¸ƒ')
    
    plt.tight_layout()
    plt.savefig('pymc_detailed_comparison.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š è©³ç´°æ¯”è¼ƒåœ–å·²ä¿å­˜: pymc_detailed_comparison.png")
    
    return fig

def summarize_model_performance():
    """ç¸½çµæ¨¡å‹æ€§èƒ½"""
    
    predictions_df = pd.read_csv("pymc_parallel_and_predictions_p31.csv")
    fit_metrics_df = pd.read_csv("pymc_parallel_and_fit_metrics_p31.csv")
    
    print(f"\nğŸ“‹ PyMC ParallelANDæ¨¡å‹ç¸½çµ:")
    print(f"="*50)
    
    # åŸºæœ¬çµ±è¨ˆ
    actual_rts = predictions_df['actual_rt']
    predicted_rts = predictions_df['predicted_rt']
    
    print(f"è³‡æ–™é‡: {len(predictions_df)} å€‹trial")
    print(f"RTç›¸é—œä¿‚æ•¸: {fit_metrics_df['rt_correlation'].iloc[0]:.4f}")
    print(f"RT RMSE: {fit_metrics_df['rt_rmse'].iloc[0]:.4f} ç§’")
    print(f"å¹³å‡çµ•å°èª¤å·®: {np.mean(np.abs(predicted_rts - actual_rts)):.4f} ç§’")
    
    # RTç¯„åœæ¯”è¼ƒ
    print(f"\nRTç¯„åœæ¯”è¼ƒ:")
    print(f"å¯¦éš›RT: {actual_rts.min():.3f} - {actual_rts.max():.3f} ç§’")
    print(f"é æ¸¬RT: {predicted_rts.min():.3f} - {predicted_rts.max():.3f} ç§’")
    
    # ParallelANDè¦å‰‡é©—è­‰
    left_drifts = predictions_df['left_drift']
    right_drifts = predictions_df['right_drift']
    effective_drifts = predictions_df['effective_drift']
    
    min_rule_correct = np.sum(effective_drifts == np.minimum(left_drifts, right_drifts))
    print(f"\nParallelANDè¦å‰‡åŸ·è¡Œ:")
    print(f"æ­£ç¢ºæ‡‰ç”¨æœ€å°å€¼è¦å‰‡: {min_rule_correct}/{len(predictions_df)} ({min_rule_correct/len(predictions_df)*100:.1f}%)")
    
    # æŒ‰åæ‡‰é¡å‹åˆ†æ
    print(f"\næŒ‰åæ‡‰é¡å‹åˆ†æ:")
    for response in sorted(predictions_df['response'].unique()):
        subset = predictions_df[predictions_df['response'] == response]
        if len(subset) > 0:
            corr = np.corrcoef(subset['actual_rt'], subset['predicted_rt'])[0,1]
            rmse = np.sqrt(np.mean((subset['actual_rt'] - subset['predicted_rt'])**2))
            print(f"  åæ‡‰ {response}: n={len(subset)}, r={corr:.3f}, RMSE={rmse:.3f}")
    
    return {
        'summary_stats': {
            'n_trials': len(predictions_df),
            'rt_correlation': fit_metrics_df['rt_correlation'].iloc[0],
            'rt_rmse': fit_metrics_df['rt_rmse'].iloc[0],
            'mean_absolute_error': np.mean(np.abs(predicted_rts - actual_rts)),
            'parallel_and_rule_accuracy': min_rule_correct/len(predictions_df)
        }
    }

if __name__ == "__main__":
    # åŸ·è¡Œå®Œæ•´åˆ†æ
    print("ğŸš€ é–‹å§‹PyMCé æ¸¬çµæœåˆ†æ...")
    
    # åŸºæœ¬åˆ†æ
    results = analyze_prediction_accuracy()
    
    # è©³ç´°åœ–è¡¨
    plot_detailed_comparison()
    
    # æ€§èƒ½ç¸½çµ
    summary = summarize_model_performance()
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ä¸»è¦ç™¼ç¾: RTç›¸é—œæ€§ = {results['statistical_tests']['correlation']:.4f}")
    print(f"ParallelANDè¦å‰‡æº–ç¢ºæ€§ = {summary['summary_stats']['parallel_and_rule_accuracy']:.2f}")