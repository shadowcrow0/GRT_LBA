#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‹è¡Œå‰©é¤˜å—è©¦è€…çš„å®Œæ•´LBAåˆ†æ
åŸºæ–¼complete_reanalysis.pyä½†åªè·‘æŒ‡å®šçš„å—è©¦è€…
"""

import numpy as np
import pandas as pd
import pymc as pm
import arviz as az
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
import os
from datetime import datetime
warnings.filterwarnings('ignore')

# æª¢æŸ¥å“ªäº›å—è©¦è€…å·²ç¶“å®Œæˆ
def check_completed_participants():
    """æª¢æŸ¥å·²å®Œæˆçš„å—è©¦è€…"""
    completed = []
    results_dir = Path("complete_lba_results")
    
    if results_dir.exists():
        for file in results_dir.glob("participant_*_complete_lba_trace.nc"):
            participant_id = int(file.name.split('_')[1])
            completed.append(participant_id)
    
    return sorted(completed)

def get_remaining_participants():
    """ç²å–å‰©é¤˜éœ€è¦åˆ†æçš„å—è©¦è€…"""
    # è¼‰å…¥æ›´æ–°çš„æ•¸æ“šæª¢æŸ¥æ‰€æœ‰å—è©¦è€… (åªåŒ…å«æ­£ç¢ºç‡>=65%çš„åƒèˆ‡è€…)
    data = np.load('model_data_updated.npz', allow_pickle=True)
    all_participants = np.unique(data['participant_idx'])
    
    # æª¢æŸ¥å·²å®Œæˆçš„å—è©¦è€…
    completed = check_completed_participants()
    
    # è¨ˆç®—å‰©é¤˜å—è©¦è€…
    remaining = [p for p in all_participants if p not in completed]
    
    # é¡¯ç¤ºåŸå§‹åƒèˆ‡è€…IDå°æ‡‰
    if 'participant_mapping' in data:
        mapping = data['participant_mapping'].item()
        original_ids = {new_id: old_id for old_id, new_id in mapping.items()}
        print(f"ğŸ“Š åƒèˆ‡è€…IDæ˜ å°„: {mapping}")
        print(f"ğŸ“Š å‰©é¤˜åƒèˆ‡è€…çš„åŸå§‹ID: {[original_ids[p] for p in remaining]}")
    
    print(f"ğŸ“Š ç¸½å—è©¦è€…æ•¸: {len(all_participants)} (æ­£ç¢ºç‡>=65%)")
    print(f"âœ… å·²å®Œæˆ: {completed}")
    print(f"â³ å‰©é¤˜éœ€è¦è·‘: {remaining}")
    
    return remaining

# ä¿®æ”¹åŸå§‹çš„CompleteLBAReanalysisé¡ï¼Œä½¿å…¶å¯ä»¥æŒ‡å®šå—è©¦è€…æ¸…å–®
class RemainingParticipantsAnalysis:
    """å°ˆé–€è·‘å‰©é¤˜å—è©¦è€…çš„åˆ†æ"""
    
    def __init__(self, target_participants=None, results_dir="complete_lba_results", data_file='model_data_fixed.npz'):
        self.results_dir = Path(results_dir)
        self.data_file = data_file
        self.data = None
        self.target_participants = target_participants  # æŒ‡å®šçš„å—è©¦è€…æ¸…å–®
        self.all_participants = None
        self.results = {}
        
        # åˆºæ¿€æ¢ä»¶
        self.stimulus_conditions = {
            0: {'left': 'vertical', 'right': 'nonvertical'},
            1: {'left': 'nonvertical', 'right': 'nonvertical'}, 
            2: {'left': 'nonvertical', 'right': 'vertical'},
            3: {'left': 'vertical', 'right': 'vertical'}
        }
        
    def setup(self):
        """åˆå§‹è¨­ç½®"""
        print("ğŸ”§ è¨­ç½®å‰©é¤˜åƒèˆ‡è€…åˆ†æ...")
        print("=" * 60)
        
        # è¼‰å…¥æ•¸æ“š
        self.data = np.load(self.data_file, allow_pickle=True)
        participant_idx = self.data['participant_idx']
        all_participants = np.unique(participant_idx)
        
        # å¦‚æœæ²’æœ‰æŒ‡å®šï¼Œå‰‡è‡ªå‹•ç²å–å‰©é¤˜å—è©¦è€…
        if self.target_participants is None:
            self.target_participants = get_remaining_participants()
        
        self.all_participants = [p for p in all_participants if p in self.target_participants]
        
        print(f"ğŸ“Š ç›®æ¨™å—è©¦è€…: {self.target_participants}")
        print(f"ğŸ“Š å¯¦éš›è¦è·‘çš„å—è©¦è€…: {self.all_participants}")
        print(f"ğŸ“Š ç¸½è©¦é©—æ•¸: {len(participant_idx)}")
        
        # å‰µå»ºçµæœç›®éŒ„
        self.results_dir.mkdir(exist_ok=True)
        
        return len(self.all_participants) > 0

# å°å…¥åŸå§‹çš„CompleteDualLBAModelFitter
import sys
import importlib.util

# å˜—è©¦å¾ç¾æœ‰ç¨‹å¼ä¸­å°å…¥CompleteDualLBAModelFitter
try:
    # å¦‚æœå­˜åœ¨getposterior_complete.pyï¼Œå¾ä¸­å°å…¥
    if Path('getposterior_complete.py').exists():
        spec = importlib.util.spec_from_file_location("getposterior_complete", "getposterior_complete.py")
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        CompleteDualLBAModelFitter = module.CompleteDualLBAModelFitter
        print("âœ… å¾getposterior_complete.pyå°å…¥LBAæ¨¡å‹")
    else:
        raise ImportError("æ‰¾ä¸åˆ°getposterior_complete.py")
        
except ImportError as e:
    print(f"âš ï¸ ç„¡æ³•å°å…¥LBAæ¨¡å‹: {e}")
    print("è«‹ç¢ºèªgetposterior_complete.pyå­˜åœ¨ä¸”åŒ…å«CompleteDualLBAModelFitteré¡")
    sys.exit(1)

def fit_participant_models(participant_id, data_dict):
    """æ“¬åˆå–®å€‹å—è©¦è€…çš„LBAæ¨¡å‹"""
    
    print(f"\nğŸ¯ é–‹å§‹æ“¬åˆåƒèˆ‡è€… {participant_id}")
    
    # æº–å‚™åƒèˆ‡è€…æ•¸æ“š (ä½¿ç”¨æ›´æ–°çš„æ•¸æ“šçµæ§‹)
    participant_mask = data_dict['participant_idx'] == participant_id
    
    # å¾æ›´æ–°çš„æ•¸æ“šçµæ§‹ä¸­ç›´æ¥æå–æ•¸æ“š
    model_input = data_dict['model_input_data'].item()
    
    # ç¢ºä¿åƒèˆ‡è€…æœ‰æ•¸æ“š
    if np.sum(participant_mask) == 0:
        raise ValueError(f"åƒèˆ‡è€… {participant_id} æ²’æœ‰æ•¸æ“š")
    
    participant_data = pd.DataFrame({
        'participant_id': [participant_id] * np.sum(participant_mask),
        'stimulus_condition': model_input['stimulus_condition'][participant_mask],
        'observed_rt': model_input['observed_rt'][participant_mask], 
        'response_correct': model_input['response_correct'][participant_mask]
    })
    
    # æ·»åŠ responseåˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'response' in model_input:
        participant_data['response'] = model_input['response'][participant_mask]
    
    print(f"   è©¦é©—æ•¸: {len(participant_data)}")
    print(f"   RTç¯„åœ: {participant_data['observed_rt'].min():.3f} - {participant_data['observed_rt'].max():.3f}")
    
    # åˆå§‹åŒ–æ“¬åˆå™¨
    fitter = CompleteDualLBAModelFitter(random_seed=42)
    
    try:
        # æ“¬åˆæ¨¡å‹ (é€²ä¸€æ­¥å„ªåŒ–é€Ÿåº¦)
        summary, trace, priors = fitter.fit_model_for_participant(
            participant_data, draws=1000, tune=1000, chains=4
        )
        
        # æå–drift rateåƒæ•¸
        drift_params = fitter.extract_drift_parameters(trace, participant_data)
        
        # é€²è¡ŒRTå’Œåæ‡‰æ­£ç¢ºæ€§æ¨¡æ“¬
        print(f"ğŸ² é€²è¡Œå¾Œé©—é æ¸¬æ¨¡æ“¬...")
        simulation_df = fitter.simulate_rt_and_accuracy(trace, participant_data, n_simulations=1000)
        simulation_summary = fitter.create_simulation_summary(simulation_df)
        
        # é€²è¡Œæœ€çµ‚å·¦å³drift rateæ¨¡æ“¬
        print(f"ğŸ¯ é€²è¡Œæœ€çµ‚å·¦å³drift rateæ¨¡æ“¬...")
        final_drift_results = fitter.simulate_final_left_right_drifts(trace, participant_data, n_simulations=1000)
        
        # ä¿å­˜çµæœ
        output_dir = Path("complete_lba_results")
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜trace
        trace_file = output_dir / f"participant_{participant_id}_complete_lba_trace.nc"
        trace.to_netcdf(trace_file)
        print(f"   âœ… Traceå·²ä¿å­˜: {trace_file}")
        
        # ä¿å­˜æ‘˜è¦
        summary_file = output_dir / f"participant_{participant_id}_complete_lba_summary.csv"
        summary.to_csv(summary_file)
        print(f"   âœ… æ‘˜è¦å·²ä¿å­˜: {summary_file}")
        
        # ä¿å­˜drift parameters
        drift_file = output_dir / f"participant_{participant_id}_drift_params.npz"
        np.savez(drift_file, **drift_params)
        print(f"   âœ… Driftåƒæ•¸å·²ä¿å­˜: {drift_file}")
        
        # ä¿å­˜æ¨¡æ“¬çµæœ
        simulation_file = output_dir / f"participant_{participant_id}_simulation_results.csv"
        simulation_df.to_csv(simulation_file, index=False)
        print(f"   âœ… RTå’Œåæ‡‰æ¨¡æ“¬çµæœå·²ä¿å­˜: {simulation_file}")
        
        # ä¿å­˜æ¨¡æ“¬æ‘˜è¦
        summary_stats_file = output_dir / f"participant_{participant_id}_simulation_summary.json"
        import json
        summary_to_save = {
            'overall_mae': float(simulation_summary['overall_mae']),
            'overall_rmse': float(simulation_summary['overall_rmse']),
            'participant_accuracy': float(simulation_summary['participant_accuracy'].iloc[0]) if len(simulation_summary['participant_accuracy']) > 0 else 0.0
        }
        with open(summary_stats_file, 'w') as f:
            json.dump(summary_to_save, f, indent=2)
        print(f"   âœ… æ¨¡æ“¬æ‘˜è¦å·²ä¿å­˜: {summary_stats_file}")
        
        # ä¿å­˜æœ€çµ‚å·¦å³drift rateæ¨¡æ“¬çµæœ
        final_drift_file = output_dir / f"participant_{participant_id}_final_left_right_drifts.csv"
        final_drift_df = pd.DataFrame([
            {k: v for k, v in result.items() if k not in ['v_left_samples', 'v_right_samples']}
            for result in final_drift_results
        ])
        final_drift_df.to_csv(final_drift_file, index=False)
        print(f"   âœ… æœ€çµ‚å·¦å³drift rateæ¨¡æ“¬çµæœå·²ä¿å­˜: {final_drift_file}")
        
        # ä¿å­˜è©³ç´°samples
        samples_file = output_dir / f"participant_{participant_id}_drift_samples.npz"
        samples_data = {}
        for i, result in enumerate(final_drift_results):
            samples_data[f'trial_{i}_left_samples'] = result['v_left_samples']
            samples_data[f'trial_{i}_right_samples'] = result['v_right_samples']
        np.savez(samples_file, **samples_data)
        print(f"   âœ… è©³ç´°drift rateæ¨£æœ¬å·²ä¿å­˜: {samples_file}")
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        print(f"\nğŸ“Š åƒèˆ‡è€… {participant_id} çµæœæ‘˜è¦:")
        main_params = ['v_vertical_left', 'v_nonvertical_left', 'v_vertical_right', 'v_nonvertical_right',
                      'boundary', 'non_decision', 'start_point_variability']
        for param in main_params:
            if param in summary.index:
                row = summary.loc[param]
                print(f"   {param}: Î¼={row['mean']:.3f} Â± {row['sd']:.3f}")
        
        print(f"   RTé æ¸¬èª¤å·® (MAE): {simulation_summary['overall_mae']:.3f}")
        print(f"   RTé æ¸¬èª¤å·® (RMSE): {simulation_summary['overall_rmse']:.3f}")
        print(f"   æ¨¡æ“¬è©¦é©—ç¸½æ•¸: {len(simulation_df)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åƒèˆ‡è€… {participant_id} æ“¬åˆå¤±æ•—: {e}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹é‹è¡Œå‰©é¤˜å—è©¦è€…çš„å®Œæ•´LBAåˆ†æ")
    print("=" * 80)
    
    # æª¢æŸ¥å‰©é¤˜å—è©¦è€…
    remaining_participants = get_remaining_participants()
    
    if not remaining_participants:
        print("âœ… æ‰€æœ‰å—è©¦è€…å·²å®Œæˆåˆ†æï¼")
        return
    
    print(f"\nå°‡åˆ†æ {len(remaining_participants)} ä½å‰©é¤˜å—è©¦è€…: {remaining_participants}")
    
    # è¼‰å…¥æ›´æ–°çš„æ•¸æ“š (åŒ…å« GRT_LBA.csv çš„æ‰€æœ‰åƒæ•¸)
    data = np.load('model_data_updated.npz', allow_pickle=True)
    
    # åˆ†ææ¯ä½å—è©¦è€…
    success_count = 0
    failed_participants = []
    
    for i, participant_id in enumerate(remaining_participants):
        print(f"\n{'='*20} è™•ç†åƒèˆ‡è€… {participant_id} ({i+1}/{len(remaining_participants)}) {'='*20}")
        
        try:
            success = fit_participant_models(participant_id, data)
            if success:
                success_count += 1
                print(f"âœ… åƒèˆ‡è€… {participant_id} å®Œæˆ")
            else:
                failed_participants.append(participant_id)
                print(f"âŒ åƒèˆ‡è€… {participant_id} å¤±æ•—")
        except Exception as e:
            failed_participants.append(participant_id)
            print(f"âŒ åƒèˆ‡è€… {participant_id} ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # æœ€çµ‚æ‘˜è¦
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"âœ… æˆåŠŸ: {success_count}/{len(remaining_participants)} ä½å—è©¦è€…")
    if failed_participants:
        print(f"âŒ å¤±æ•—: {failed_participants}")
    
    print(f"\nğŸ“ æ‰€æœ‰çµæœå·²ä¿å­˜è‡³: complete_lba_results/")

if __name__ == '__main__':
    main()