# -*- coding: utf-8 -*-
"""
fit_all_participants_parallel_and.py - Fit ParallelAND model for all participants
è™•ç†æ‰€æœ‰å—è©¦è€…è³‡æ–™ï¼Œè¨ˆç®—log-likelihoodå’ŒBIC
"""

import numpy as np
import pandas as pd
import pymc as pm
import pytensor.tensor as pt
from typing import Dict
import warnings
warnings.filterwarnings('ignore')
import time

class ParallelANDModelFitter:
    """ParallelANDæ¨¡å‹fittingé¡åˆ¥"""
    
    def __init__(self):
        self.results = []
        self.failed_participants = []
        
    def load_all_participants(self, file_path: str = "GRT_LBA.csv", accuracy_threshold: float = 0.65) -> Dict:
        """è¼‰å…¥æ‰€æœ‰å—è©¦è€…è³‡æ–™ä¸¦éæ¿¾æ­£ç¢ºç‡"""
        
        print("ğŸ“Š è¼‰å…¥æ‰€æœ‰å—è©¦è€…è³‡æ–™...")
        data = pd.read_csv(file_path)
        
        # è½‰æ›stimulusæ ¼å¼
        data['left_stimulus'] = data['Chanel1']  # 0=nonvertical, 1=vertical
        data['right_stimulus'] = data['Chanel2']
        
        participants = sorted(data['participant'].unique())
        print(f"   ç™¼ç¾ {len(participants)} ä½å—è©¦è€…: {participants}")
        
        participant_data = {}
        filtered_count = 0
        
        for pid in participants:
            p_data = data[data['participant'] == pid].copy()
            
            # è¨ˆç®—æ­£ç¢ºç‡
            accuracy = self._calculate_accuracy(p_data)
            
            if accuracy >= accuracy_threshold:
                participant_data[pid] = {
                    'responses': p_data['Response'].astype(int).values,
                    'rts': p_data['RT'].astype(float).values,
                    'left_stimuli': p_data['Chanel1'].values,
                    'right_stimuli': p_data['Chanel2'].values,
                    'n_trials': len(p_data),
                    'participant_id': pid,
                    'accuracy': accuracy
                }
                print(f"   âœ… åƒèˆ‡è€… {pid}: {len(p_data)} trials, æ­£ç¢ºç‡={accuracy:.3f}")
            else:
                filtered_count += 1
                print(f"   âŒ åƒèˆ‡è€… {pid}: æ­£ç¢ºç‡={accuracy:.3f} < {accuracy_threshold}, å·²éæ¿¾")
        
        print(f"\nğŸ“‹ éæ¿¾çµæœ:")
        print(f"   ä¿ç•™: {len(participant_data)} ä½å—è©¦è€…")
        print(f"   éæ¿¾: {filtered_count} ä½å—è©¦è€…")
        print(f"   æ­£ç¢ºç‡é–¾å€¼: {accuracy_threshold}")
        
        return participant_data
    
    def create_parallel_and_model(self, data: Dict) -> pm.Model:
        """å‰µå»ºParallelAND PyMCæ¨¡å‹"""
        
        with pm.Model() as model:
            # Prior distributions (same as single_side_lba)
            left_v_vertical = pm.Gamma('left_v_vertical', alpha=2.5, beta=1.5)
            left_v_nonvertical = pm.Gamma('left_v_nonvertical', alpha=2.5, beta=1.5)
            left_v_vertical_error = pm.Gamma('left_v_vertical_error', alpha=2.0, beta=3.0)
            left_v_nonvertical_error = pm.Gamma('left_v_nonvertical_error', alpha=2.0, beta=3.0)
            A = pm.HalfNormal("start_point_variability", sigma=0.5)

            right_v_vertical = pm.Gamma('right_v_vertical', alpha=2.5, beta=1.5)
            right_v_nonvertical = pm.Gamma('right_v_nonvertical', alpha=2.5, beta=1.5)
            right_v_vertical_error = pm.Gamma('right_v_vertical_error', alpha=2.0, beta=3.0)
            right_v_nonvertical_error = pm.Gamma('right_v_nonvertical_error', alpha=2.0, beta=3.0)
            
            threshold = pm.Gamma('threshold', alpha=3.0, beta=3.5)
            ndt = pm.Uniform('ndt', lower=0.05, upper=0.6)
            effective_boundary = threshold  - A / 2
            

            # è½‰æ›è³‡æ–™ç‚ºtensors
            responses_tensor = pt.as_tensor_variable(data['responses'])
            rts_tensor = pt.as_tensor_variable(data['rts'])
            left_stimuli_tensor = pt.as_tensor_variable(data['left_stimuli'])
            right_stimuli_tensor = pt.as_tensor_variable(data['right_stimuli'])
            
            # è¨ˆç®—ParallelAND RT predictions
            predicted_rts = self._compute_parallel_and_rt(
                left_stimuli_tensor, right_stimuli_tensor, responses_tensor,
                left_v_vertical, left_v_nonvertical, left_v_vertical_error, left_v_nonvertical_error,
                right_v_vertical, right_v_nonvertical, right_v_vertical_error, right_v_nonvertical_error,
                threshold, ndt
            )
            
            # Likelihood
            rt_sigma = pm.HalfNormal('rt_sigma', sigma=0.3)
            pm.Normal('rt_obs', mu=predicted_rts, sigma=rt_sigma, observed=rts_tensor)
            
        return model
    
    def _compute_parallel_and_rt(self, left_stimuli, right_stimuli, responses,
                                left_v_v, left_v_nv, left_v_v_err, left_v_nv_err,
                                right_v_v, right_v_nv, right_v_v_err, right_v_nv_err,
                                threshold, ndt):
        """è¨ˆç®—ParallelAND RT predictions"""
        
        # å·¦å´drift rates (åŸºæ–¼stimulus-responseçµ„åˆ)
        left_is_vertical_stim = pt.eq(left_stimuli, 1)
        left_is_vertical_resp = pt.or_(pt.eq(responses, 1), pt.eq(responses, 2))
        
        # ä¾æ“šsingle_side_lbaé‚è¼¯ï¼šstimulusæ±ºå®šæ˜¯å¦ä½¿ç”¨error drift rate
        left_drift = pt.where(
            left_is_vertical_stim,  # Vertical stimulus
            pt.where(left_is_vertical_resp, left_v_v, left_v_nv_err),
            pt.where(left_is_vertical_resp, left_v_v_err, left_v_nv)
        )
        
        # å³å´drift rates (åŸºæ–¼stimulus-responseçµ„åˆ)
        right_is_vertical_stim = pt.eq(right_stimuli, 1)
        right_is_vertical_resp = pt.or_(pt.eq(responses, 0), pt.eq(responses, 1))
        
        # ä¾æ“šsingle_side_lbaé‚è¼¯ï¼šstimulusæ±ºå®šæ˜¯å¦ä½¿ç”¨error drift rate
        right_drift = pt.where(
            right_is_vertical_stim,  # Vertical stimulus
            pt.where(right_is_vertical_resp, right_v_v, right_v_nv_err),
            pt.where(right_is_vertical_resp, right_v_v_err, right_v_nv)
        )
        
        # ParallelAND: æœ€å°drift rate
        effective_drift = pt.minimum(left_drift, right_drift)
        effective_drift = pt.maximum(effective_drift, 0.05)
        
        # RT prediction
        decision_time = threshold / effective_drift
        predicted_rt = decision_time + ndt
        
        return predicted_rt
    
    def fit_participant(self, participant_id: int, data: Dict, 
                       n_samples: int = 1000, n_tune: int = 1000) -> Dict:
        """Fitæ¨¡å‹çµ¦å–®ä¸€å—è©¦è€…"""
        
        print(f"\nğŸ”¬ Fitting participant {participant_id} ({data['n_trials']} trials)...")
        start_time = time.time()
        
        try:
            # å‰µå»ºæ¨¡å‹
            model = self.create_parallel_and_model(data)
            
            # MCMC sampling
            with model:
                trace = pm.sample(
                    draws=n_samples,
                    tune=n_tune,
                    target_accept=0.95,
                    chains=4,
                    cores=2,  # å–®coreé¿å…ä¸¦è¡Œå•é¡Œ
                    random_seed=42 + participant_id,
                    progressbar=True,  # é—œé–‰progress baré¿å…éå¤šè¼¸å‡º
                    return_inferencedata=True
                )
            
            # è¨ˆç®—posterior means
            posterior_means = {}
            for var in trace.posterior.data_vars:
                posterior_means[var] = float(trace.posterior[var].mean())
            
            # è¨ˆç®—log-likelihood
            log_likelihood = self._calculate_log_likelihood(data, posterior_means)
            
            # è¨ˆç®—BIC
            n_params = len(posterior_means)
            n_trials = data['n_trials']
            bic = -2 * log_likelihood + n_params * np.log(n_trials)
            
            # è¨ˆç®—å…¶ä»–metrics
            aic = -2 * log_likelihood + 2 * n_params
            
            fit_time = time.time() - start_time
            
            result = {
                'participant_id': participant_id,
                'n_trials': n_trials,
                'n_parameters': n_params,
                'log_likelihood': log_likelihood,
                'bic': bic,
                'aic': aic,
                'fit_time_seconds': fit_time,
                'converged': True,
                'posterior_means': posterior_means,
                'trace': trace
            }
            
            print(f"   âœ… æˆåŠŸ! LL={log_likelihood:.2f}, BIC={bic:.2f}, æ™‚é–“={fit_time:.1f}s")
            return result
            
        except Exception as e:
            fit_time = time.time() - start_time
            print(f"   âŒ å¤±æ•—: {str(e)}")
            
            self.failed_participants.append({
                'participant_id': participant_id,
                'error': str(e),
                'fit_time_seconds': fit_time
            })
            
            return None
    
    def _calculate_log_likelihood(self, data: Dict, params: Dict) -> float:
        """è¨ˆç®—log-likelihood"""
        
        try:
            predictions = self._generate_rt_predictions(data, params)
            actual_rts = data['rts']
            predicted_rts = predictions['predicted_rts']
            
            # ä½¿ç”¨Normal likelihood
            sigma = params.get('rt_sigma', 0.3)
            log_likelihood = np.sum(
                -0.5 * np.log(2 * np.pi * sigma**2) - 
                0.5 * ((actual_rts - predicted_rts) / sigma)**2
            )
            
            return log_likelihood
            
        except Exception as e:
            print(f"   è­¦å‘Š: log-likelihoodè¨ˆç®—å¤±æ•—: {e}")
            return -np.inf
    
    def _generate_rt_predictions(self, data: Dict, params: Dict) -> Dict:
        """ç”ŸæˆRT predictions"""
        
        predicted_rts = []
        
        for i in range(data['n_trials']):
            left_stim = data['left_stimuli'][i]
            right_stim = data['right_stimuli'][i]
            response = data['responses'][i]
            
            # è¨ˆç®—drift rates
            if left_stim == 1:  # Vertical stimulus
                left_v_v = params['left_v_vertical']
                left_v_nv = params['left_v_nonvertical_error']
            else:  # Nonvertical stimulus
                left_v_v = params['left_v_vertical_error']
                left_v_nv = params['left_v_nonvertical']
            
            if right_stim == 1:  # Vertical stimulus
                right_v_v = params['right_v_vertical']
                right_v_nv = params['right_v_nonvertical_error']
            else:  # Nonvertical stimulus
                right_v_v = params['right_v_vertical_error']
                right_v_nv = params['right_v_nonvertical']
            
            # ç¢ºå®šä½¿ç”¨çš„drift rates
            if response in [1, 2]:  # Left vertical response
                left_drift = left_v_v
            else:  # Left nonvertical response
                left_drift = left_v_nv
                
            if response in [0, 1]:  # Right vertical response
                right_drift = right_v_v
            else:  # Right nonvertical response
                right_drift = right_v_nv
            
            # ParallelAND: æœ€å°drift rate
            effective_drift = min(left_drift, right_drift)
            effective_drift = max(effective_drift, 0.05)
            
            # RT prediction
            decision_time = params['threshold'] / effective_drift
            predicted_rt = decision_time + params['ndt']
            
            predicted_rts.append(predicted_rt)
        
        return {'predicted_rts': predicted_rts}
    
    def fit_all_participants(self, file_path: str = "GRT_LBA.csv", accuracy_threshold: float = 0.65) -> pd.DataFrame:
        """Fitæ¨¡å‹çµ¦æ‰€æœ‰å—è©¦è€…ï¼ˆéæ¿¾æ­£ç¢ºç‡ï¼‰"""
        
        print("ğŸš€ é–‹å§‹fittingæ‰€æœ‰å—è©¦è€…çš„ParallelANDæ¨¡å‹...")
        print("="*60)
        
        # è¼‰å…¥è³‡æ–™ä¸¦éæ¿¾
        all_data = self.load_all_participants(file_path, accuracy_threshold)
        
        if len(all_data) == 0:
            print(f"âŒ æ²’æœ‰å—è©¦è€…ç¬¦åˆæ­£ç¢ºç‡é–¾å€¼ {accuracy_threshold}")
            return pd.DataFrame()
        
        # Fitæ¯å€‹å—è©¦è€…
        for participant_id, data in all_data.items():
            result = self.fit_participant(participant_id, data)
            if result is not None:
                # æ·»åŠ æ­£ç¢ºç‡ä¿¡æ¯
                result['accuracy'] = data['accuracy']
                self.results.append(result)
        
        # è½‰æ›ç‚ºDataFrame
        if self.results:
            results_df = pd.DataFrame([
                {
                    'participant_id': r['participant_id'],
                    'accuracy': r['accuracy'],
                    'n_trials': r['n_trials'],
                    'n_parameters': r['n_parameters'],
                    'log_likelihood': r['log_likelihood'],
                    'bic': r['bic'],
                    'aic': r['aic'],
                    'fit_time_seconds': r['fit_time_seconds'],
                    'converged': r['converged']
                }
                for r in self.results
            ])
        else:
            results_df = pd.DataFrame()
        
        return results_df
    
    def save_results(self, results_df: pd.DataFrame, output_prefix: str = "all_participants_parallel_and"):
        """å„²å­˜çµæœ"""
        
        print(f"\nğŸ’¾ å„²å­˜çµæœ...")
        
        # å„²å­˜ç¸½çµæœ
        results_df.to_csv(f"{output_prefix}_summary.csv", index=False)
        print(f"   ğŸ“ ç¸½çµæœ: {output_prefix}_summary.csv")
        
        # å„²å­˜è©³ç´°åƒæ•¸
        detailed_params = []
        for result in self.results:
            param_row = {'participant_id': result['participant_id']}
            param_row.update(result['posterior_means'])
            detailed_params.append(param_row)
        
        if detailed_params:
            params_df = pd.DataFrame(detailed_params)
            params_df.to_csv(f"{output_prefix}_parameters.csv", index=False)
            print(f"   ğŸ“ è©³ç´°åƒæ•¸: {output_prefix}_parameters.csv")
        
        # å„²å­˜å¤±æ•—çš„å—è©¦è€…
        if self.failed_participants:
            failed_df = pd.DataFrame(self.failed_participants)
            failed_df.to_csv(f"{output_prefix}_failed.csv", index=False)
            print(f"   ğŸ“ å¤±æ•—ç´€éŒ„: {output_prefix}_failed.csv")
        
        # å°å‡ºç¸½çµ
        print(f"\nğŸ“Š ç¸½çµ:")
        print(f"   æˆåŠŸfitting: {len(self.results)} ä½å—è©¦è€…")
        print(f"   å¤±æ•—: {len(self.failed_participants)} ä½å—è©¦è€…")
        
        if len(results_df) > 0:
            print(f"   å¹³å‡log-likelihood: {results_df['log_likelihood'].mean():.2f}")
            print(f"   å¹³å‡BIC: {results_df['bic'].mean():.2f}")
            print(f"   å¹³å‡AIC: {results_df['aic'].mean():.2f}")
            print(f"   æœ€ä½³BIC: {results_df['bic'].min():.2f} (åƒèˆ‡è€… {results_df.loc[results_df['bic'].idxmin(), 'participant_id']})")

    def _calculate_accuracy(self, p_data: pd.DataFrame) -> float:
        """è¨ˆç®—å–®ä¸€å—è©¦è€…çš„æ­£ç¢ºç‡ï¼ˆåŸºæ–¼Correctæ¬„ä½ï¼‰"""
        
        # ç›´æ¥ä½¿ç”¨Correctæ¬„ä½è¨ˆç®—æ­£ç¢ºç‡
        return p_data['Correct'].mean()

def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    
    print("ğŸ¯ ParallelANDæ¨¡å‹ - é«˜æ­£ç¢ºç‡å—è©¦è€…fitting (>65%)")
    print("="*60)
    
    # åˆå§‹åŒ–fitter
    fitter = ParallelANDModelFitter()
    
    # Fitæ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„å—è©¦è€…
    results_df = fitter.fit_all_participants(accuracy_threshold=0.65)
    
    # å„²å­˜çµæœ
    if len(results_df) > 0:
        fitter.save_results(results_df, output_prefix="high_accuracy_parallel_and")
        
        # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        print(f"\nğŸ“Š æ­£ç¢ºç‡çµ±è¨ˆ:")
        print(f"   å¹³å‡æ­£ç¢ºç‡: {results_df['accuracy'].mean():.3f}")
        print(f"   æ­£ç¢ºç‡ç¯„åœ: {results_df['accuracy'].min():.3f} - {results_df['accuracy'].max():.3f}")
        
        # é¡¯ç¤ºå‰å¹¾åçµæœ
        print(f"\nğŸ† BICå‰5å:")
        top_5 = results_df.nsmallest(5, 'bic')[['participant_id', 'accuracy', 'log_likelihood', 'bic', 'aic']]
        print(top_5.to_string(index=False))
        
    else:
        print("âŒ æ²’æœ‰æˆåŠŸçš„çµæœ")
    
    print(f"\nâœ… å®Œæˆ!")

if __name__ == "__main__":
    main()