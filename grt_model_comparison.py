# -*- coding: utf-8 -*-
"""
grt_model_comparison.py - GRT å››é¸é …æ¨¡å‹æ¯”è¼ƒ
Four-Choice GRT Model Comparison: Parallel AND vs Coactive Architectures

å¯¦ç¾å…©ç¨®è™•ç†æ¶æ§‹çš„å®Œæ•´ PyMC æ¨¡å‹ï¼š
1. Parallel AND (Exhaustive): å·¦å³ç¨ç«‹è™•ç†ï¼Œå–æœ€å¤§æ™‚é–“
2. Coactive: å·¦å³è­‰æ“šåŠ ç¸½ï¼Œå…±åŒè™•ç†

åŒ…å«å®Œæ•´çš„æ¨¡å‹æ¯”è¼ƒæ¡†æ¶ï¼šWAIC, LOO, BIC, Bayes Factor ç­‰
"""

import numpy as np
import pandas as pd
import pymc as pm
import pytensor.tensor as pt
import arviz as az
import time
from typing import Dict, List, Tuple, Optional
from enum import Enum
from dataclasses import dataclass

class ModelType(Enum):
    """æ¨¡å‹é¡å‹"""
    PARALLEL_AND = "parallel_and"
    COACTIVE = "coactive"

@dataclass
class ModelComparisonResult:
    """æ¨¡å‹æ¯”è¼ƒçµæœ"""
    model_type: ModelType
    waic: float
    waic_se: float
    loo: float
    loo_se: float
    bic: float
    marginal_likelihood: float
    n_parameters: int
    convergence_success: bool
    sampling_time: float

class GRTModelBuilder:
    """GRT å››é¸é …æ¨¡å‹å»ºæ§‹å™¨"""
    
    def __init__(self, model_type: ModelType):
        """
        åˆå§‹åŒ–æ¨¡å‹å»ºæ§‹å™¨
        
        Args:
            model_type: æ¨¡å‹é¡å‹ (PARALLEL_AND æˆ– COACTIVE)
        """
        self.model_type = model_type
        self.param_names = self._get_parameter_names()
        
        print(f"ğŸ”§ åˆå§‹åŒ– {model_type.value} æ¨¡å‹å»ºæ§‹å™¨")
        print(f"   åƒæ•¸æ•¸é‡: {len(self.param_names)}")
        
    def _get_parameter_names(self) -> List[str]:
        """ç²å–æ¨¡å‹åƒæ•¸åç¨±"""
        
        if self.model_type == ModelType.PARALLEL_AND:
            return [
                # å·¦é€šé“ LBA åƒæ•¸
                'left_drift_correct', 'left_drift_incorrect',
                'left_threshold', 'left_start_var', 'left_ndt', 'left_noise',
                
                # å³é€šé“ LBA åƒæ•¸
                'right_drift_correct', 'right_drift_incorrect', 
                'right_threshold', 'right_start_var', 'right_ndt', 'right_noise',
                
                # å››é¸é …æ•´åˆå±¤åƒæ•¸
                'choice_0_drift', 'choice_1_drift', 'choice_2_drift', 'choice_3_drift',
                'final_threshold', 'final_start_var', 'final_ndt', 'final_noise',
                
                # æ™‚é–“åˆ†é…åƒæ•¸
                'time_split_ratio'  # ç¬¬ä¸€éšæ®µå ç¸½æ™‚é–“çš„æ¯”ä¾‹
            ]
        else:  # COACTIVE
            return [
                # å…±åŒæ¿€æ´» LBA åƒæ•¸
                'coactive_drift_correct', 'coactive_drift_incorrect',
                'coactive_threshold', 'coactive_start_var', 'coactive_ndt', 'coactive_noise',
                
                # å·¦å³é€šé“æ¬Šé‡
                'left_channel_weight', 'right_channel_weight',
                
                # å››é¸é …æ•´åˆå±¤åƒæ•¸
                'choice_0_drift', 'choice_1_drift', 'choice_2_drift', 'choice_3_drift',
                'final_threshold', 'final_start_var', 'final_ndt', 'final_noise',
                
                # æ™‚é–“åˆ†é…åƒæ•¸
                'time_split_ratio'
            ]
    
    def build_model(self, subject_data: Dict) -> pm.Model:
        """
        å»ºæ§‹å®Œæ•´çš„ PyMC æ¨¡å‹
        
        Args:
            subject_data: å—è©¦è€…è³‡æ–™å­—å…¸ï¼ŒåŒ…å«ï¼š
                - choices: å››é¸é …é¸æ“‡ (0,1,2,3)
                - rt: åæ‡‰æ™‚é–“
                - left_stimuli: å·¦é‚Šåˆºæ¿€ (0=å‚ç›´, 1=å°è§’)
                - left_choices: å·¦é‚Šé¸æ“‡ (0=å‚ç›´, 1=å°è§’)
                - right_stimuli: å³é‚Šåˆºæ¿€ (0=å‚ç›´, 1=å°è§’)
                - right_choices: å³é‚Šé¸æ“‡ (0=å‚ç›´, 1=å°è§’)
                
        Returns:
            PyMC æ¨¡å‹
        """
        
        print(f"ğŸ—ï¸  å»ºæ§‹ {self.model_type.value} PyMC æ¨¡å‹...")
        print(f"   å—è©¦è€…: {subject_data['subject_id']}")
        print(f"   è©¦é©—æ•¸: {subject_data['n_trials']}")
        
        with pm.Model() as model:
            
            # 1. å®šç¾©å…ˆé©—åˆ†å¸ƒ
            params = self._define_priors()
            
            # 2. æº–å‚™è§€å¯Ÿè³‡æ–™
            data_tensors = self._prepare_data_tensors(subject_data)
            
            # 3. æ ¹æ“šæ¨¡å‹é¡å‹è¨ˆç®—ä¼¼ç„¶
            if self.model_type == ModelType.PARALLEL_AND:
                log_likelihood = self._compute_parallel_and_likelihood(params, data_tensors)
            else:
                log_likelihood = self._compute_coactive_likelihood(params, data_tensors)
            
            # 4. æ·»åŠ ä¼¼ç„¶åˆ°æ¨¡å‹
            pm.Potential('model_likelihood', log_likelihood)
            
            # 5. æ·»åŠ è¨ºæ–·è®Šæ•¸
            pm.Deterministic('total_log_likelihood', log_likelihood)
            
        print(f"âœ… {self.model_type.value} æ¨¡å‹å»ºæ§‹å®Œæˆ")
        print(f"   è‡ªç”±åƒæ•¸: {len(model.free_RVs)}")
        
        return model
    
    def _define_priors(self) -> Dict:
        """å®šç¾©å…ˆé©—åˆ†å¸ƒ"""
        
        params = {}
        
        if self.model_type == ModelType.PARALLEL_AND:
            # å·¦é€šé“åƒæ•¸
            params['left_drift_correct'] = pm.Gamma('left_drift_correct', alpha=2.5, beta=1.5)
            params['left_drift_incorrect'] = pm.Gamma('left_drift_incorrect', alpha=2.0, beta=3.0)
            params['left_threshold'] = pm.Gamma('left_threshold', alpha=3.0, beta=3.5)
            params['left_start_var'] = pm.Uniform('left_start_var', lower=0.1, upper=0.7)
            params['left_ndt'] = pm.Uniform('left_ndt', lower=0.05, upper=0.4)
            params['left_noise'] = pm.Gamma('left_noise', alpha=2.5, beta=8.0)
            
            # å³é€šé“åƒæ•¸
            params['right_drift_correct'] = pm.Gamma('right_drift_correct', alpha=2.5, beta=1.5)
            params['right_drift_incorrect'] = pm.Gamma('right_drift_incorrect', alpha=2.0, beta=3.0)
            params['right_threshold'] = pm.Gamma('right_threshold', alpha=3.0, beta=3.5)
            params['right_start_var'] = pm.Uniform('right_start_var', lower=0.1, upper=0.7)
            params['right_ndt'] = pm.Uniform('right_ndt', lower=0.05, upper=0.4)
            params['right_noise'] = pm.Gamma('right_noise', alpha=2.5, beta=8.0)
            
        else:  # COACTIVE
            # å…±åŒæ¿€æ´»åƒæ•¸
            params['coactive_drift_correct'] = pm.Gamma('coactive_drift_correct', alpha=3.0, beta=1.2)
            params['coactive_drift_incorrect'] = pm.Gamma('coactive_drift_incorrect', alpha=2.0, beta=2.5)
            params['coactive_threshold'] = pm.Gamma('coactive_threshold', alpha=3.0, beta=3.0)
            params['coactive_start_var'] = pm.Uniform('coactive_start_var', lower=0.1, upper=0.8)
            params['coactive_ndt'] = pm.Uniform('coactive_ndt', lower=0.05, upper=0.4)
            params['coactive_noise'] = pm.Gamma('coactive_noise', alpha=2.5, beta=6.0)
            
            # é€šé“æ¬Šé‡åƒæ•¸
            params['left_channel_weight'] = pm.Beta('left_channel_weight', alpha=3.0, beta=3.0)
            params['right_channel_weight'] = pm.Beta('right_channel_weight', alpha=3.0, beta=3.0)
        
        # å››é¸é …æ•´åˆå±¤åƒæ•¸ï¼ˆå…©ç¨®æ¨¡å‹éƒ½éœ€è¦ï¼‰
        for i in range(4):
            params[f'choice_{i}_drift'] = pm.Gamma(f'choice_{i}_drift', alpha=2.0, beta=2.0)
        
        params['final_threshold'] = pm.Gamma('final_threshold', alpha=2.5, beta=3.0)
        params['final_start_var'] = pm.Uniform('final_start_var', lower=0.1, upper=0.5)
        params['final_ndt'] = pm.Uniform('final_ndt', lower=0.05, upper=0.3)
        params['final_noise'] = pm.Gamma('final_noise', alpha=2.0, beta=6.0)
        
        # æ™‚é–“åˆ†é…åƒæ•¸
        params['time_split_ratio'] = pm.Beta('time_split_ratio', alpha=3.0, beta=2.0)
        
        return params
    
    def _prepare_data_tensors(self, subject_data: Dict) -> Dict:
        """æº–å‚™è³‡æ–™å¼µé‡"""
        
        return {
            'final_choices': pt.as_tensor_variable(subject_data['choices'], dtype='int32'),
            'rt_total': pt.as_tensor_variable(subject_data['rt'], dtype='float64'),
            'left_stimuli': pt.as_tensor_variable(subject_data['left_stimuli'], dtype='int32'),
            'left_choices': pt.as_tensor_variable(subject_data['left_choices'], dtype='int32'),
            'right_stimuli': pt.as_tensor_variable(subject_data['right_stimuli'], dtype='int32'),
            'right_choices': pt.as_tensor_variable(subject_data['right_choices'], dtype='int32'),
            'n_trials': len(subject_data['choices'])
        }
    
    def _compute_parallel_and_likelihood(self, params: Dict, data: Dict) -> pt.TensorVariable:
        """
        è¨ˆç®— Parallel AND æ¨¡å‹çš„ä¼¼ç„¶å‡½æ•¸
        
        æ¶æ§‹ï¼š
        1. å·¦å³å…©å€‹ç¨ç«‹ LBA åŒæ™‚è™•ç†
        2. ç­‰å¾…å…©é‚Šéƒ½å®Œæˆï¼ˆAND stopping ruleï¼‰
        3. å– max(left_time, right_time) ä½œç‚ºç¬¬ä¸€éšæ®µæ™‚é–“
        4. å‰©é¤˜æ™‚é–“ç”¨æ–¼å››é¸é …æ±ºç­–
        """
        
        # æ‡‰ç”¨åƒæ•¸ç´„æŸ
        left_params = self._apply_parameter_constraints(params, 'left')
        right_params = self._apply_parameter_constraints(params, 'right')
        final_params = self._apply_parameter_constraints(params, 'final')
        time_split = pt.clip(params['time_split_ratio'], 0.3, 0.8)
        
        # è¨ˆç®—ç¬¬ä¸€éšæ®µæ™‚é–“åˆ†é…
        stage1_time = data['rt_total'] * time_split
        stage2_time = data['rt_total'] * (1 - time_split)
        stage2_time = pt.maximum(stage2_time, 0.01)
        
        # å·¦é€šé“ LBA ä¼¼ç„¶
        left_ll = self._compute_single_channel_lba_likelihood(
            data['left_choices'], data['left_stimuli'], stage1_time, left_params
        )
        
        # å³é€šé“ LBA ä¼¼ç„¶
        right_ll = self._compute_single_channel_lba_likelihood(
            data['right_choices'], data['right_stimuli'], stage1_time, right_params
        )
        
        # AND stopping rule: å…©é‚Šéƒ½éœ€è¦å®Œæˆ
        # é€™è£¡æˆ‘å€‘å‡è¨­è§€å¯Ÿåˆ°çš„åæ‡‰è¡¨ç¤ºå…©é‚Šéƒ½å·²ç¶“è™•ç†å®Œæˆ
        stage1_likelihood = left_ll + right_ll
        
        # è¨ˆç®—æ•´åˆè­‰æ“š
        evidence_strength = self._compute_parallel_evidence_strength(
            left_params, right_params, data['left_stimuli'], data['left_choices'],
            data['right_stimuli'], data['right_choices']
        )
        
        # ç¬¬äºŒéšæ®µï¼šå››é¸é …æ±ºç­–
        stage2_likelihood = self._compute_four_choice_lba_likelihood(
            data['final_choices'], stage2_time, evidence_strength, final_params
        )
        
        return stage1_likelihood + stage2_likelihood
    
    def _compute_coactive_likelihood(self, params: Dict, data: Dict) -> pt.TensorVariable:
        """
        è¨ˆç®— Coactive æ¨¡å‹çš„ä¼¼ç„¶å‡½æ•¸
        
        æ¶æ§‹ï¼š
        1. å·¦å³è­‰æ“šåŠ ç¸½åˆ°å–®ä¸€ LBA
        2. å…±åŒæ¿€æ´»è™•ç†ç”¢ç”Ÿç¬¬ä¸€éšæ®µæ±ºç­–
        3. å‰©é¤˜æ™‚é–“ç”¨æ–¼å››é¸é …æ±ºç­–
        """
        
        # æ‡‰ç”¨åƒæ•¸ç´„æŸ
        coactive_params = self._apply_parameter_constraints(params, 'coactive')
        final_params = self._apply_parameter_constraints(params, 'final')
        time_split = pt.clip(params['time_split_ratio'], 0.3, 0.8)
        
        # æ¬Šé‡åƒæ•¸
        left_weight = pt.clip(params['left_channel_weight'], 0.1, 0.9)
        right_weight = pt.clip(params['right_channel_weight'], 0.1, 0.9)
        
        # è¨ˆç®—æ™‚é–“åˆ†é…
        stage1_time = data['rt_total'] * time_split
        stage2_time = data['rt_total'] * (1 - time_split)
        stage2_time = pt.maximum(stage2_time, 0.01)
        
        # è¨ˆç®—åŠ æ¬Šçµ„åˆçš„æ¼‚ç§»ç‡
        combined_drift_correct, combined_drift_incorrect = self._compute_coactive_drifts(
            coactive_params, left_weight, right_weight,
            data['left_stimuli'], data['left_choices'],
            data['right_stimuli'], data['right_choices']
        )
        
        # ç¬¬ä¸€éšæ®µï¼šå…±åŒæ¿€æ´» LBA ä¼¼ç„¶
        stage1_likelihood = self._compute_coactive_lba_likelihood(
            combined_drift_correct, combined_drift_incorrect, 
            stage1_time, coactive_params
        )
        
        # è¨ˆç®—æ•´åˆè­‰æ“š
        evidence_strength = self._compute_coactive_evidence_strength(
            left_weight, right_weight, coactive_params,
            data['left_stimuli'], data['left_choices'],
            data['right_stimuli'], data['right_choices']
        )
        
        # ç¬¬äºŒéšæ®µï¼šå››é¸é …æ±ºç­–
        stage2_likelihood = self._compute_four_choice_lba_likelihood(
            data['final_choices'], stage2_time, evidence_strength, final_params
        )
        
        return stage1_likelihood + stage2_likelihood
    
    def _apply_parameter_constraints(self, params: Dict, prefix: str) -> Dict:
        """æ‡‰ç”¨åƒæ•¸ç´„æŸ"""
        
        constrained = {}
        
        if prefix in ['left', 'right']:
            constrained[f'{prefix}_drift_correct'] = pt.maximum(params[f'{prefix}_drift_correct'], 0.1)
            constrained[f'{prefix}_drift_incorrect'] = pt.maximum(params[f'{prefix}_drift_incorrect'], 0.05)
            constrained[f'{prefix}_threshold'] = pt.maximum(params[f'{prefix}_threshold'], 0.1)
            constrained[f'{prefix}_start_var'] = pt.clip(params[f'{prefix}_start_var'], 0.05, 1.0)
            constrained[f'{prefix}_ndt'] = pt.clip(params[f'{prefix}_ndt'], 0.05, 0.5)
            constrained[f'{prefix}_noise'] = pt.maximum(params[f'{prefix}_noise'], 0.1)
            
            # ç¢ºä¿æ­£ç¢ºæ¼‚ç§»ç‡ > éŒ¯èª¤æ¼‚ç§»ç‡
            constrained[f'{prefix}_drift_correct'] = pt.maximum(
                constrained[f'{prefix}_drift_correct'],
                constrained[f'{prefix}_drift_incorrect'] + 0.05
            )
            
        elif prefix == 'coactive':
            constrained['coactive_drift_correct'] = pt.maximum(params['coactive_drift_correct'], 0.1)
            constrained['coactive_drift_incorrect'] = pt.maximum(params['coactive_drift_incorrect'], 0.05)
            constrained['coactive_threshold'] = pt.maximum(params['coactive_threshold'], 0.1)
            constrained['coactive_start_var'] = pt.clip(params['coactive_start_var'], 0.05, 1.0)
            constrained['coactive_ndt'] = pt.clip(params['coactive_ndt'], 0.05, 0.5)
            constrained['coactive_noise'] = pt.maximum(params['coactive_noise'], 0.1)
            
            # ç¢ºä¿æ­£ç¢ºæ¼‚ç§»ç‡ > éŒ¯èª¤æ¼‚ç§»ç‡
            constrained['coactive_drift_correct'] = pt.maximum(
                constrained['coactive_drift_correct'],
                constrained['coactive_drift_incorrect'] + 0.05
            )
            
        elif prefix == 'final':
            for i in range(4):
                constrained[f'choice_{i}_drift'] = pt.maximum(params[f'choice_{i}_drift'], 0.1)
            constrained['final_threshold'] = pt.maximum(params['final_threshold'], 0.1)
            constrained['final_start_var'] = pt.clip(params['final_start_var'], 0.05, 0.8)
            constrained['final_ndt'] = pt.clip(params['final_ndt'], 0.05, 0.4)
            constrained['final_noise'] = pt.maximum(params['final_noise'], 0.1)
        
        return constrained
    
    def _compute_single_channel_lba_likelihood(self, decisions, stimuli, rt, params):
        """è¨ˆç®—å–®é€šé“ LBA ä¼¼ç„¶"""
        
        prefix = list(params.keys())[0].split('_')[0]
        
        drift_correct = params[f'{prefix}_drift_correct']
        drift_incorrect = params[f'{prefix}_drift_incorrect']
        threshold = params[f'{prefix}_threshold']
        start_var = params[f'{prefix}_start_var']
        ndt = params[f'{prefix}_ndt']
        noise = params[f'{prefix}_noise']
        
        # è¨ˆç®—æ±ºç­–æ™‚é–“
        decision_time = pt.maximum(rt - ndt, 0.01)
        
        # åˆ¤æ–·æ­£ç¢ºæ€§
        is_correct = pt.eq(decisions, stimuli)
        
        # è¨­å®šæ¼‚ç§»ç‡
        v_winner = pt.where(is_correct, drift_correct, drift_incorrect)
        v_loser = pt.where(is_correct, drift_incorrect, drift_correct)
        
        # è¨ˆç®— LBA ä¼¼ç„¶
        return self._lba_likelihood_core(decision_time, v_winner, v_loser, threshold, start_var, noise)
    
    def _compute_coactive_drifts(self, params, left_weight, right_weight,
                                left_stimuli, left_choices, right_stimuli, right_choices):
        """è¨ˆç®—å…±åŒæ¿€æ´»çš„çµ„åˆæ¼‚ç§»ç‡"""
        
        # å·¦é€šé“è²¢ç»
        left_correct = pt.eq(left_choices, left_stimuli)
        left_drift = pt.where(left_correct, 
                             params['coactive_drift_correct'], 
                             params['coactive_drift_incorrect'])
        
        # å³é€šé“è²¢ç»
        right_correct = pt.eq(right_choices, right_stimuli)
        right_drift = pt.where(right_correct,
                              params['coactive_drift_correct'],
                              params['coactive_drift_incorrect'])
        
        # åŠ æ¬Šçµ„åˆï¼ˆCoactive çš„æ ¸å¿ƒç‰¹å¾µï¼‰
        combined_drift_correct = left_weight * left_drift + right_weight * right_drift
        combined_drift_incorrect = (left_weight * params['coactive_drift_incorrect'] + 
                                   right_weight * params['coactive_drift_incorrect'])
        
        return combined_drift_correct, combined_drift_incorrect
    
    def _compute_coactive_lba_likelihood(self, drift_correct, drift_incorrect, rt, params):
        """è¨ˆç®—å…±åŒæ¿€æ´» LBA ä¼¼ç„¶"""
        
        threshold = params['coactive_threshold']
        start_var = params['coactive_start_var']
        ndt = params['coactive_ndt']
        noise = params['coactive_noise']
        
        decision_time = pt.maximum(rt - ndt, 0.01)
        
        # å‡è¨­æˆ‘å€‘ç¸½æ˜¯é¸æ“‡è¼ƒå¼·çš„è­‰æ“š
        v_winner = pt.maximum(drift_correct, drift_incorrect)
        v_loser = pt.minimum(drift_correct, drift_incorrect)
        
        return self._lba_likelihood_core(decision_time, v_winner, v_loser, threshold, start_var, noise)
    
    def _compute_parallel_evidence_strength(self, left_params, right_params,
                                          left_stimuli, left_choices, right_stimuli, right_choices):
        """è¨ˆç®—å¹³è¡Œè™•ç†çš„è­‰æ“šå¼·åº¦"""
        
        # å·¦é€šé“å¼·åº¦
        left_strength = left_params['left_drift_correct'] / pt.maximum(left_params['left_drift_incorrect'], 0.1)
        
        # å³é€šé“å¼·åº¦
        right_strength = right_params['right_drift_correct'] / pt.maximum(right_params['right_drift_incorrect'], 0.1)
        
        # å››é¸é …è­‰æ“šçµ„åˆï¼ˆåŸºæ–¼ GRT å°æ‡‰é—œä¿‚ï¼‰
        return {
            'choice_0': left_strength * 0.8 + right_strength * 0.2,  # å·¦å°è§’å³å‚ç›´
            'choice_1': left_strength * 0.8 + right_strength * 0.8,  # å·¦å°è§’å³å°è§’
            'choice_2': left_strength * 0.2 + right_strength * 0.2,  # å·¦å‚ç›´å³å‚ç›´
            'choice_3': left_strength * 0.2 + right_strength * 0.8   # å·¦å‚ç›´å³å°è§’
        }
    
    def _compute_coactive_evidence_strength(self, left_weight, right_weight, params,
                                          left_stimuli, left_choices, right_stimuli, right_choices):
        """è¨ˆç®—å…±åŒæ¿€æ´»çš„è­‰æ“šå¼·åº¦"""
        
        # çµ„åˆå¼·åº¦
        combined_strength = (left_weight + right_weight) * \
                           params['coactive_drift_correct'] / pt.maximum(params['coactive_drift_incorrect'], 0.1)
        
        # å››é¸é …è­‰æ“šï¼ˆå…±åŒæ¿€æ´»å°è‡´è¼ƒå‡å‹»çš„åˆ†å¸ƒï¼‰
        base_evidence = combined_strength * 0.6
        return {
            'choice_0': base_evidence * 1.05,
            'choice_1': base_evidence * 1.00,
            'choice_2': base_evidence * 0.95,
            'choice_3': base_evidence * 1.00
        }
    
    def _compute_four_choice_lba_likelihood(self, choices, rt, evidence_strength, params):
        """è¨ˆç®—å››é¸é … LBA ä¼¼ç„¶"""
        
        # èª¿æ•´æ¼‚ç§»ç‡
        adjusted_drifts = []
        for i in range(4):
            base_drift = params[f'choice_{i}_drift']
            evidence_boost = evidence_strength[f'choice_{i}']
            adjusted_drift = base_drift * (1.0 + evidence_boost * 0.3)
            adjusted_drifts.append(pt.maximum(adjusted_drift, 0.1))
        
        threshold = params['final_threshold']
        start_var = params['final_start_var']
        ndt = params['final_ndt']
        noise = params['final_noise']
        
        decision_time = pt.maximum(rt - ndt, 0.01)
        
        return self._four_choice_lba_likelihood_core(choices, decision_time, adjusted_drifts, 
                                                   threshold, start_var, noise)
    
    def _lba_likelihood_core(self, t, v_winner, v_loser, threshold, start_var, noise):
        """LBA ä¼¼ç„¶è¨ˆç®—æ ¸å¿ƒ"""
        
        from pytensor.tensor import erf
        
        sqrt_t = pt.sqrt(t)
        
        def safe_normal_cdf(x):
            return 0.5 * (1 + erf(pt.clip(x, -4.5, 4.5) / pt.sqrt(2)))
        
        def safe_normal_pdf(x):
            x_safe = pt.clip(x, -4.5, 4.5)
            return pt.exp(-0.5 * x_safe**2) / pt.sqrt(2 * pt.pi)
        
        # Winner è¨ˆç®—
        z1_winner = (v_winner * t - threshold) / (noise * sqrt_t)
        z2_winner = (v_winner * t - start_var) / (noise * sqrt_t)
        
        winner_cdf = safe_normal_cdf(z1_winner) - safe_normal_cdf(z2_winner)
        winner_pdf = (safe_normal_pdf(z1_winner) - safe_normal_pdf(z2_winner)) / (noise * sqrt_t)
        
        winner_likelihood = pt.maximum(
            (v_winner / start_var) * pt.maximum(winner_cdf, 1e-10) + winner_pdf / start_var,
            1e-10
        )
        
        # Loser å­˜æ´»
        z1_loser = (v_loser * t - threshold) / (noise * sqrt_t)
        loser_survival = pt.maximum(1 - safe_normal_cdf(z1_loser), 1e-10)
        
        # è¯åˆä¼¼ç„¶
        joint_likelihood = winner_likelihood * loser_survival
        log_likelihood = pt.log(pt.maximum(joint_likelihood, 1e-12))
        
        return pt.sum(pt.clip(log_likelihood, -100.0, 10.0))
    
    def _four_choice_lba_likelihood_core(self, choices, t, drifts, threshold, start_var, noise):
        """å››é¸é … LBA ä¼¼ç„¶æ ¸å¿ƒ"""
        
        from pytensor.tensor import erf
        
        def safe_normal_cdf(x):
            return 0.5 * (1 + erf(pt.clip(x, -4.5, 4.5) / pt.sqrt(2)))
        
        sqrt_t = pt.sqrt(t)
        
        # è¨ˆç®—æ¯å€‹é¸é …çš„å¯†åº¦å’Œå­˜æ´»å‡½æ•¸
        densities = []
        survivals = []
        
        for drift in drifts:
            # å¯†åº¦è¨ˆç®—
            z1 = (drift * t - threshold) / (noise * sqrt_t)
            z2 = (drift * t - start_var) / (noise * sqrt_t)
            
            density = pt.maximum(
                (drift / start_var) * pt.maximum(safe_normal_cdf(z1) - safe_normal_cdf(z2), 1e-10),
                1e-10
            )
            densities.append(density)
            
            # å­˜æ´»è¨ˆç®—
            survival = pt.maximum(1 - safe_normal_cdf(z1), 1e-10)
            survivals.append(survival)
        
        # è¨ˆç®—æ¯å€‹é¸é …çš„å®Œæ•´ä¼¼ç„¶
        trial_likelihoods = pt.zeros_like(t)
        for i in range(4):
            # Winner density Ã— All other survivals
            likelihood_i = densities[i]
            for j in range(4):
                if i != j:
                    likelihood_i = likelihood_i * survivals[j]
            
            # æ ¹æ“šå¯¦éš›é¸æ“‡ç´¯åŠ 
            mask = pt.eq(choices, i)
            trial_likelihoods = trial_likelihoods + mask * likelihood_i
        
        # è¿”å›å°æ•¸ä¼¼ç„¶
        log_likelihood = pt.log(pt.maximum(trial_likelihoods, 1e-12))
        return pt.sum(pt.clip(log_likelihood, -100.0, 10.0))

class GRTModelComparator:
    """GRT æ¨¡å‹æ¯”è¼ƒå™¨"""
    
    def __init__(self, mcmc_config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹æ¯”è¼ƒå™¨
        
        Args:
            mcmc_config: MCMC é…ç½®å­—å…¸
        """
        self.mcmc_config = mcmc_config or {
            'draws': 500,
            'tune': 500,
            'chains': 2,
            'cores': 1,
            'target_accept': 0.85,
            'max_treedepth': 8,
            'random_seed': 42,
            'progressbar': True,
            'return_inferencedata': True
        }
        
        print("ğŸ† åˆå§‹åŒ– GRT æ¨¡å‹æ¯”è¼ƒå™¨")
        print(f"   MCMC è¨­å®š: {self.mcmc_config['draws']} draws Ã— {self.mcmc_config['chains']} chains")
    
    def fit_and_compare_models(self, subject_data: Dict, verbose: bool = True) -> Dict:
        """
        æ“¬åˆå…©å€‹æ¨¡å‹ä¸¦é€²è¡Œæ¯”è¼ƒ
        
        Args:
            subject_data: å—è©¦è€…è³‡æ–™
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°ä¿¡æ¯
            
        Returns:
            å®Œæ•´æ¯”è¼ƒçµæœå­—å…¸
        """
        
        if verbose:
            print(f"\nğŸ¯ æ¨¡å‹æ¯”è¼ƒåˆ†æ")
            print(f"   å—è©¦è€…: {subject_data['subject_id']}")
            print(f"   è©¦é©—æ•¸: {subject_data['n_trials']}")
            print("="*60)
        
        results = {}
        
        # 1. æ“¬åˆ Parallel AND æ¨¡å‹
        if verbose:
            print("\nğŸ“Š æ“¬åˆ Parallel AND æ¨¡å‹...")
        
        parallel_result = self._fit_single_model(
            ModelType.PARALLEL_AND, subject_data, verbose
        )
        results['parallel_and'] = parallel_result
        
        # 2. æ“¬åˆ Coactive æ¨¡å‹
        if verbose:
            print("\nğŸ“Š æ“¬åˆ Coactive æ¨¡å‹...")
        
        coactive_result = self._fit_single_model(
            ModelType.COACTIVE, subject_data, verbose
        )
        results['coactive'] = coactive_result
        
        # 3. é€²è¡Œæ¨¡å‹æ¯”è¼ƒ
        if verbose:
            print("\nğŸ† æ¨¡å‹æ¯”è¼ƒåˆ†æ...")
        
        comparison = self._compare_model_results(parallel_result, coactive_result, verbose)
        results['comparison'] = comparison
        
        # 4. ç”Ÿæˆæ¯”è¼ƒæ‘˜è¦
        if verbose:
            self._print_comparison_summary(results)
        
        return results
    
    def _fit_single_model(self, model_type: ModelType, subject_data: Dict, verbose: bool) -> ModelComparisonResult:
        """æ“¬åˆå–®ä¸€æ¨¡å‹"""
        
        start_time = time.time()
        
        try:
            # å»ºæ§‹æ¨¡å‹
            builder = GRTModelBuilder(model_type)
            model = builder.build_model(subject_data)
            
            # æ¨¡å‹é©—è­‰
            with model:
                test_point = model.initial_point()
                initial_logp = model.compile_logp()(test_point)
                
                if not np.isfinite(initial_logp):
                    raise ValueError(f"Invalid initial log probability: {initial_logp}")
            
            if verbose:
                print(f"   âœ… æ¨¡å‹é©—è­‰é€šé (initial_logp = {initial_logp:.2f})")
            
            # MCMC æ¡æ¨£
            with model:
                if verbose:
                    print("   ğŸ² åŸ·è¡Œ MCMC æ¡æ¨£...")
                
                trace = pm.sample(
                    draws=self.mcmc_config['draws'],
                    tune=self.mcmc_config['tune'],
                    chains=self.mcmc_config['chains'],
                    cores=self.mcmc_config['cores'],
                    target_accept=self.mcmc_config['target_accept'],
                    max_treedepth=self.mcmc_config['max_treedepth'],
                    random_seed=self.mcmc_config['random_seed'],
                    progressbar=self.mcmc_config['progressbar'] and verbose,
                    return_inferencedata=self.mcmc_config['return_inferencedata']
                )
            
            sampling_time = time.time() - start_time
            
            # æ”¶æ–‚è¨ºæ–·
            convergence_success = self._check_convergence(trace, verbose)
            
            # æ¨¡å‹è©•ä¼°æŒ‡æ¨™
            evaluation_metrics = self._compute_evaluation_metrics(trace, model, verbose)
            
            if verbose:
                print(f"   â±ï¸ æ¡æ¨£æ™‚é–“: {sampling_time/60:.1f} åˆ†é˜")
                print(f"   ğŸ”„ æ”¶æ–‚ç‹€æ…‹: {'æˆåŠŸ' if convergence_success else 'è­¦å‘Š'}")
            
            return ModelComparisonResult(
                model_type=model_type,
                waic=evaluation_metrics['waic'],
                waic_se=evaluation_metrics['waic_se'],
                loo=evaluation_metrics['loo'],
                loo_se=evaluation_metrics['loo_se'],
                bic=evaluation_metrics['bic'],
                marginal_likelihood=evaluation_metrics['marginal_likelihood'],
                n_parameters=len(builder.param_names),
                convergence_success=convergence_success,
                sampling_time=sampling_time
            )
            
        except Exception as e:
            if verbose:
                print(f"   âŒ æ¨¡å‹æ“¬åˆå¤±æ•—: {e}")
            
            return ModelComparisonResult(
                model_type=model_type,
                waic=np.inf,
                waic_se=np.inf,
                loo=np.inf,
                loo_se=np.inf,
                bic=np.inf,
                marginal_likelihood=-np.inf,
                n_parameters=len(GRTModelBuilder(model_type).param_names),
                convergence_success=False,
                sampling_time=time.time() - start_time
            )
    
    def _check_convergence(self, trace, verbose: bool) -> bool:
        """æª¢æŸ¥æ”¶æ–‚ç‹€æ…‹"""
        
        try:
            # R-hat çµ±è¨ˆ
            rhat = az.rhat(trace)
            max_rhat = float(rhat.to_array().max())
            
            # ESS çµ±è¨ˆ
            ess_bulk = az.ess(trace)
            min_ess = float(ess_bulk.to_array().min())
            
            # æ”¶æ–‚æ¨™æº–
            rhat_ok = max_rhat <= 1.05
            ess_ok = min_ess >= 100
            
            convergence_success = rhat_ok and ess_ok
            
            if verbose:
                print(f"      RÌ‚_max = {max_rhat:.3f}")
                print(f"      ESS_min = {min_ess:.0f}")
            
            return convergence_success
            
        except Exception as e:
            if verbose:
                print(f"      âš ï¸ æ”¶æ–‚æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _compute_evaluation_metrics(self, trace, model, verbose: bool) -> Dict:
        """è¨ˆç®—æ¨¡å‹è©•ä¼°æŒ‡æ¨™"""
        
        metrics = {
            'waic': np.inf,
            'waic_se': np.inf,
            'loo': np.inf,
            'loo_se': np.inf,
            'bic': np.inf,
            'marginal_likelihood': -np.inf
        }
        
        try:
            # WAIC (Widely Applicable Information Criterion)
            waic_result = az.waic(trace)
            metrics['waic'] = float(waic_result.waic)
            metrics['waic_se'] = float(waic_result.se)
            
            if verbose:
                print(f"      WAIC = {metrics['waic']:.2f} Â± {metrics['waic_se']:.2f}")
            
        except Exception as e:
            if verbose:
                print(f"      âš ï¸ WAIC è¨ˆç®—å¤±æ•—: {e}")
        
        try:
            # LOO (Leave-One-Out Cross-Validation)
            loo_result = az.loo(trace)
            metrics['loo'] = float(loo_result.loo)
            metrics['loo_se'] = float(loo_result.se)
            
            if verbose:
                print(f"      LOO = {metrics['loo']:.2f} Â± {metrics['loo_se']:.2f}")
            
        except Exception as e:
            if verbose:
                print(f"      âš ï¸ LOO è¨ˆç®—å¤±æ•—: {e}")
        
        try:
            # BIC ä¼°ç®— (åŸºæ–¼å¾Œé©—å‡å€¼)
            log_likelihood_samples = trace.log_likelihood.values if hasattr(trace, 'log_likelihood') else None
            if log_likelihood_samples is not None:
                mean_log_likelihood = np.mean(log_likelihood_samples)
                n_params = len(trace.posterior.data_vars)
                n_obs = log_likelihood_samples.shape[-1]  # å‡è¨­æœ€å¾Œä¸€ç¶­æ˜¯è§€å¯Ÿæ•¸
                
                metrics['bic'] = -2 * mean_log_likelihood + n_params * np.log(n_obs)
                
                if verbose:
                    print(f"      BIC â‰ˆ {metrics['bic']:.2f}")
            
        except Exception as e:
            if verbose:
                print(f"      âš ï¸ BIC è¨ˆç®—å¤±æ•—: {e}")
        
        try:
            # é‚Šéš›ä¼¼ç„¶ä¼°ç®— (åŸºæ–¼ Harmonic Mean Estimator)
            log_likelihood_samples = trace.log_likelihood.values if hasattr(trace, 'log_likelihood') else None
            if log_likelihood_samples is not None:
                # ç°¡åŒ–çš„é‚Šéš›ä¼¼ç„¶ä¼°ç®—
                metrics['marginal_likelihood'] = np.mean(log_likelihood_samples)
                
                if verbose:
                    print(f"      Marginal LL â‰ˆ {metrics['marginal_likelihood']:.2f}")
            
        except Exception as e:
            if verbose:
                print(f"      âš ï¸ é‚Šéš›ä¼¼ç„¶è¨ˆç®—å¤±æ•—: {e}")
        
        return metrics
    
    def _compare_model_results(self, parallel_result: ModelComparisonResult, 
                              coactive_result: ModelComparisonResult, verbose: bool) -> Dict:
        """æ¯”è¼ƒå…©å€‹æ¨¡å‹çš„çµæœ"""
        
        comparison = {}
        
        # 1. WAIC æ¯”è¼ƒ
        if np.isfinite(parallel_result.waic) and np.isfinite(coactive_result.waic):
            waic_diff = parallel_result.waic - coactive_result.waic
            waic_se_diff = np.sqrt(parallel_result.waic_se**2 + coactive_result.waic_se**2)
            
            comparison['waic'] = {
                'parallel_and': parallel_result.waic,
                'coactive': coactive_result.waic,
                'difference': waic_diff,
                'se_difference': waic_se_diff,
                'better_model': 'coactive' if waic_diff > 0 else 'parallel_and',
                'significant': abs(waic_diff) > 2 * waic_se_diff
            }
        
        # 2. LOO æ¯”è¼ƒ
        if np.isfinite(parallel_result.loo) and np.isfinite(coactive_result.loo):
            loo_diff = parallel_result.loo - coactive_result.loo
            loo_se_diff = np.sqrt(parallel_result.loo_se**2 + coactive_result.loo_se**2)
            
            comparison['loo'] = {
                'parallel_and': parallel_result.loo,
                'coactive': coactive_result.loo,
                'difference': loo_diff,
                'se_difference': loo_se_diff,
                'better_model': 'coactive' if loo_diff > 0 else 'parallel_and',
                'significant': abs(loo_diff) > 2 * loo_se_diff
            }
        
        # 3. BIC æ¯”è¼ƒ
        if np.isfinite(parallel_result.bic) and np.isfinite(coactive_result.bic):
            bic_diff = parallel_result.bic - coactive_result.bic
            
            comparison['bic'] = {
                'parallel_and': parallel_result.bic,
                'coactive': coactive_result.bic,
                'difference': bic_diff,
                'better_model': 'coactive' if bic_diff > 0 else 'parallel_and',
                'strength': self._interpret_bic_difference(abs(bic_diff))
            }
        
        # 4. Bayes Factor ä¼°ç®—
        if (np.isfinite(parallel_result.marginal_likelihood) and 
            np.isfinite(coactive_result.marginal_likelihood)):
            
            log_bf = parallel_result.marginal_likelihood - coactive_result.marginal_likelihood
            bf = np.exp(log_bf)
            
            comparison['bayes_factor'] = {
                'log_bayes_factor': log_bf,
                'bayes_factor': bf,
                'evidence_strength': self._interpret_bayes_factor(bf),
                'favored_model': 'parallel_and' if log_bf > 0 else 'coactive'
            }
        
        # 5. æ”¶æ–‚æ¯”è¼ƒ
        comparison['convergence'] = {
            'parallel_and_converged': parallel_result.convergence_success,
            'coactive_converged': coactive_result.convergence_success,
            'both_converged': parallel_result.convergence_success and coactive_result.convergence_success
        }
        
        # 6. è¤‡é›œåº¦æ¯”è¼ƒ
        comparison['complexity'] = {
            'parallel_and_params': parallel_result.n_parameters,
            'coactive_params': coactive_result.n_parameters,
            'parameter_difference': parallel_result.n_parameters - coactive_result.n_parameters
        }
        
        # 7. æ•´é«”å»ºè­°
        comparison['recommendation'] = self._generate_overall_recommendation(comparison, verbose)
        
        return comparison
    
    def _interpret_bic_difference(self, bic_diff: float) -> str:
        """è§£é‡‹ BIC å·®ç•°å¼·åº¦"""
        
        if bic_diff < 2:
            return "weak"
        elif bic_diff < 6:
            return "positive"
        elif bic_diff < 10:
            return "strong"
        else:
            return "very_strong"
    
    def _interpret_bayes_factor(self, bf: float) -> str:
        """è§£é‡‹ Bayes Factor è­‰æ“šå¼·åº¦"""
        
        if bf < 1:
            bf = 1 / bf  # å–å€’æ•¸ä»¥ä¾¿çµ±ä¸€è§£é‡‹
        
        if bf < 3:
            return "anecdotal"
        elif bf < 10:
            return "moderate" 
        elif bf < 30:
            return "strong"
        elif bf < 100:
            return "very_strong"
        else:
            return "extreme"
    
    def _generate_overall_recommendation(self, comparison: Dict, verbose: bool) -> Dict:
        """ç”Ÿæˆæ•´é«”å»ºè­°"""
        
        recommendations = []
        confidence_score = 0
        
        # æª¢æŸ¥æ”¶æ–‚
        if not comparison['convergence']['both_converged']:
            recommendations.append("âš ï¸ éƒ¨åˆ†æ¨¡å‹æ”¶æ–‚å•é¡Œï¼Œçµæœéœ€è¬¹æ…è§£é‡‹")
            confidence_score -= 30
        
        # WAIC å»ºè­°
        if 'waic' in comparison:
            waic_info = comparison['waic']
            if waic_info['significant']:
                recommendations.append(f"ğŸ¯ WAIC æ”¯æŒ {waic_info['better_model']} æ¨¡å‹")
                confidence_score += 25
        
        # LOO å»ºè­°
        if 'loo' in comparison:
            loo_info = comparison['loo']
            if loo_info['significant']:
                recommendations.append(f"ğŸ¯ LOO æ”¯æŒ {loo_info['better_model']} æ¨¡å‹")
                confidence_score += 25
        
        # BIC å»ºè­°
        if 'bic' in comparison:
            bic_info = comparison['bic']
            if bic_info['strength'] in ['strong', 'very_strong']:
                recommendations.append(f"ğŸ¯ BIC å¼·çƒˆæ”¯æŒ {bic_info['better_model']} æ¨¡å‹")
                confidence_score += 30
            elif bic_info['strength'] == 'positive':
                recommendations.append(f"ğŸ¯ BIC æ”¯æŒ {bic_info['better_model']} æ¨¡å‹")
                confidence_score += 15
        
        # Bayes Factor å»ºè­°
        if 'bayes_factor' in comparison:
            bf_info = comparison['bayes_factor']
            if bf_info['evidence_strength'] in ['strong', 'very_strong', 'extreme']:
                recommendations.append(f"ğŸ¯ Bayes Factor å¼·çƒˆæ”¯æŒ {bf_info['favored_model']} æ¨¡å‹")
                confidence_score += 35
        
        # ç¢ºå®šæœ€çµ‚å»ºè­°
        if confidence_score >= 50:
            final_recommendation = "strong_preference"
        elif confidence_score >= 25:
            final_recommendation = "moderate_preference" 
        elif confidence_score >= 0:
            final_recommendation = "weak_preference"
        else:
            final_recommendation = "inconclusive"
        
        return {
            'recommendations': recommendations,
            'confidence_score': confidence_score,
            'final_recommendation': final_recommendation
        }
    
    def _print_comparison_summary(self, results: Dict):
        """æ‰“å°æ¯”è¼ƒæ‘˜è¦"""
        
        print(f"\n{'='*60}")
        print("ğŸ† æ¨¡å‹æ¯”è¼ƒæ‘˜è¦")
        print(f"{'='*60}")
        
        parallel = results['parallel_and']
        coactive = results['coactive']
        comparison = results['comparison']
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"   Parallel AND: {parallel.n_parameters} åƒæ•¸")
        print(f"   Coactive: {coactive.n_parameters} åƒæ•¸")
        print(f"   æ”¶æ–‚ç‹€æ…‹: Parallel={parallel.convergence_success}, Coactive={coactive.convergence_success}")
        
        # æ¨¡å‹é¸æ“‡æŒ‡æ¨™
        print(f"\nğŸ¯ æ¨¡å‹é¸æ“‡æŒ‡æ¨™:")
        
        if 'waic' in comparison:
            waic = comparison['waic']
            print(f"   WAIC: Parallel={waic['parallel_and']:.2f}, Coactive={waic['coactive']:.2f}")
            print(f"         å·®ç•°={waic['difference']:.2f} Â± {waic['se_difference']:.2f}")
            print(f"         å»ºè­°: {waic['better_model']} ({'é¡¯è‘—' if waic['significant'] else 'éé¡¯è‘—'})")
        
        if 'loo' in comparison:
            loo = comparison['loo']
            print(f"   LOO:  Parallel={loo['parallel_and']:.2f}, Coactive={loo['coactive']:.2f}")
            print(f"         å·®ç•°={loo['difference']:.2f} Â± {loo['se_difference']:.2f}")
            print(f"         å»ºè­°: {loo['better_model']} ({'é¡¯è‘—' if loo['significant'] else 'éé¡¯è‘—'})")
        
        if 'bic' in comparison:
            bic = comparison['bic']
            print(f"   BIC:  Parallel={bic['parallel_and']:.2f}, Coactive={bic['coactive']:.2f}")
            print(f"         å·®ç•°={bic['difference']:.2f}")
            print(f"         å»ºè­°: {bic['better_model']} ({bic['strength']} evidence)")
        
        if 'bayes_factor' in comparison:
            bf = comparison['bayes_factor']
            print(f"   Bayes Factor: {bf['bayes_factor']:.2f}")
            print(f"                 æ”¯æŒ: {bf['favored_model']} ({bf['evidence_strength']} evidence)")
        
        # æœ€çµ‚å»ºè­°
        print(f"\nğŸ¯ æœ€çµ‚å»ºè­°:")
        rec = comparison['recommendation']
        for recommendation in rec['recommendations']:
            print(f"   {recommendation}")
        
        print(f"   ä¿¡å¿ƒåˆ†æ•¸: {rec['confidence_score']}")
        print(f"   å»ºè­°å¼·åº¦: {rec['final_recommendation']}")
        
        print(f"\n{'='*60}")

# ä¾¿åˆ©å‡½æ•¸å’Œæ¸¬è©¦
def create_test_subject_data(n_trials: int = 200, seed: int = 42) -> Dict:
    """å‰µå»ºæ¸¬è©¦ç”¨å—è©¦è€…è³‡æ–™"""
    
    np.random.seed(seed)
    
    # ç”Ÿæˆå››é¸é …é¸æ“‡
    choices = np.random.choice([0, 1, 2, 3], size=n_trials, p=[0.3, 0.25, 0.2, 0.25])
    
    # ç”Ÿæˆåæ‡‰æ™‚é–“ï¼ˆåŸºæ–¼é¸æ“‡çš„ä¸åŒåˆ†å¸ƒï¼‰
    rt = np.zeros(n_trials)
    for choice in range(4):
        mask = choices == choice
        rt[mask] = np.random.gamma(2 + choice * 0.3, 0.3, np.sum(mask))
    
    # ç”Ÿæˆå·¦å³é€šé“çš„åˆºæ¿€å’Œé¸æ“‡
    left_stimuli = np.random.choice([0, 1], size=n_trials)
    right_stimuli = np.random.choice([0, 1], size=n_trials)
    
    # åŸºæ–¼åˆºæ¿€ç”Ÿæˆé¸æ“‡ï¼ˆæ·»åŠ ä¸€äº›å™ªéŸ³ï¼‰
    left_choices = np.where(np.random.random(n_trials) < 0.8, left_stimuli, 1 - left_stimuli)
    right_choices = np.where(np.random.random(n_trials) < 0.8, right_stimuli, 1 - right_stimuli)
    
    return {
        'subject_id': 'TEST_001',
        'n_trials': n_trials,
        'choices': choices,
        'rt': rt,
        'left_stimuli': left_stimuli,
        'left_choices': left_choices,
        'right_stimuli': right_stimuli,
        'right_choices': right_choices,
        'accuracy': np.mean(left_choices == left_stimuli) * np.mean(right_choices == right_stimuli)
    }

def quick_model_comparison_test(n_trials: int = 100):
    """å¿«é€Ÿæ¨¡å‹æ¯”è¼ƒæ¸¬è©¦"""
    
    print("ğŸ§ª å¿«é€Ÿæ¨¡å‹æ¯”è¼ƒæ¸¬è©¦")
    print("="*50)
    
    try:
        # å‰µå»ºæ¸¬è©¦è³‡æ–™
        test_data = create_test_subject_data(n_trials)
        print(f"âœ… æ¸¬è©¦è³‡æ–™å‰µå»ºå®Œæˆ: {n_trials} è©¦é©—")
        
        # è¨­å®šç°¡åŒ–çš„ MCMC é…ç½®
        quick_mcmc_config = {
            'draws': 100,
            'tune': 100,
            'chains': 1,
            'cores': 1,
            'target_accept': 0.80,
            'max_treedepth': 6,
            'random_seed': 42,
            'progressbar': True,
            'return_inferencedata': True
        }
        
        # å‰µå»ºæ¯”è¼ƒå™¨
        comparator = GRTModelComparator(quick_mcmc_config)
        
        # åŸ·è¡Œæ¯”è¼ƒ
        results = comparator.fit_and_compare_models(test_data, verbose=True)
        
        print("âœ… æ¨¡å‹æ¯”è¼ƒæ¸¬è©¦å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def full_model_comparison_pipeline(subject_data: Dict, 
                                 mcmc_config: Optional[Dict] = None,
                                 save_results: bool = True) -> Dict:
    """å®Œæ•´çš„æ¨¡å‹æ¯”è¼ƒæµç¨‹"""
    
    print("ğŸš€ GRT å››é¸é …æ¨¡å‹æ¯”è¼ƒæµç¨‹")
    print("="*60)
    
    # å‰µå»ºæ¯”è¼ƒå™¨
    comparator = GRTModelComparator(mcmc_config)
    
    # åŸ·è¡Œæ¯”è¼ƒ
    start_time = time.time()
    results = comparator.fit_and_compare_models(subject_data, verbose=True)
    total_time = time.time() - start_time
    
    # æ·»åŠ æ™‚é–“ä¿¡æ¯
    results['meta'] = {
        'total_analysis_time': total_time,
        'subject_id': subject_data['subject_id'],
        'n_trials': subject_data['n_trials'],
        'mcmc_config': comparator.mcmc_config
    }
    
    # å„²å­˜çµæœ
    if save_results:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"grt_model_comparison_{subject_data['subject_id']}_{timestamp}.pkl"
        
        import pickle
        try:
            with open(filename, 'wb') as f:
                pickle.save(results, f)
            print(f"ğŸ’¾ çµæœå·²å„²å­˜: {filename}")
        except Exception as e:
            print(f"âš ï¸ çµæœå„²å­˜å¤±æ•—: {e}")
    
    print(f"\nâ±ï¸ ç¸½åˆ†ææ™‚é–“: {total_time/60:.1f} åˆ†é˜")
    
    return results

if __name__ == "__main__":
    print("é¸æ“‡æ¸¬è©¦æ¨¡å¼:")
    print("1. å¿«é€Ÿæ¸¬è©¦ (ç°¡åŒ– MCMC)")
    print("2. å®Œæ•´æ¸¬è©¦ (æ¨™æº– MCMC)")
    
    choice = input("è«‹é¸æ“‡ (1 æˆ– 2): ").strip()
    
    if choice == "1":
        success = quick_model_comparison_test(100)
        if success:
            print("\nğŸ‰ å¿«é€Ÿæ¸¬è©¦æˆåŠŸ! æ¨¡å‹æ¯”è¼ƒæ¶æ§‹é‹ä½œæ­£å¸¸ã€‚")
        else:
            print("\nâŒ å¿«é€Ÿæ¸¬è©¦å¤±æ•—ã€‚")
    
    elif choice == "2":
        test_data = create_test_subject_data(200)
        results = full_model_comparison_pipeline(test_data)
        print("\nğŸ‰ å®Œæ•´æ¸¬è©¦å®Œæˆ!")
    
    else:
        print("ç„¡æ•ˆé¸æ“‡ï¼ŒåŸ·è¡Œå¿«é€Ÿæ¸¬è©¦...")
        quick_model_comparison_test(50)
