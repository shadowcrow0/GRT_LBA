# -*- coding: utf-8 -*-
"""
LBA_main_fixed.py - ä¿®å¾©ç‰ˆ LBA åˆ†æä¸»ç¨‹å¼
è§£æ±º loglikelihood è¨ˆç®—å•é¡Œ
"""

import numpy as np
import pandas as pd
import pymc as pm
import arviz as az
import os
import warnings
from datetime import datetime
import argparse

# å°å…¥ä¿®å¾©ç‰ˆå‡½æ•¸
from LBA_loglikelihood_fix import (
    create_fixed_coactive_model, 
    diagnose_loglikelihood_issue,
    create_fixed_lba_logp
)

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings('ignore')

def fixed_sample_with_convergence_check(model, max_attempts=3, draws=300, tune=400, chains=2):
    """
    ä¿®å¾©ç‰ˆæ¡æ¨£å‡½æ•¸ï¼Œå°ˆé–€é‡å° loglikelihood å•é¡Œ
    """
    
    print(f"  é–‹å§‹ä¿®å¾©ç‰ˆæ¡æ¨£ (draws={draws}, tune={tune}, chains={chains})...")
    
    for attempt in range(max_attempts):
        try:
            print(f"    å˜—è©¦ {attempt + 1}/{max_attempts}")
            
            with model:
                # æ›´ç©©å¥çš„æ¡æ¨£ç­–ç•¥
                trace = pm.sample(
                    draws=draws,
                    tune=tune,
                    chains=chains,
                    target_accept=0.85,  # è¼ƒä½çš„æ¥å—ç‡ä»¥æé«˜ç©©å®šæ€§
                    return_inferencedata=True,
                    progressbar=True,
                    random_seed=42 + attempt,
                    init='jitter+adapt_diag',
                    cores=1  # å–®æ ¸å¿ƒé¿å…ä¸¦è¡Œå•é¡Œ
                )
                
                # æª¢æŸ¥æ¡æ¨£çµæœ
                try:
                    summary = az.summary(trace)
                    max_rhat = summary['r_hat'].max() if 'r_hat' in summary.columns else 1.0
                    min_ess = summary['ess_bulk'].min() if 'ess_bulk' in summary.columns else 100
                    
                    print(f"    æœ€å¤§ R-hat: {max_rhat:.4f}")
                    print(f"    æœ€å° ESS: {min_ess:.0f}")
                    
                    # è¼ƒå¯¬é¬†çš„æ”¶æ–‚æ¨™æº–
                    if max_rhat < 1.3 and min_ess > 30:
                        print(f"    âœ“ æ”¶æ–‚æˆåŠŸ")
                        
                        # æª¢æŸ¥ä¸¦ä¿®å¾© log_likelihood
                        trace_fixed = ensure_log_likelihood(trace)
                        
                        return trace_fixed, {
                            'max_rhat': max_rhat, 
                            'min_ess': min_ess,
                            'attempt': attempt + 1
                        }
                    else:
                        print(f"    âš ï¸ æ”¶æ–‚æ¨™æº–æœªé”æˆï¼Œä½†è¿”å›çµæœ...")
                        if attempt == max_attempts - 1:
                            trace_fixed = ensure_log_likelihood(trace)
                            return trace_fixed, {
                                'max_rhat': max_rhat, 
                                'min_ess': min_ess,
                                'attempt': attempt + 1
                            }
                        
                except Exception as diag_error:
                    print(f"    âš ï¸ è¨ºæ–·å¤±æ•—ä½†æ¡æ¨£å®Œæˆ: {diag_error}")
                    if trace is not None:
                        trace_fixed = ensure_log_likelihood(trace)
                        return trace_fixed, {'max_rhat': np.nan, 'min_ess': np.nan}
                
        except Exception as e:
            print(f"    âŒ æ¡æ¨£å¤±æ•—: {e}")
            if attempt < max_attempts - 1:
                # èª¿æ•´åƒæ•¸é‡è©¦
                draws = max(100, int(draws * 0.8))
                tune = max(200, int(tune * 0.9))
                print(f"    èª¿æ•´åƒæ•¸é‡è©¦: draws={draws}, tune={tune}")
    
    print(f"    âŒ {max_attempts} æ¬¡å˜—è©¦å¾Œä»æœªæˆåŠŸ")
    return None, None

def ensure_log_likelihood(trace):
    """
    ç¢ºä¿ trace åŒ…å«æ­£ç¢ºçš„ log_likelihood ç”¨æ–¼æ¨¡å‹æ¯”è¼ƒ
    """
    try:
        if hasattr(trace, 'log_likelihood'):
            print("    âœ“ trace å·²åŒ…å« log_likelihood")
            return trace
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ‰‹å‹•è¨ˆç®—çš„ log_likelihood
        if 'log_likelihood_values' in trace.posterior:
            print("    ğŸ”§ å¾æ‰‹å‹•è¨ˆç®—å‰µå»º log_likelihood...")
            
            import xarray as xr
            
            # å‰µå»º log_likelihood æ•¸æ“šé›†
            log_likelihood = xr.Dataset({
                'likelihood': trace.posterior['log_likelihood_values']
            })
            
            # å°‡å…¶æ·»åŠ åˆ° trace
            trace_fixed = trace.assign(log_likelihood=log_likelihood)
            print("    âœ“ log_likelihood å‰µå»ºæˆåŠŸ")
            return trace_fixed
        else:
            print("    âš ï¸ ç„¡æ³•æ‰¾åˆ° log_likelihood æ•¸æ“š")
            return trace
            
    except Exception as e:
        print(f"    âŒ log_likelihood ä¿®å¾©å¤±æ•—: {e}")
        return trace

def improved_model_comparison(models):
    """
    æ”¹é€²ç‰ˆæ¨¡å‹æ¯”è¼ƒï¼Œå°ˆé–€è™•ç† loglikelihood å•é¡Œ
    """
    print("ğŸ”¬ åŸ·è¡Œæ”¹é€²ç‰ˆæ¨¡å‹æ¯”è¼ƒ...")
    
    if len(models) < 2:
        print("éœ€è¦è‡³å°‘ 2 å€‹æ¨¡å‹é€²è¡Œæ¯”è¼ƒ")
        return None
    
    # æª¢æŸ¥æ¯å€‹æ¨¡å‹çš„ log_likelihood
    valid_models = {}
    model_scores = {}
    
    for model_name, trace in models.items():
        print(f"  æª¢æŸ¥ {model_name}...")
        
        try:
            # æ–¹æ³• 1: å˜—è©¦ WAIC/LOO
            if hasattr(trace, 'log_likelihood'):
                try:
                    ll_values = trace.log_likelihood.likelihood.values
                    if not np.any(np.isnan(ll_values)) and not np.any(np.isinf(ll_values)):
                        valid_models[model_name] = trace
                        model_scores[model_name] = np.mean(ll_values)
                        print(f"    âœ“ {model_name}: æœ‰æ•ˆçš„ log_likelihood")
                        continue
                except:
                    pass
            
            # æ–¹æ³• 2: ä½¿ç”¨æ‰‹å‹•è¨ˆç®—çš„ log_likelihood
            if 'log_likelihood_values' in trace.posterior:
                try:
                    ll_values = trace.posterior['log_likelihood_values'].values.flatten()
                    ll_clean = ll_values[np.isfinite(ll_values)]
                    if len(ll_clean) > 0:
                        model_scores[model_name] = np.mean(ll_clean)
                        print(f"    âœ“ {model_name}: ä½¿ç”¨æ‰‹å‹• log_likelihood")
                        continue
                except:
                    pass
            
            # æ–¹æ³• 3: åŸºæ–¼æ”¶æ–‚æ€§è©•åˆ†
            try:
                summary = az.summary(trace)
                max_rhat = summary['r_hat'].max() if 'r_hat' in summary.columns else 1.0
                min_ess = summary['ess_bulk'].min() if 'ess_bulk' in summary.columns else 100
                
                # æ”¶æ–‚è©•åˆ†
                score = min_ess / max(max_rhat - 1.0, 0.01)
                model_scores[model_name] = score
                print(f"    ~ {model_name}: æ”¶æ–‚è©•åˆ† = {score:.2f}")
            except:
                model_scores[model_name] = 0
                print(f"    âŒ {model_name}: ç„¡æ³•è©•åˆ†")
                
        except Exception as e:
            print(f"    âŒ {model_name}: è©•ä¼°å¤±æ•— - {e}")
            model_scores[model_name] = 0
    
    # å˜—è©¦æ¨™æº– WAIC æ¯”è¼ƒ
    if len(valid_models) >= 2:
        try:
            print("  å˜—è©¦ WAIC æ¯”è¼ƒ...")
            comparison_result = az.compare(valid_models, ic='waic')
            winner = comparison_result.index[0]
            
            print(f"    âœ… WAIC æˆåŠŸï¼ç²å‹è€…: {winner}")
            
            return {
                'winner': winner,
                'method': 'WAIC',
                'comparison_table': comparison_result,
                'model_scores': model_scores,
                'success': True
            }
        except Exception as e:
            print(f"    âŒ WAIC å¤±æ•—: {e}")
    
    # å‚™ç”¨ï¼šåŸºæ–¼è©•åˆ†çš„æ¯”è¼ƒ
    if model_scores:
        winner = max(model_scores, key=model_scores.get)
        winner_score = model_scores[winner]
        
        print(f"    ğŸ† è©•åˆ†ç²å‹è€…: {winner} (è©•åˆ†: {winner_score:.2f})")
        
        return {
            'winner': winner,
            'method': 'Score_Based',
            'model_scores': model_scores,
            'success': True
        }
    else:
        # æœ€å¾Œæ‰‹æ®µ
        winner = list(models.keys())[0]
        return {
            'winner': winner,
            'method': 'Default',
            'success': False
        }

class FixedLBAAnalysisRunner:
    """ä¿®å¾©ç‰ˆ LBA åˆ†æé‹è¡Œå™¨"""
    
    def __init__(self, data_file='model_data.npz', output_base_dir='lba_fixed_results'):
        self.data_file = data_file
        self.output_base_dir = output_base_dir
        self.results_dir = None
        self.data = None
        self.participants = None
        
    def setup_analysis(self):
        """è¨­ç½®åˆ†æç’°å¢ƒ"""
        
        print("ğŸ”§ è¨­ç½®ä¿®å¾©ç‰ˆ LBA åˆ†æç’°å¢ƒ...")
        
        # è¨ºæ–·æ•¸æ“šå•é¡Œ
        issues = diagnose_loglikelihood_issue(self.data_file)
        if issues:
            print("ç™¼ç¾æ•¸æ“šå•é¡Œï¼Œå˜—è©¦ä½¿ç”¨ä¿®å¾©ç‰ˆæ•¸æ“š...")
            fixed_file = self.data_file.replace('.npz', '_fixed.npz')
            if os.path.exists(fixed_file):
                self.data_file = fixed_file
                print(f"åˆ‡æ›åˆ°ä¿®å¾©ç‰ˆæ•¸æ“š: {fixed_file}")
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results_dir = f"{self.output_base_dir}_{timestamp}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è¼‰å…¥æ•¸æ“š
        try:
            self.data = np.load(self.data_file, allow_pickle=True)
            observed_value = self.data['observed_value']
            participant_idx = self.data['participant_idx']
            
            self.participants = np.unique(participant_idx)
            
            print(f"âœ“ ä¿®å¾©ç‰ˆæ•¸æ“šè¼‰å…¥æˆåŠŸ")
            print(f"âœ“ åƒèˆ‡è€…æ•¸: {len(self.participants)}")
            print(f"âœ“ ç¸½è©¦é©—æ•¸: {len(observed_value)}")
            print(f"âœ“ RT ç¯„åœ: {observed_value[:, 0].min():.1f} - {observed_value[:, 0].max():.1f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def run_single_participant_analysis(self, participant_id):
        """é‹è¡Œå–®å€‹åƒèˆ‡è€…åˆ†æ"""
        
        print(f"\nğŸ§  åˆ†æåƒèˆ‡è€… {participant_id} (ä¿®å¾©ç‰ˆ)")
        print("-" * 50)
        
        # æå–åƒèˆ‡è€…æ•¸æ“š
        observed_value = self.data['observed_value']
        participant_idx = self.data['participant_idx']
        model_input_data = self.data['model_input_data'].item()
        
        mask = participant_idx == participant_id
        participant_data = observed_value[mask]
        participant_input = {
            'left_match': model_input_data['left_match'][mask],
            'right_match': model_input_data['right_match'][mask]
        }
        
        print(f"è©¦é©—æ•¸: {len(participant_data)}")
        print(f"å¹³å‡ RT: {participant_data[:, 0].mean():.1f} ms")
        print(f"æº–ç¢ºç‡: {participant_data[:, 1].mean():.3f}")
        
        # å‰µå»ºä¸¦æ“¬åˆæ¨¡å‹
        try:
            print("\nğŸ“Š å‰µå»ºä¿®å¾©ç‰ˆ Coactive æ¨¡å‹...")
            model = create_fixed_coactive_model(participant_data, participant_input)
            
            # æ¡æ¨£
            print("ğŸ”„ é–‹å§‹æ¡æ¨£...")
            trace, diagnostics = fixed_sample_with_convergence_check(
                model, 
                max_attempts=3,
                draws=400,
                tune=500,
                chains=2
            )
            
            if trace is not None:
                print("âœ… æ¨¡å‹æ“¬åˆæˆåŠŸ")
                
                # ä¿å­˜çµæœ
                self.save_participant_results(participant_id, trace, diagnostics)
                
                # æ¸¬è©¦æ¨¡å‹æ¯”è¼ƒåŠŸèƒ½
                models = {'Coactive_Fixed': trace}
                comparison = improved_model_comparison(models)
                
                return {
                    'participant': participant_id,
                    'trace': trace,
                    'diagnostics': diagnostics,
                    'comparison': comparison,
                    'success': True
                }
            else:
                print("âŒ æ¨¡å‹æ“¬åˆå¤±æ•—")
                return {
                    'participant': participant_id,
                    'success': False,
                    'error': 'Sampling failed'
                }
                
        except Exception as e:
            print(f"âŒ åˆ†æå¤±æ•—: {e}")
            return {
                'participant': participant_id,
                'success': False,
                'error': str(e)
            }
    
    def save_participant_results(self, participant_id, trace, diagnostics):
        """ä¿å­˜åƒèˆ‡è€…çµæœ"""
        
        try:
            # ä¿å­˜ trace
            trace_file = os.path.join(self.results_dir, f'participant_{participant_id}_trace.nc')
            trace.to_netcdf(trace_file)
            
            # å‰µå»ºæ‘˜è¦å ±å‘Š
            summary_file = os.path.join(self.results_dir, f'participant_{participant_id}_summary.txt')
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(f"åƒèˆ‡è€… {participant_id} åˆ†æçµæœ\n")
                f.write("=" * 40 + "\n\n")
                
                # åŸºæœ¬ä¿¡æ¯
                f.write("æ¨¡å‹ä¿¡æ¯:\n")
                f.write("- æ¨¡å‹é¡å‹: ä¿®å¾©ç‰ˆ Coactive LBA\n")
                f.write(f"- æ¡æ¨£æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                # æ”¶æ–‚è¨ºæ–·
                if diagnostics:
                    f.write("æ”¶æ–‚è¨ºæ–·:\n")
                    f.write(f"- æœ€å¤§ R-hat: {diagnostics.get('max_rhat', 'N/A')}\n")
                    f.write(f"- æœ€å° ESS: {diagnostics.get('min_ess', 'N/A')}\n")
                    f.write(f"- æ¡æ¨£å˜—è©¦: {diagnostics.get('attempt', 'N/A')}\n\n")
                
                # åƒæ•¸ä¼°è¨ˆ
                try:
                    summary = az.summary(trace)
                    f.write("åƒæ•¸ä¼°è¨ˆ:\n")
                    f.write(summary.to_string())
                    f.write("\n\n")
                except:
                    f.write("åƒæ•¸ä¼°è¨ˆ: ç„¡æ³•ç”Ÿæˆ\n\n")
                
                # Log-likelihood æª¢æŸ¥
                if hasattr(trace, 'log_likelihood'):
                    f.write("âœ“ Log-likelihood: æ­£å¸¸\n")
                elif 'log_likelihood_values' in trace.posterior:
                    f.write("âœ“ Log-likelihood: æ‰‹å‹•è¨ˆç®—\n")
                else:
                    f.write("âŒ Log-likelihood: ç¼ºå¤±\n")
            
            print(f"    âœ“ çµæœå·²ä¿å­˜: {summary_file}")
            
        except Exception as e:
            print(f"    âŒ ä¿å­˜çµæœå¤±æ•—: {e}")

def main():
    """ä¸»ç¨‹åº"""
    
    parser = argparse.ArgumentParser(description='ä¿®å¾©ç‰ˆ LBA åˆ†æç¨‹å¼')
    parser.add_argument('--participant', type=str, help='åˆ†æç‰¹å®šåƒèˆ‡è€…')
    parser.add_argument('--data-file', default='model_data.npz', help='æ•¸æ“šæª”æ¡ˆ')
    parser.add_argument('--test', action='store_true', help='åŸ·è¡Œæ¸¬è©¦æ¨¡å¼')
    
    args = parser.parse_args()
    
    print("ğŸ§  ä¿®å¾©ç‰ˆ LBA åˆ†æç¨‹å¼")
    print("=" * 50)
    print("å°ˆé–€è§£æ±º loglikelihood è¨ˆç®—å•é¡Œ")
    
    # å‰µå»ºåˆ†æå™¨
    runner = FixedLBAAnalysisRunner(data_file=args.data_file)
    
    # è¨­ç½®ç’°å¢ƒ
    if not runner.setup_analysis():
        print("âŒ ç’°å¢ƒè¨­ç½®å¤±æ•—")
        return
    
    if args.test:
        # æ¸¬è©¦æ¨¡å¼
        print("\nğŸ§ª åŸ·è¡Œæ¸¬è©¦æ¨¡å¼...")
        if len(runner.participants) > 0:
            test_participant = runner.participants[0]
            result = runner.run_single_participant_analysis(test_participant)
            
            if result['success']:
                print(f"\nâœ… æ¸¬è©¦æˆåŠŸï¼åƒèˆ‡è€… {test_participant}")
                print(f"ğŸ“ çµæœä¿å­˜æ–¼: {runner.results_dir}")
            else:
                print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    elif args.participant:
        # å–®å€‹åƒèˆ‡è€…æ¨¡å¼
        if args.participant in runner.participants.astype(str):
            result = runner.run_single_participant_analysis(args.participant)
            
            if result['success']:
                print(f"\nâœ… åˆ†æå®Œæˆï¼åƒèˆ‡è€… {args.participant}")
            else:
                print(f"\nâŒ åˆ†æå¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°åƒèˆ‡è€… {args.participant}")
            print(f"å¯ç”¨åƒèˆ‡è€…: {runner.participants[:10]}...")
    
    else:
        # é¡¯ç¤ºä½¿ç”¨èªªæ˜
        print("\nä½¿ç”¨æ–¹å¼:")
        print("  python LBA_main_fixed.py --test                    # æ¸¬è©¦æ¨¡å¼")
        print("  python LBA_main_fixed.py --participant ID         # åˆ†æç‰¹å®šåƒèˆ‡è€…")
        print("  python LBA_main_fixed.py --data-file file.npz     # æŒ‡å®šæ•¸æ“šæª”æ¡ˆ")
        print(f"\nå¯ç”¨åƒèˆ‡è€…: {runner.participants[:5]}...")

if __name__ == '__main__':
    main()