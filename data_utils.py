# -*- coding: utf-8 -*-
"""
data_utils.py - è³‡æ–™é è™•ç†æ¨¡çµ„
Sequential Processing LBA - Data Utilities Module

åŠŸèƒ½ï¼š
- è¼‰å…¥å’Œæ¸…ç†å¯¦é©—è³‡æ–™
- å°‡4é¸æ“‡è³‡æ–™åˆ†è§£ç‚ºå·¦å³é€šé“ç‰¹å¾µ
- æå–å–®ä¸€å—è©¦è€…è³‡æ–™
- è³‡æ–™å“è³ªæª¢æŸ¥
"""

import numpy as np
import pandas as pd
from typing import Dict, Tuple, List

class DataProcessor:
    """è³‡æ–™é è™•ç†å™¨"""
    
    def __init__(self):
        # åˆºæ¿€æ˜ å°„ï¼šåˆºæ¿€ç·¨è™Ÿ -> å·¦å³ç·šæ¢æ–¹å‘
        self.stimulus_mapping = {
            0: {'left': 1, 'right': 0},  # å·¦å°è§’ï¼Œå³å‚ç›´
            1: {'left': 1, 'right': 1},  # å·¦å°è§’ï¼Œå³å°è§’
            2: {'left': 0, 'right': 0},  # å·¦å‚ç›´ï¼Œå³å‚ç›´
            3: {'left': 0, 'right': 1}   # å·¦å‚ç›´ï¼Œå³å°è§’
        }
        
        # é¸æ“‡æ˜ å°„ï¼šé¸æ“‡ç·¨è™Ÿ -> å·¦å³åˆ¤æ–·
        self.choice_mapping = {
            0: {'left': 1, 'right': 0},  # é¸æ“‡ \|
            1: {'left': 1, 'right': 1},  # é¸æ“‡ \/
            2: {'left': 0, 'right': 0},  # é¸æ“‡ ||
            3: {'left': 0, 'right': 1}   # é¸æ“‡ |/
        }
        
        # æè¿°æ˜ å°„
        self.stimulus_descriptions = {
            0: 'Left\\Right|',   # å·¦å°è§’å³å‚ç›´
            1: 'Left\\Right/',   # å·¦å°è§’å³å°è§’
            2: 'Left|Right|',    # å·¦å‚ç›´å³å‚ç›´
            3: 'Left|Right/'     # å·¦å‚ç›´å³å°è§’
        }
    
    def load_and_clean_data(self, csv_file: str) -> pd.DataFrame:
        """è¼‰å…¥ä¸¦æ¸…ç†å¯¦é©—è³‡æ–™"""
        
        print("ğŸ“‚ è¼‰å…¥å¯¦é©—è³‡æ–™...")
        
        try:
            # è¼‰å…¥åŸå§‹è³‡æ–™
            raw_df = pd.read_csv(csv_file, encoding='utf-8')
            print(f"âœ… è¼‰å…¥ {len(raw_df)} å€‹è©¦é©—")
            
            # åŸºæœ¬è³‡æ–™æ¸…ç†
            print("ğŸ”„ åŸ·è¡Œè³‡æ–™æ¸…ç†...")
            
            # RTç¯„åœæª¢æŸ¥
            valid_rt = (raw_df['RT'] >= 0.1) & (raw_df['RT'] <= 3.0)
            
            # é¸æ“‡æœ‰æ•ˆæ€§æª¢æŸ¥
            valid_choice = raw_df['Response'].isin([0, 1, 2, 3])
            
            # åˆºæ¿€æœ‰æ•ˆæ€§æª¢æŸ¥
            valid_stimulus = raw_df['Stimulus'].isin([0, 1, 2, 3])
            
            # çµ„åˆæ‰€æœ‰æœ‰æ•ˆæ¢ä»¶
            valid_trials = valid_rt & valid_choice & valid_stimulus
            
            # éæ¿¾è³‡æ–™
            clean_df = raw_df[valid_trials].copy()
            
            # ç§»é™¤ç¼ºå¤±å€¼
            clean_df = clean_df.dropna(subset=['Response', 'RT', 'Stimulus', 'participant'])
            
            print(f"âœ… è³‡æ–™æ¸…ç†å®Œæˆ:")
            print(f"   åŸå§‹: {len(raw_df)} è©¦é©—")
            print(f"   æ¸…ç†å¾Œ: {len(clean_df)} è©¦é©—")
            print(f"   ä¿ç•™ç‡: {len(clean_df)/len(raw_df)*100:.1f}%")
            print(f"   å—è©¦è€…æ•¸: {clean_df['participant'].nunique()}")
            
            # æ·»åŠ åˆ†è§£ç‰¹å¾µ
            clean_df = self.add_decomposed_features(clean_df)
            
            # é¡¯ç¤ºåˆºæ¿€åˆ†å¸ƒ
            self.print_stimulus_distribution(clean_df)
            
            return clean_df
            
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {csv_file}")
            raise
        except Exception as e:
            print(f"âŒ è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def add_decomposed_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ åˆ†è§£çš„å·¦å³é€šé“ç‰¹å¾µ"""
        
        print("ğŸ”„ æ·»åŠ å·¦å³é€šé“ç‰¹å¾µ...")
        
        df = df.copy()
        
        # åˆºæ¿€ç‰¹å¾µåˆ†è§£
        df['left_stimulus'] = df['Stimulus'].map(
            lambda x: self.stimulus_mapping.get(x, {'left': 0})['left']
        )
        df['right_stimulus'] = df['Stimulus'].map(
            lambda x: self.stimulus_mapping.get(x, {'right': 0})['right']
        )
        
        # é¸æ“‡ç‰¹å¾µåˆ†è§£
        df['left_choice'] = df['Response'].map(
            lambda x: self.choice_mapping.get(x, {'left': 0})['left']
        )
        df['right_choice'] = df['Response'].map(
            lambda x: self.choice_mapping.get(x, {'right': 0})['right']
        )
        
        # è¨ˆç®—å·¦å³é€šé“æ­£ç¢ºæ€§
        df['left_correct'] = (df['left_choice'] == df['left_stimulus']).astype(int)
        df['right_correct'] = (df['right_choice'] == df['right_stimulus']).astype(int)
        
        # è¨ˆç®—æ•´é«”æ­£ç¢ºæ€§ï¼ˆå…©å€‹é€šé“éƒ½è¦å°ï¼‰
        df['both_correct'] = (df['left_correct'] & df['right_correct']).astype(int)
        
        print(f"âœ… é€šé“ç‰¹å¾µæ·»åŠ å®Œæˆ")
        print(f"   å·¦é€šé“æº–ç¢ºç‡: {df['left_correct'].mean():.1%}")
        print(f"   å³é€šé“æº–ç¢ºç‡: {df['right_correct'].mean():.1%}")
        print(f"   æ•´é«”æº–ç¢ºç‡: {df['both_correct'].mean():.1%}")
        
        return df
    
    def print_stimulus_distribution(self, df: pd.DataFrame):
        """é¡¯ç¤ºåˆºæ¿€åˆ†å¸ƒ"""
        
        print("\nğŸ“Š åˆºæ¿€åˆ†å¸ƒ:")
        print("-" * 50)
        
        for stimulus in [0, 1, 2, 3]:
            count = len(df[df['Stimulus'] == stimulus])
            percentage = count / len(df) * 100
            description = self.stimulus_descriptions.get(stimulus, f'Stimulus {stimulus}')
            print(f"   åˆºæ¿€ {stimulus} ({description}): {count:4d} è©¦é©— ({percentage:5.1f}%)")
        
        print("-" * 50)
    
    def extract_subject_data(self, df: pd.DataFrame, subject_id: int) -> Dict:
        """æå–å–®ä¸€å—è©¦è€…è³‡æ–™"""
        
        # éæ¿¾å—è©¦è€…è³‡æ–™
        subject_df = df[df['participant'] == subject_id].copy()
        
        if len(subject_df) == 0:
            raise ValueError(f"æ‰¾ä¸åˆ°å—è©¦è€… {subject_id} çš„è³‡æ–™")
        
        # åŸºæœ¬çµ±è¨ˆ
        n_trials = len(subject_df)
        accuracy = subject_df['both_correct'].mean()
        mean_rt = subject_df['RT'].mean()
        std_rt = subject_df['RT'].std()
        
        # å·¦å³é€šé“çµ±è¨ˆ
        left_accuracy = subject_df['left_correct'].mean()
        right_accuracy = subject_df['right_correct'].mean()
        
        return {
            'subject_id': subject_id,
            'n_trials': n_trials,
            'accuracy': accuracy,
            'mean_rt': mean_rt,
            'std_rt': std_rt,
            'left_accuracy': left_accuracy,
            'right_accuracy': right_accuracy,
            
            # åŸå§‹è³‡æ–™é™£åˆ—
            'stimuli': subject_df['Stimulus'].values,
            'choices': subject_df['Response'].values,
            'rt': subject_df['RT'].values,
            'correct': subject_df['both_correct'].values,
            
            # å·¦å³é€šé“è³‡æ–™é™£åˆ—
            'left_stimuli': subject_df['left_stimulus'].values,
            'right_stimuli': subject_df['right_stimulus'].values,
            'left_choices': subject_df['left_choice'].values,
            'right_choices': subject_df['right_choice'].values,
            'left_correct': subject_df['left_correct'].values,
            'right_correct': subject_df['right_correct'].values,
            
            # å®Œæ•´DataFrameï¼ˆä¾›é€²éšåˆ†æä½¿ç”¨ï¼‰
            'dataframe': subject_df
        }
    
    def get_subject_summary(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç²å¾—æ‰€æœ‰å—è©¦è€…çš„æ‘˜è¦çµ±è¨ˆ"""
        
        print("ğŸ“Š è¨ˆç®—å—è©¦è€…æ‘˜è¦çµ±è¨ˆ...")
        
        summary_data = []
        
        for subject_id in sorted(df['participant'].unique()):
            try:
                subject_data = self.extract_subject_data(df, subject_id)
                
                summary_data.append({
                    'subject_id': subject_id,
                    'n_trials': subject_data['n_trials'],
                    'accuracy': subject_data['accuracy'],
                    'left_accuracy': subject_data['left_accuracy'],
                    'right_accuracy': subject_data['right_accuracy'],
                    'mean_rt': subject_data['mean_rt'],
                    'std_rt': subject_data['std_rt']
                })
                
            except Exception as e:
                print(f"âš ï¸ å—è©¦è€… {subject_id} è³‡æ–™æå–å¤±æ•—: {e}")
                continue
        
        summary_df = pd.DataFrame(summary_data)
        
        print(f"âœ… æ‘˜è¦çµ±è¨ˆå®Œæˆ: {len(summary_df)} ä½å—è©¦è€…")
        
        return summary_df
    
    def validate_data_quality(self, df: pd.DataFrame, min_trials_per_subject=50):
        """é©—è­‰è³‡æ–™å“è³ª"""
        
        print("ğŸ” é©—è­‰è³‡æ–™å“è³ª...")
        
        # æª¢æŸ¥å—è©¦è€…è©¦é©—æ•¸
        subject_trial_counts = df.groupby('participant').size()
        insufficient_data = subject_trial_counts[subject_trial_counts < min_trials_per_subject]
        
        if len(insufficient_data) > 0:
            print(f"âš ï¸ {len(insufficient_data)} ä½å—è©¦è€…è³‡æ–™ä¸è¶³ (< {min_trials_per_subject} è©¦é©—):")
            for subject_id, count in insufficient_data.items():
                print(f"   å—è©¦è€… {subject_id}: {count} è©¦é©—")
        
        # æª¢æŸ¥RTåˆ†å¸ƒ
        rt_stats = df['RT'].describe()
        print(f"\nğŸ“Š RTåˆ†å¸ƒçµ±è¨ˆ:")
        print(f"   å¹³å‡: {rt_stats['mean']:.3f}s")
        print(f"   æ¨™æº–å·®: {rt_stats['std']:.3f}s")
        print(f"   ç¯„åœ: {rt_stats['min']:.3f}s - {rt_stats['max']:.3f}s")
        
        # æª¢æŸ¥æº–ç¢ºç‡åˆ†å¸ƒ
        accuracy_stats = df['both_correct'].describe()
        print(f"\nğŸ¯ æº–ç¢ºç‡çµ±è¨ˆ:")
        print(f"   å¹³å‡: {accuracy_stats['mean']:.1%}")
        print(f"   ç¯„åœ: {accuracy_stats['min']:.1%} - {accuracy_stats['max']:.1%}")
        
        # æª¢æŸ¥æ¥µç«¯å€¼
        very_fast = df['RT'] < 0.2
        very_slow = df['RT'] > 2.0
        very_low_acc = df.groupby('participant')['both_correct'].mean() < 0.3
        
        if very_fast.sum() > 0:
            print(f"âš ï¸ {very_fast.sum()} å€‹æ¥µå¿«åæ‡‰ (< 0.2s)")
        
        if very_slow.sum() > 0:
            print(f"âš ï¸ {very_slow.sum()} å€‹æ¥µæ…¢åæ‡‰ (> 2.0s)")
        
        if very_low_acc.sum() > 0:
            print(f"âš ï¸ {very_low_acc.sum()} ä½å—è©¦è€…æº–ç¢ºç‡æ¥µä½ (< 30%)")
        
        print("âœ… è³‡æ–™å“è³ªæª¢æŸ¥å®Œæˆ")
        
        return {
            'total_trials': len(df),
            'total_subjects': df['participant'].nunique(),
            'insufficient_data_subjects': len(insufficient_data),
            'very_fast_trials': very_fast.sum(),
            'very_slow_trials': very_slow.sum(),
            'low_accuracy_subjects': very_low_acc.sum(),
            'mean_rt': rt_stats['mean'],
            'mean_accuracy': accuracy_stats['mean']
        }

# ä¾¿åˆ©å‡½æ•¸
def load_data(csv_file='GRT_LBA.csv'):
    """å¿«é€Ÿè¼‰å…¥è³‡æ–™çš„ä¾¿åˆ©å‡½æ•¸"""
    processor = DataProcessor()
    return processor.load_and_clean_data(csv_file)

def get_subject_data(df, subject_id):
    """å¿«é€Ÿæå–å—è©¦è€…è³‡æ–™çš„ä¾¿åˆ©å‡½æ•¸"""
    processor = DataProcessor()
    return processor.extract_subject_data(df, subject_id)

# æ¸¬è©¦å‡½æ•¸
def test_data_processor(csv_file='GRT_LBA.csv'):
    """æ¸¬è©¦è³‡æ–™è™•ç†å™¨åŠŸèƒ½"""
    
    print("ğŸ§ª æ¸¬è©¦è³‡æ–™è™•ç†å™¨...")
    
    try:
        # å‰µå»ºè™•ç†å™¨
        processor = DataProcessor()
        
        # è¼‰å…¥è³‡æ–™
        df = processor.load_and_clean_data(csv_file)
        
        # é©—è­‰è³‡æ–™å“è³ª
        quality_report = processor.validate_data_quality(df)
        
        # ç²å¾—æ‘˜è¦çµ±è¨ˆ
        summary = processor.get_subject_summary(df)
        
        # æ¸¬è©¦å–®ä¸€å—è©¦è€…æå–
        first_subject = df['participant'].iloc[0]
        subject_data = processor.extract_subject_data(df, first_subject)
        
        print(f"\nâœ… è³‡æ–™è™•ç†å™¨æ¸¬è©¦æˆåŠŸ!")
        print(f"   ç¸½è©¦é©—æ•¸: {len(df)}")
        print(f"   å—è©¦è€…æ•¸: {df['participant'].nunique()}")
        print(f"   æ¸¬è©¦å—è©¦è€… {first_subject}: {subject_data['n_trials']} è©¦é©—")
        
        return True
        
    except Exception as e:
        print(f"âŒ è³‡æ–™è™•ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # å¦‚æœç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆï¼Œé€²è¡Œæ¸¬è©¦
    test_data_processor()
