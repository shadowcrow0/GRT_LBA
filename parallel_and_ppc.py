# -*- coding: utf-8 -*-
"""
parallel_and_ppc.py - Posterior Predictive Check for ParallelAND LBA model
å°ParallelANDæ¨¡å‹é€²è¡Œå¾Œé©—é æ¸¬æª¢é©—
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class ParallelANDPPC:
    """ParallelANDæ¨¡å‹å¾Œé©—é æ¸¬æª¢é©—"""
    
    def __init__(self):
        self.observed_data = None
        self.posterior_samples = None
        self.simulated_data = None
        
    def load_fitted_results(self, participant_id: int, 
                           summary_file: str = "high_accuracy_parallel_and_summary.csv",
                           params_file: str = "high_accuracy_parallel_and_parameters.csv",
                           original_data_file: str = "GRT_LBA.csv") -> bool:
        """è¼‰å…¥fittedçµæœå’ŒåŸå§‹è³‡æ–™"""
        
        print(f"ğŸ“Š è¼‰å…¥åƒèˆ‡è€… {participant_id} çš„fittedçµæœ...")
        
        try:
            # è¼‰å…¥fittedåƒæ•¸
            params_df = pd.read_csv(params_file)
            participant_params = params_df[params_df['participant_id'] == participant_id]
            
            if len(participant_params) == 0:
                print(f"âŒ æ‰¾ä¸åˆ°åƒèˆ‡è€… {participant_id} çš„åƒæ•¸")
                return False
            
            self.fitted_params = participant_params.iloc[0].to_dict()
            
            # è¼‰å…¥åŸå§‹è³‡æ–™
            original_data = pd.read_csv(original_data_file)
            participant_data = original_data[original_data['participant'] == participant_id].copy()
            
            if len(participant_data) == 0:
                print(f"âŒ æ‰¾ä¸åˆ°åƒèˆ‡è€… {participant_id} çš„åŸå§‹è³‡æ–™")
                return False
            
            # æº–å‚™observed data
            self.observed_data = {
                'responses': participant_data['Response'].astype(int).values,
                'rts': participant_data['RT'].astype(float).values,
                'left_stimuli': participant_data['Chanel1'].values,
                'right_stimuli': participant_data['Chanel2'].values,
                'n_trials': len(participant_data),
                'participant_id': participant_id
            }
            
            print(f"   âœ… æˆåŠŸè¼‰å…¥ {self.observed_data['n_trials']} trials")
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def generate_posterior_samples(self, n_samples: int = 1000) -> None:
        """ç”Ÿæˆå¾Œé©—æ¨£æœ¬ï¼ˆæ¨¡æ“¬ä¸ç¢ºå®šæ€§ï¼‰"""
        
        print(f"ğŸ² ç”Ÿæˆ {n_samples} å€‹å¾Œé©—æ¨£æœ¬...")
        
        # ç‚ºç°¡åŒ–ï¼Œæˆ‘å€‘åœ¨fittedåƒæ•¸å‘¨åœåŠ å…¥å°‘é‡å™ªéŸ³ä¾†æ¨¡æ“¬å¾Œé©—ä¸ç¢ºå®šæ€§
        # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™äº›æ‡‰è©²ä¾†è‡ªMCMC trace
        
        base_params = self.fitted_params.copy()
        samples = []
        
        for i in range(n_samples):
            sample = {}
            for param_name, value in base_params.items():
                if param_name == 'participant_id':
                    sample[param_name] = value
                elif 'v_' in param_name:  # drift rates
                    # åœ¨åŸå€¼å‘¨åœåŠ å…¥10%çš„è®Šç•°
                    sample[param_name] = np.random.gamma(value * 9, 0.1)
                elif param_name == 'threshold':
                    sample[param_name] = np.random.gamma(value * 9, 0.1)
                elif param_name == 'ndt':
                    sample[param_name] = np.random.uniform(max(0.05, value - 0.1), 
                                                         min(0.6, value + 0.1))
                elif param_name == 'start_var':
                    sample[param_name] = np.random.uniform(max(0.1, value - 0.1), 
                                                         min(0.7, value + 0.1))
                elif param_name == 'noise':
                    sample[param_name] = np.random.gamma(value * 9, 0.1)
                elif param_name == 'rt_sigma':
                    sample[param_name] = np.random.gamma(value * 9, 0.1)
                else:
                    sample[param_name] = value
            
            samples.append(sample)
        
        self.posterior_samples = samples
        print(f"   âœ… ç”Ÿæˆå®Œæˆ")
    
    def simulate_data_from_posterior(self, n_sim_datasets: int = 100) -> None:
        """å¾å¾Œé©—æ¨£æœ¬ç”Ÿæˆæ¨¡æ“¬è³‡æ–™"""
        
        print(f"ğŸ”¬ å¾å¾Œé©—ç”Ÿæˆ {n_sim_datasets} å€‹æ¨¡æ“¬è³‡æ–™é›†...")
        
        if self.posterior_samples is None:
            print("âŒ è«‹å…ˆç”Ÿæˆå¾Œé©—æ¨£æœ¬")
            return
        
        simulated_datasets = []
        
        # éš¨æ©Ÿé¸æ“‡å¾Œé©—æ¨£æœ¬
        selected_samples = np.random.choice(len(self.posterior_samples), 
                                          size=n_sim_datasets, replace=True)
        
        for i, sample_idx in enumerate(selected_samples):
            params = self.posterior_samples[sample_idx]
            simulated_data = self._simulate_single_dataset(params)
            simulated_datasets.append(simulated_data)
        
        self.simulated_data = simulated_datasets
        print(f"   âœ… ç”Ÿæˆ {len(simulated_datasets)} å€‹æ¨¡æ“¬è³‡æ–™é›†")
    
    def _simulate_single_dataset(self, params: Dict) -> Dict:
        """ä½¿ç”¨çµ¦å®šåƒæ•¸ç”Ÿæˆå–®ä¸€æ¨¡æ“¬è³‡æ–™é›†"""
        
        n_trials = self.observed_data['n_trials']
        
        simulated_responses = []
        simulated_rts = []
        
        for i in range(n_trials):
            left_stim = self.observed_data['left_stimuli'][i]
            right_stim = self.observed_data['right_stimuli'][i]
            
            # è¨ˆç®—4ç¨®å¯èƒ½åæ‡‰çš„RT
            response_rts = []
            
            for response in range(4):
                # ç¢ºå®šdrift rates
                if left_stim == 1:  # Vertical stimulus
                    left_v_v = params['left_v_vertical']
                    left_v_nv = params['left_v_nonvertical_error']
                else:  # Nonvertical stimulus
                    left_v_v = params['left_v_vertical_error']
                    left_v_nv = params['left_v_nonvertical']
                
                if right_stim == 1:  # Vertical stimulus
                    right_v_v = params['right_v_vertical']
                    right_v_nv = params['right_v_nonvertical_error']
                else:  # Nonvertical stimulus
                    right_v_v = params['right_v_vertical_error']
                    right_v_nv = params['right_v_nonvertical']
                
                # ç¢ºå®šä½¿ç”¨çš„drift rates
                if response in [1, 2]:  # Left vertical response
                    left_drift = left_v_v
                else:  # Left nonvertical response
                    left_drift = left_v_nv
                    
                if response in [0, 1]:  # Right vertical response
                    right_drift = right_v_v
                else:  # Right nonvertical response
                    right_drift = right_v_nv
                
                # ParallelAND: æœ€å°drift rate
                effective_drift = min(left_drift, right_drift)
                effective_drift = max(effective_drift, 0.05)
                
                # æ¨¡æ“¬RTï¼ˆåŠ å…¥è®Šç•°æ€§ï¼‰
                mean_rt = params['threshold'] / effective_drift + params['ndt']
                rt = np.random.normal(mean_rt, params.get('rt_sigma', 0.3))
                rt = max(rt, 0.1)  # æœ€å°RT
                
                response_rts.append(rt)
            
            # é¸æ“‡æœ€å¿«çš„åæ‡‰
            chosen_response = np.argmin(response_rts)
            chosen_rt = response_rts[chosen_response]
            
            simulated_responses.append(chosen_response)
            simulated_rts.append(chosen_rt)
        
        return {
            'responses': np.array(simulated_responses),
            'rts': np.array(simulated_rts)
        }
    
    def compute_ppc_statistics(self) -> Dict:
        """è¨ˆç®—PPCçµ±è¨ˆé‡"""
        
        print("ğŸ“ˆ è¨ˆç®—PPCçµ±è¨ˆé‡...")
        
        if self.simulated_data is None:
            print("âŒ è«‹å…ˆç”Ÿæˆæ¨¡æ“¬è³‡æ–™")
            return {}
        
        observed = self.observed_data
        
        # è§€å¯Ÿè³‡æ–™çµ±è¨ˆé‡
        obs_stats = {
            'mean_rt': np.mean(observed['rts']),
            'std_rt': np.std(observed['rts']),
            'min_rt': np.min(observed['rts']),
            'max_rt': np.max(observed['rts']),
            'median_rt': np.median(observed['rts']),
            'response_proportions': np.bincount(observed['responses'], minlength=4) / len(observed['responses'])
        }
        
        # æ¨¡æ“¬è³‡æ–™çµ±è¨ˆé‡
        sim_stats = {
            'mean_rt': [],
            'std_rt': [],
            'min_rt': [],
            'max_rt': [],
            'median_rt': [],
            'response_proportions': []
        }
        
        for sim_data in self.simulated_data:
            sim_stats['mean_rt'].append(np.mean(sim_data['rts']))
            sim_stats['std_rt'].append(np.std(sim_data['rts']))
            sim_stats['min_rt'].append(np.min(sim_data['rts']))
            sim_stats['max_rt'].append(np.max(sim_data['rts']))
            sim_stats['median_rt'].append(np.median(sim_data['rts']))
            
            resp_props = np.bincount(sim_data['responses'], minlength=4) / len(sim_data['responses'])
            sim_stats['response_proportions'].append(resp_props)
        
        # è¨ˆç®—p-values (Bayesian p-values)
        p_values = {}
        for stat_name in ['mean_rt', 'std_rt', 'min_rt', 'max_rt', 'median_rt']:
            sim_values = np.array(sim_stats[stat_name])
            obs_value = obs_stats[stat_name]
            p_values[stat_name] = np.mean(sim_values >= obs_value)
        
        # Response proportions p-values
        sim_resp_props = np.array(sim_stats['response_proportions'])
        obs_resp_props = obs_stats['response_proportions']
        p_values['response_proportions'] = []
        
        for i in range(4):
            p_val = np.mean(sim_resp_props[:, i] >= obs_resp_props[i])
            p_values['response_proportions'].append(p_val)
        
        results = {
            'observed': obs_stats,
            'simulated': sim_stats,
            'p_values': p_values
        }
        
        # å°å‡ºçµæœ
        print(f"\nğŸ“Š PPCçµæœ (p-valuesæ¥è¿‘0.5è¡¨ç¤ºæ¨¡å‹fitè‰¯å¥½):")
        print(f"   Mean RT: {obs_stats['mean_rt']:.3f} (p={p_values['mean_rt']:.3f})")
        print(f"   Std RT: {obs_stats['std_rt']:.3f} (p={p_values['std_rt']:.3f})")
        print(f"   Median RT: {obs_stats['median_rt']:.3f} (p={p_values['median_rt']:.3f})")
        
        print(f"\n   Response proportions:")
        for i, (obs_prop, p_val) in enumerate(zip(obs_resp_props, p_values['response_proportions'])):
            print(f"     Response {i}: {obs_prop:.3f} (p={p_val:.3f})")
        
        return results
    
    def plot_ppc_results(self, save_path: str = None) -> plt.Figure:
        """ç¹ªè£½PPCçµæœ"""
        
        print("ğŸ¨ ç¹ªè£½PPCçµæœ...")
        
        if self.simulated_data is None:
            print("âŒ è«‹å…ˆç”Ÿæˆæ¨¡æ“¬è³‡æ–™")
            return None
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        observed = self.observed_data
        
        # 1. RTåˆ†å¸ƒæ¯”è¼ƒ
        axes[0, 0].hist(observed['rts'], bins=30, alpha=0.7, density=True, 
                       label='Observed', color='red')
        
        # ç¹ªè£½å¹¾å€‹æ¨¡æ“¬è³‡æ–™é›†
        for i, sim_data in enumerate(self.simulated_data[:10]):
            axes[0, 0].hist(sim_data['rts'], bins=30, alpha=0.1, density=True, 
                           color='blue', label='Simulated' if i == 0 else "")
        
        axes[0, 0].set_xlabel('RT')
        axes[0, 0].set_ylabel('Density')
        axes[0, 0].set_title('RT Distribution')
        axes[0, 0].legend()
        
        # 2. Mean RTåˆ†å¸ƒ
        sim_mean_rts = [np.mean(sim_data['rts']) for sim_data in self.simulated_data]
        axes[0, 1].hist(sim_mean_rts, bins=20, alpha=0.7, color='blue', density=True)
        axes[0, 1].axvline(np.mean(observed['rts']), color='red', linestyle='--', 
                          linewidth=2, label='Observed')
        axes[0, 1].set_xlabel('Mean RT')
        axes[0, 1].set_ylabel('Density')
        axes[0, 1].set_title('Mean RT Distribution')
        axes[0, 1].legend()
        
        # 3. Std RTåˆ†å¸ƒ
        sim_std_rts = [np.std(sim_data['rts']) for sim_data in self.simulated_data]
        axes[0, 2].hist(sim_std_rts, bins=20, alpha=0.7, color='blue', density=True)
        axes[0, 2].axvline(np.std(observed['rts']), color='red', linestyle='--', 
                          linewidth=2, label='Observed')
        axes[0, 2].set_xlabel('Std RT')
        axes[0, 2].set_ylabel('Density')
        axes[0, 2].set_title('RT Std Distribution')
        axes[0, 2].legend()
        
        # 4. Response proportions
        obs_resp_props = np.bincount(observed['responses'], minlength=4) / len(observed['responses'])
        sim_resp_props = np.array([
            np.bincount(sim_data['responses'], minlength=4) / len(sim_data['responses']) 
            for sim_data in self.simulated_data
        ])
        
        x = np.arange(4)
        width = 0.35
        
        axes[1, 0].bar(x - width/2, obs_resp_props, width, label='Observed', 
                      alpha=0.7, color='red')
        axes[1, 0].bar(x + width/2, np.mean(sim_resp_props, axis=0), width, 
                      label='Simulated (mean)', alpha=0.7, color='blue')
        axes[1, 0].set_xlabel('Response')
        axes[1, 0].set_ylabel('Proportion')
        axes[1, 0].set_title('Response Proportions')
        axes[1, 0].set_xticks(x)
        axes[1, 0].legend()
        
        # 5. RT vs Response scatter
        axes[1, 1].scatter(observed['responses'], observed['rts'], 
                          alpha=0.6, color='red', label='Observed', s=20)
        
        # åˆä½µæ‰€æœ‰æ¨¡æ“¬è³‡æ–™
        all_sim_responses = np.concatenate([sim_data['responses'] for sim_data in self.simulated_data[:5]])
        all_sim_rts = np.concatenate([sim_data['rts'] for sim_data in self.simulated_data[:5]])
        
        axes[1, 1].scatter(all_sim_responses, all_sim_rts, 
                          alpha=0.1, color='blue', label='Simulated', s=10)
        axes[1, 1].set_xlabel('Response')
        axes[1, 1].set_ylabel('RT')
        axes[1, 1].set_title('RT vs Response')
        axes[1, 1].legend()
        
        # 6. Quantile-Quantile plot
        obs_rt_sorted = np.sort(observed['rts'])
        sim_rt_quantiles = []
        
        for q in np.linspace(0.01, 0.99, len(obs_rt_sorted)):
            sim_q_values = [np.quantile(sim_data['rts'], q) for sim_data in self.simulated_data]
            sim_rt_quantiles.append(np.mean(sim_q_values))
        
        axes[1, 2].scatter(obs_rt_sorted, sim_rt_quantiles, alpha=0.6, s=20)
        axes[1, 2].plot([obs_rt_sorted.min(), obs_rt_sorted.max()], 
                       [obs_rt_sorted.min(), obs_rt_sorted.max()], 'r--', alpha=0.8)
        axes[1, 2].set_xlabel('Observed RT Quantiles')
        axes[1, 2].set_ylabel('Simulated RT Quantiles')
        axes[1, 2].set_title('Q-Q Plot')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"   ğŸ“Š PPCåœ–è¡¨å·²å„²å­˜: {save_path}")
        
        return fig
    
    def run_complete_ppc(self, participant_id: int, n_posterior_samples: int = 1000, 
                        n_sim_datasets: int = 100) -> Dict:
        """åŸ·è¡Œå®Œæ•´çš„PPCåˆ†æ"""
        
        print(f"ğŸ¯ åŸ·è¡Œåƒèˆ‡è€… {participant_id} çš„å®Œæ•´PPCåˆ†æ")
        print("="*60)
        
        # è¼‰å…¥è³‡æ–™
        if not self.load_fitted_results(participant_id):
            return {}
        
        # ç”Ÿæˆå¾Œé©—æ¨£æœ¬
        self.generate_posterior_samples(n_posterior_samples)
        
        # ç”Ÿæˆæ¨¡æ“¬è³‡æ–™
        self.simulate_data_from_posterior(n_sim_datasets)
        
        # è¨ˆç®—çµ±è¨ˆé‡
        ppc_results = self.compute_ppc_statistics()
        
        # ç¹ªè£½çµæœ
        fig = self.plot_ppc_results(f"ppc_participant_{participant_id}.png")
        
        # å„²å­˜çµæœ
        ppc_summary = {
            'participant_id': participant_id,
            'n_posterior_samples': n_posterior_samples,
            'n_sim_datasets': n_sim_datasets,
            'ppc_statistics': ppc_results
        }
        
        print(f"\nâœ… PPCåˆ†æå®Œæˆ!")
        return ppc_summary

def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    
    print("ğŸ” ParallelANDæ¨¡å‹å¾Œé©—é æ¸¬æª¢é©— (PPC)")
    print("="*50)
    
    # é¸æ“‡è¦åˆ†æçš„å—è©¦è€…ï¼ˆå¯ä»¥æ”¹ç‚ºå¾å‘½ä»¤è¡Œåƒæ•¸ç²å–ï¼‰
    participant_id = 40  # å¯ä»¥ä¿®æ”¹ç‚ºå…¶ä»–å—è©¦è€…
    
    # åŸ·è¡ŒPPC
    ppc = ParallelANDPPC()
    results = ppc.run_complete_ppc(participant_id, n_posterior_samples=500, n_sim_datasets=50)
    
    if results:
        print(f"\nğŸ‰ åƒèˆ‡è€… {participant_id} çš„PPCåˆ†æå®Œæˆ!")
    else:
        print("âŒ PPCåˆ†æå¤±æ•—")

if __name__ == "__main__":
    main()