# ultra_conservative_rescue.py - è¶…ä¿å®ˆæ¶æ•‘æ–¹æ¡ˆï¼Œå¾¹åº•è§£æ±ºæ”¶æ–‚å•é¡Œ

import numpy as np
import pandas as pd
import pymc as pm
import arviz as az
import time
from typing import Dict, Optional, Tuple

def diagnose_convergence_simple(trace, verbose=True):
    """ç°¡åŒ–çš„æ”¶æ–‚è¨ºæ–·"""
    try:
        summary = az.summary(trace)
        
        max_rhat = summary['r_hat'].max() if 'r_hat' in summary.columns else np.nan
        min_ess = summary['ess_bulk'].min() if 'ess_bulk' in summary.columns else np.nan
        
        n_divergent = 0
        if hasattr(trace, 'sample_stats') and 'diverging' in trace.sample_stats:
            n_divergent = int(trace.sample_stats.diverging.sum())
        
        converged = (max_rhat < 1.05 and min_ess > 200 and n_divergent == 0)
        
        if verbose:
            if converged:
                status = "ğŸ‰ å®Œç¾æ”¶æ–‚"
            elif max_rhat < 1.1 and min_ess > 100:
                status = "âœ… æ”¶æ–‚è‰¯å¥½"
            else:
                status = "âš ï¸ æ”¶æ–‚è­¦å‘Š"
            
            print(f"   {status}: RÌ‚={max_rhat:.3f}, ESS={min_ess:.0f}, ç™¼æ•£={n_divergent}")
        
        return {
            'converged': converged,
            'max_rhat': max_rhat,
            'min_ess': min_ess,
            'n_divergent': n_divergent
        }
    except Exception as e:
        if verbose:
            print(f"   âŒ è¨ºæ–·å¤±æ•—: {e}")
        return {'converged': False, 'error': str(e)}

class UltraConservativeLBA:
    """è¶…ä¿å®ˆLBAæ¨¡å‹ - å°ˆé–€è§£æ±ºåš´é‡æ”¶æ–‚å•é¡Œ"""
    
    def __init__(self):
        # æ¥µä¿å®ˆçš„å›ºå®šåƒæ•¸
        self.FIXED_PARAMS = {
            'threshold': 1.0,      # æé«˜é–¾å€¼
            'start_var': 0.15,     # é™ä½èµ·å§‹è®Šç•°  
            'ndt': 0.12,           # é™ä½éæ±ºç­–æ™‚é–“
            'noise': 0.25          # é™ä½å™ªéŸ³
        }
        
        # æ¥µä¿å®ˆçš„MCMCè¨­å®š
        self.mcmc_config = {
            'draws': 1000,
            'tune': 2500,           # æ¥µé•·èª¿å„ªæœŸ
            'chains': 4,            # æ›´å¤šéˆ
            'cores': 1,
            'target_accept': 0.995,  # å¹¾ä¹å®Œç¾æ¥å—ç‡
            'max_treedepth': 25,    # éå¸¸æ·±çš„æ¨¹
            'init': 'jitter+adapt_diag',
            'progressbar': True,
            'return_inferencedata': True,
            'step_scale': 0.05,     # æ¥µå°æ­¥é•·
            'random_seed': [42, 43, 44, 45, 46, 47]
        }
        
        print("ğŸ›¡ï¸ è¶…ä¿å®ˆLBAæ¨¡å‹åˆå§‹åŒ–")
        print("   ç­–ç•¥: æ¥µç«¯ä¿å®ˆè¨­å®šï¼Œå°ˆé–€è§£æ±ºæ”¶æ–‚å•é¡Œ")
        print("   å›ºå®šåƒæ•¸:", self.FIXED_PARAMS)
        print("   MCMCè¨­å®š: draws=1000, tune=2500, chains=6, target_accept=0.995")
    
    def prepare_subject_data(self, df, subject_id):
        """æº–å‚™å—è©¦è€…æ•¸æ“š"""
        
        subject_df = df[df['participant'] == subject_id].copy()
        
        if len(subject_df) == 0:
            raise ValueError(f"æ‰¾ä¸åˆ°å—è©¦è€… {subject_id}")
        
        # æ•¸æ“šæ˜ å°„
        stimulus_map = {0: [1, 0], 1: [1, 1], 2: [0, 0], 3: [0, 1]}
        choice_map = {0: [1, 0], 1: [1, 1], 2: [0, 0], 3: [0, 1]}
        
        left_stim, right_stim = [], []
        left_choice, right_choice = [], []
        
        for _, row in subject_df.iterrows():
            s, c = int(row['Stimulus']), int(row['Response'])
            left_stim.append(stimulus_map[s][0])
            right_stim.append(stimulus_map[s][1])
            left_choice.append(choice_map[c][0])
            right_choice.append(choice_map[c][1])
        
        # è¨ˆç®—è§€å¯Ÿçµ±è¨ˆ
        left_correct = np.array(left_choice) == np.array(left_stim)
        right_correct = np.array(right_choice) == np.array(right_stim)
        
        return {
            'subject_id': subject_id,
            'n_trials': len(subject_df),
            'rt': subject_df['RT'].values,
            'left_stimuli': np.array(left_stim),
            'right_stimuli': np.array(right_stim),
            'left_choices': np.array(left_choice),
            'right_choices': np.array(right_choice),
            'left_accuracy': np.mean(left_correct),
            'right_accuracy': np.mean(right_correct),
            'overall_accuracy': np.mean(left_correct & right_correct),
            'mean_rt': np.mean(subject_df['RT']),
            'std_rt': np.std(subject_df['RT'])
        }
    
    def build_ultra_constrained_model(self, data):
        """æ§‹å»ºè¶…ç´„æŸæ¨¡å‹"""
        
        print("ğŸ”§ æ§‹å»ºè¶…ç´„æŸæ¨¡å‹")
        print("   ç‰¹è‰²: éšå±¤å…ˆé©— + å…¨å°æ•¸è®Šæ› + è¶…å¼·ç´„æŸ")
        
        with pm.Model() as model:
            
            # === éšå±¤å…ˆé©—çµæ§‹ ===
            # ç¾¤çµ„å‡å€¼ï¼ˆæ¥µä¿å®ˆï¼‰
            mu_match = pm.Normal('mu_match', mu=0.1, sigma=0.2)  # å°æ•¸ç©ºé–“
            mu_mismatch = pm.Normal('mu_mismatch', mu=-1.2, sigma=0.15)
            
            # ç¾¤çµ„æ¨™æº–å·®ï¼ˆæ¥µå°ï¼Œä¿ƒé€²å¼·ç›¸ä¼¼æ€§ï¼‰
            sigma_match = pm.HalfNormal('sigma_match', sigma=0.1)
            sigma_mismatch = pm.HalfNormal('sigma_mismatch', sigma=0.08)
            
            # === å€‹åˆ¥åƒæ•¸ï¼ˆåœ¨å°æ•¸ç©ºé–“ï¼‰ ===
            log_left_match = pm.Normal('log_left_match', mu=mu_match, sigma=sigma_match)
            log_left_mismatch = pm.Normal('log_left_mismatch', mu=mu_mismatch, sigma=sigma_mismatch)
            log_right_match = pm.Normal('log_right_match', mu=mu_match, sigma=sigma_match)
            log_right_mismatch = pm.Normal('log_right_mismatch', mu=mu_mismatch, sigma=sigma_mismatch)
            
            # === è®Šæ›åˆ°æ­£å€¼ç©ºé–“ï¼ˆä¿è­‰é †åºï¼‰===
            # mismatch åƒæ•¸ï¼ˆæœ‰æœ€å°å€¼ä¿è­‰ï¼‰
            left_drift_mismatch_base = pm.math.exp(log_left_mismatch) + 0.12
            right_drift_mismatch_base = pm.math.exp(log_right_mismatch) + 0.12
            
            # match åƒæ•¸ï¼ˆä¿è­‰ > mismatchï¼‰
            left_drift_match_base = left_drift_mismatch_base + pm.math.exp(log_left_match) + 0.25
            right_drift_match_base = right_drift_mismatch_base + pm.math.exp(log_right_match) + 0.25
            
            # === è¶…å¼·å°ç¨±æ€§ç´„æŸ ===
            symmetry_weight = 0.8  # æ¥µå¼·çš„å°ç¨±æ€§
            
            # å°ç¨±åŒ–åƒæ•¸
            mean_match = (left_drift_match_base + right_drift_match_base) / 2
            mean_mismatch = (left_drift_mismatch_base + right_drift_mismatch_base) / 2
            
            # æœ€çµ‚åƒæ•¸ï¼ˆå¹¾ä¹å®Œå…¨å°ç¨±ï¼‰
            left_drift_match = pm.Deterministic('left_drift_match',
                symmetry_weight * mean_match + (1 - symmetry_weight) * left_drift_match_base)
            left_drift_mismatch = pm.Deterministic('left_drift_mismatch',
                symmetry_weight * mean_mismatch + (1 - symmetry_weight) * left_drift_mismatch_base)
            
            right_drift_match = pm.Deterministic('right_drift_match',
                symmetry_weight * mean_match + (1 - symmetry_weight) * right_drift_match_base)
            right_drift_mismatch = pm.Deterministic('right_drift_mismatch',
                symmetry_weight * mean_mismatch + (1 - symmetry_weight) * right_drift_mismatch_base)
            
            # === é¡å¤–çš„è»Ÿç´„æŸé˜²æ­¢æ¥µç«¯å€¼ ===
            # é™åˆ¶æœ€å¤§å€¼ï¼ˆé˜²æ­¢æ•¸å€¼çˆ†ç‚¸ï¼‰
            pm.Potential('max_drift_constraint',
                -0.2 * (pm.math.maximum(left_drift_match - 3.5, 0)**2 +
                       pm.math.maximum(right_drift_match - 3.5, 0)**2))
            
            # ä¿ƒé€²åˆç†æ¯”ä¾‹ï¼ˆmatch/mismatch åœ¨ 1.5-4.0 ä¹‹é–“ï¼‰
            left_ratio = left_drift_match / left_drift_mismatch
            right_ratio = right_drift_match / right_drift_mismatch
            pm.Potential('ratio_constraint',
                -0.1 * (pm.math.maximum(left_ratio - 4.0, 0)**2 +
                       pm.math.maximum(right_ratio - 4.0, 0)**2 +
                       pm.math.maximum(1.5 - left_ratio, 0)**2 +
                       pm.math.maximum(1.5 - right_ratio, 0)**2))
            
            # === å®Œæ•´LBAä¼¼ç„¶è¨ˆç®— ===
            left_ll = self._compute_ultra_stable_lba_likelihood(
                data['left_choices'], data['left_stimuli'], data['rt'],
                left_drift_match, left_drift_mismatch
            )
            
            right_ll = self._compute_ultra_stable_lba_likelihood(
                data['right_choices'], data['right_stimuli'], data['rt'],
                right_drift_match, right_drift_mismatch
            )
            
            pm.Potential('left_likelihood', left_ll)
            pm.Potential('right_likelihood', right_ll)
        
        return model
    
    def _compute_ultra_stable_lba_likelihood(self, decisions, stimuli, rt, drift_match, drift_mismatch):
        """è¶…ç©©å®šçš„LBAä¼¼ç„¶è¨ˆç®—"""
        
        from pytensor.tensor import erf
        
        # å›ºå®šåƒæ•¸
        threshold = self.FIXED_PARAMS['threshold']
        start_var = self.FIXED_PARAMS['start_var']
        ndt = self.FIXED_PARAMS['ndt']
        noise = self.FIXED_PARAMS['noise']
        
        # === æ¥µä¿å®ˆçš„åƒæ•¸è™•ç† ===
        # æ›´åš´æ ¼çš„é‚Šç•Œï¼Œé˜²æ­¢ä»»ä½•æ•¸å€¼å•é¡Œ
        drift_match_safe = pm.math.clip(drift_match, 0.18, 3.5)
        drift_mismatch_safe = pm.math.clip(drift_mismatch, 0.12, 2.0)
        
        # ç¢ºä¿é †åºä¸”å·®è·åˆç†
        drift_match_safe = pm.math.maximum(drift_match_safe, drift_mismatch_safe + 0.2)
        drift_match_safe = pm.math.minimum(drift_match_safe, drift_mismatch_safe + 2.5)
        
        # === æ¥µä¿å®ˆçš„æ™‚é–“è™•ç† ===
        decision_time = pm.math.clip(rt - ndt, 0.1, 2.0)
        
        # === æ¨™æº–LBAè¨ˆç®—ï¼ˆæ¥µä¿å®ˆè£å‰ªï¼‰===
        stimulus_match = pm.math.eq(decisions, stimuli)
        v_chosen = pm.math.where(stimulus_match, drift_match_safe, drift_mismatch_safe)
        v_unchosen = pm.math.where(stimulus_match, drift_mismatch_safe, drift_match_safe)
        
        sqrt_t = pm.math.sqrt(decision_time)
        
        # æ¥µä¿å®ˆçš„z-scoreè£å‰ª
        z1_chosen = pm.math.clip(
            (v_chosen * decision_time - threshold) / (noise * sqrt_t), -2.5, 2.5)
        z2_chosen = pm.math.clip(
            (v_chosen * decision_time - start_var) / (noise * sqrt_t), -2.5, 2.5)
        z1_unchosen = pm.math.clip(
            (v_unchosen * decision_time - threshold) / (noise * sqrt_t), -2.5, 2.5)
        
        # æ­£æ…‹å‡½æ•¸ï¼ˆæ¥µä¿å®ˆç‰ˆæœ¬ï¼‰
        def ultra_safe_normal_cdf(x):
            x_safe = pm.math.clip(x, -2.5, 2.5)
            return 0.5 * (1 + erf(x_safe / pm.math.sqrt(2)))
        
        def ultra_safe_normal_pdf(x):
            x_safe = pm.math.clip(x, -2.5, 2.5)
            return pm.math.exp(-0.5 * x_safe**2) / pm.math.sqrt(2 * np.pi)
        
        # Winnerå¯†åº¦ï¼ˆæ¥µä¿å®ˆçš„ä¸‹é™ï¼‰
        chosen_cdf_term = ultra_safe_normal_cdf(z1_chosen) - ultra_safe_normal_cdf(z2_chosen)
        chosen_pdf_term = (ultra_safe_normal_pdf(z1_chosen) - ultra_safe_normal_pdf(z2_chosen)) / (noise * sqrt_t)
        chosen_cdf_term = pm.math.maximum(chosen_cdf_term, 1e-5)
        
        chosen_likelihood = pm.math.maximum(
            (v_chosen / start_var) * chosen_cdf_term + chosen_pdf_term / start_var, 1e-5)
        
        # Loserå­˜æ´»
        unchosen_survival = pm.math.maximum(1 - ultra_safe_normal_cdf(z1_unchosen), 1e-5)
        
        # è¯åˆä¼¼ç„¶ï¼ˆæ¥µä¿å®ˆçš„ä¸‹é™ï¼‰
        joint_likelihood = chosen_likelihood * unchosen_survival
        joint_likelihood = pm.math.maximum(joint_likelihood, 1e-6)
        log_likelihood = pm.math.log(joint_likelihood)
        
        # æ¥µä¿å®ˆçš„è£å‰ª
        log_likelihood_safe = pm.math.clip(log_likelihood, -20.0, 3.0)
        
        return pm.math.sum(log_likelihood_safe)
    
    def fit_ultra_conservative(self, data):
        """åŸ·è¡Œè¶…ä¿å®ˆæ“¬åˆ"""
        
        print(f"\nğŸ›¡ï¸ è¶…ä¿å®ˆæ“¬åˆ - å—è©¦è€… {data['subject_id']}")
        print(f"   ç›®æ¨™: å¾¹åº•è§£æ±ºæ”¶æ–‚å•é¡Œ")
        print(f"   æ•¸æ“š: {data['n_trials']} trials, æº–ç¢ºç‡ {data['overall_accuracy']:.1%}")
        
        # æ§‹å»ºæ¨¡å‹
        model = self.build_ultra_constrained_model(data)
        
        # æ¨¡å‹é©—è­‰
        with model:
            try:
                test_point = model.initial_point()
                log_prob = model.compile_logp()(test_point)
                if not np.isfinite(log_prob):
                    raise ValueError(f"æ¨¡å‹ç„¡æ•ˆ: {log_prob}")
                print(f"   âœ… æ¨¡å‹é©—è­‰: log_prob = {log_prob:.2f}")
            except Exception as e:
                print(f"   âŒ æ¨¡å‹é©—è­‰å¤±æ•—: {e}")
                raise
        
        # è¶…ä¿å®ˆMCMCæ¡æ¨£
        print(f"   ğŸŒ è¶…ä¿å®ˆMCMCæ¡æ¨£...")
        print(f"   è¨­å®š: draws={self.mcmc_config['draws']}, tune={self.mcmc_config['tune']}")
        print(f"   è­¦å‘Š: é€™å¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“ (é è¨ˆ 10-30 åˆ†é˜)")
        
        start_time = time.time()
        
        with model:
            trace = pm.sample(**self.mcmc_config)
        
        sampling_time = time.time() - start_time
        print(f"   â±ï¸ æ¡æ¨£å®Œæˆ: {sampling_time/60:.1f} åˆ†é˜")
        
        # æ”¶æ–‚è¨ºæ–·
        convergence = diagnose_convergence_simple(trace)
        
        # æå–çµæœ
        results = self._extract_results(trace, data, convergence, sampling_time)
        
        return model, trace, results
    
    def _extract_results(self, trace, data, convergence, sampling_time):
        """æå–çµæœ"""
        try:
            summary = az.summary(trace)
            
            # åƒæ•¸ä¼°è¨ˆ
            param_estimates = {}
            param_stds = {}
            
            for param in ['left_drift_match', 'left_drift_mismatch', 'right_drift_match', 'right_drift_mismatch']:
                if param in summary.index:
                    param_estimates[param] = float(summary.loc[param, 'mean'])
                    param_stds[param] = float(summary.loc[param, 'sd'])
                else:
                    param_estimates[param] = np.nan
                    param_stds[param] = np.nan
            
            # è¡ç”ŸæŒ‡æ¨™
            left_discrimination = param_estimates['left_drift_match'] - param_estimates['left_drift_mismatch']
            right_discrimination = param_estimates['right_drift_match'] - param_estimates['right_drift_mismatch']
            processing_asymmetry = abs(param_estimates['left_drift_match'] - param_estimates['right_drift_match'])
            discrimination_asymmetry = abs(left_discrimination - right_discrimination)
            
            # æ•ˆç‡æ¯”
            left_efficiency = param_estimates['left_drift_match'] / param_estimates['left_drift_mismatch']
            right_efficiency = param_estimates['right_drift_match'] / param_estimates['right_drift_mismatch']
            
            # å°ç¨±æ€§åˆ¤æ–·ï¼ˆæ›´åš´æ ¼æ¨™æº–ï¼‰
            symmetry_supported = (processing_asymmetry < 0.2 and discrimination_asymmetry < 0.25)
            
            results = {
                'success': True,
                'strategy': 'ultra_conservative',
                'subject_id': data['subject_id'],
                'converged': convergence['converged'],
                'convergence_diagnostics': convergence,
                'sampling_time_minutes': sampling_time / 60,
                'param_estimates': param_estimates,
                'param_stds': param_stds,
                'left_discrimination': left_discrimination,
                'right_discrimination': right_discrimination,
                'left_efficiency_ratio': left_efficiency,
                'right_efficiency_ratio': right_efficiency,
                'processing_asymmetry': processing_asymmetry,
                'discrimination_asymmetry': discrimination_asymmetry,
                'symmetry_supported': symmetry_supported,
                'observed_accuracy': data['overall_accuracy'],
                'observed_mean_rt': data['mean_rt'],
                'fixed_params': self.FIXED_PARAMS
            }
            
            print(f"   ğŸ“Š è¶…ä¿å®ˆçµæœ:")
            print(f"      å·¦é€šé“: match={param_estimates['left_drift_match']:.3f}, "
                  f"mismatch={param_estimates['left_drift_mismatch']:.3f}, "
                  f"è¾¨åˆ¥={left_discrimination:.3f}")
            print(f"      å³é€šé“: match={param_estimates['right_drift_match']:.3f}, "
                  f"mismatch={param_estimates['right_drift_mismatch']:.3f}, "
                  f"è¾¨åˆ¥={right_discrimination:.3f}")
            print(f"      ä¸å°ç¨±æ€§: è™•ç†={processing_asymmetry:.3f}, è¾¨åˆ¥={discrimination_asymmetry:.3f}")
            print(f"      å°ç¨±æ€§: {'âœ… æ”¯æŒ' if symmetry_supported else 'âŒ ä¸æ”¯æŒ'}")
            print(f"      æ•ˆç‡æ¯”: å·¦={left_efficiency:.2f}, å³={right_efficiency:.2f}")
            
            return results
            
        except Exception as e:
            print(f"   âŒ çµæœæå–å¤±æ•—: {e}")
            return {
                'success': False,
                'strategy': 'ultra_conservative',
                'subject_id': data['subject_id'],
                'error': str(e)
            }

def run_ultra_conservative_rescue(csv_file=None, subject_id=None):
    """é‹è¡Œè¶…ä¿å®ˆæ¶æ•‘æ–¹æ¡ˆ"""
    
    print("ğŸš¨ è¶…ä¿å®ˆæ¶æ•‘æ–¹æ¡ˆ")
    print("=" * 50)
    print("ç›®æ¨™: å¾¹åº•è§£æ±ºæ”¶æ–‚å•é¡Œ")
    print("ç­–ç•¥: æ¥µç«¯ä¿å®ˆè¨­å®š + éšå±¤å…ˆé©— + è¶…å¼·ç´„æŸ")
    
    try:
        # è©¢å•CSVæª”æ¡ˆè·¯å¾‘
        if csv_file is None:
            csv_file = input("è«‹è¼¸å…¥CSVæª”æ¡ˆè·¯å¾‘ (æˆ–æŒ‰Enterä½¿ç”¨é è¨­ 'GRT_LBA.csv'): ").strip()
            if not csv_file:
                csv_file = 'GRT_LBA.csv'
        
        # è¼‰å…¥æ•¸æ“š
        print(f"\nğŸ“‚ è¼‰å…¥æ•¸æ“š: {csv_file}")
        df = pd.read_csv(csv_file)
        df = df.dropna(subset=['Response', 'RT', 'Stimulus', 'participant'])
        df = df[(df['RT'] >= 0.2) & (df['RT'] <= 2.5)]
        
        print(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ: {len(df)} trials, {df['participant'].nunique()} å—è©¦è€…")
        
        # é¸æ“‡å—è©¦è€…
        if subject_id is None:
            print(f"\nå—è©¦è€…é¸æ“‡:")
            available_subjects = df['participant'].unique()[:10]  # é¡¯ç¤ºå‰10å€‹
            print(f"å¯ç”¨å—è©¦è€…: {list(available_subjects)}")
            
            subject_input = input("è«‹è¼¸å…¥å—è©¦è€…ID (æˆ–æŒ‰Enterè‡ªå‹•é¸æ“‡æœ€ä½³): ").strip()
            
            if subject_input:
                subject_id = int(subject_input)
            else:
                # è‡ªå‹•é¸æ“‡æœ€ä½³å—è©¦è€…
                best_subject = None
                best_score = 0
                
                for sid in available_subjects:
                    temp_analyzer = UltraConservativeLBA()
                    try:
                        temp_data = temp_analyzer.prepare_subject_data(df, sid)
                        if temp_data['n_trials'] >= 60 and temp_data['overall_accuracy'] >= 0.5:
                            # è¨ˆç®—å“è³ªåˆ†æ•¸
                            acc_score = temp_data['overall_accuracy']
                            trial_score = min(temp_data['n_trials'] / 100, 1.0)
                            rt_score = 1 / (1 + temp_data['std_rt'])
                            total_score = acc_score * 0.6 + trial_score * 0.3 + rt_score * 0.1
                            
                            if total_score > best_score:
                                best_score = total_score
                                best_subject = sid
                    except:
                        continue
                
                if best_subject is None:
                    subject_id = available_subjects[0]
                    print(f"âš ï¸ æœªæ‰¾åˆ°ç†æƒ³å—è©¦è€…ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹: {subject_id}")
                else:
                    subject_id = best_subject
                    print(f"âœ… è‡ªå‹•é¸æ“‡æœ€ä½³å—è©¦è€…: {subject_id} (å“è³ªåˆ†æ•¸: {best_score:.3f})")
        
        # å‰µå»ºè¶…ä¿å®ˆåˆ†æå™¨
        ultra_analyzer = UltraConservativeLBA()
        
        # æº–å‚™æ•¸æ“š
        data = ultra_analyzer.prepare_subject_data(df, subject_id)
        
        # æª¢æŸ¥æ•¸æ“šå“è³ª
        if data['overall_accuracy'] < 0.45:
            print(f"âš ï¸ è­¦å‘Š: å—è©¦è€… {subject_id} æº–ç¢ºç‡è¼ƒä½ ({data['overall_accuracy']:.1%})")
            print("   é€™å¯èƒ½å½±éŸ¿æ¨¡å‹æ”¶æ–‚ï¼Œå»ºè­°é¸æ“‡å…¶ä»–å—è©¦è€…")
            
            continue_choice = input("æ˜¯å¦ç¹¼çºŒ? (y/n): ").strip().lower()
            if continue_choice != 'y':
                print("åˆ†æå–æ¶ˆ")
                return None
        
        # åŸ·è¡Œè¶…ä¿å®ˆæ¶æ•‘
        print(f"\nğŸ›¡ï¸ é–‹å§‹è¶…ä¿å®ˆæ¶æ•‘...")
        model, trace, results = ultra_analyzer.fit_ultra_conservative(data)
        
        if results['success']:
            if results['converged']:
                print(f"\nğŸ‰ æ¶æ•‘æˆåŠŸ! å®Œç¾æ”¶æ–‚!")
                print(f"   RÌ‚: {results['convergence_diagnostics']['max_rhat']:.3f} (ç›®æ¨™ < 1.05)")
                print(f"   ESS: {results['convergence_diagnostics']['min_ess']:.0f} (ç›®æ¨™ > 200)")
                print(f"   ç™¼æ•£: {results['convergence_diagnostics']['n_divergent']} (ç›®æ¨™ = 0)")
                print(f"   æ¡æ¨£æ™‚é–“: {results['sampling_time_minutes']:.1f} åˆ†é˜")
            else:
                rhat = results['convergence_diagnostics']['max_rhat']
                ess = results['convergence_diagnostics']['min_ess']
                div = results['convergence_diagnostics']['n_divergent']
                
                print(f"\nâœ… æ¶æ•‘éƒ¨åˆ†æˆåŠŸ")
                print(f"   RÌ‚: {rhat:.3f} {'âœ…' if rhat < 1.1 else 'âš ï¸'}")
                print(f"   ESS: {ess:.0f} {'âœ…' if ess > 100 else 'âš ï¸'}")
                print(f"   ç™¼æ•£: {div} {'âœ…' if div == 0 else 'âš ï¸'}")
                print(f"   æ¡æ¨£æ™‚é–“: {results['sampling_time_minutes']:.1f} åˆ†é˜")
                
                if rhat < 1.2 and ess > 50:
                    print("   ğŸ’¡ çµæœå¯ç”¨æ–¼æ¢ç´¢æ€§åˆ†æ")
                else:
                    print("   âš ï¸ å»ºè­°é€²ä¸€æ­¥èª¿æ•´æˆ–å˜—è©¦å…¶ä»–å—è©¦è€…")
            
            return results
        else:
            print(f"\nâŒ æ¶æ•‘å¤±æ•—: {results.get('error', 'Unknown error')}")
            print("ğŸ’¡ å»ºè­°:")
            print("   1. å˜—è©¦å…¶ä»–å—è©¦è€…")
            print("   2. æª¢æŸ¥æ•¸æ“šå“è³ª")
            print("   3. è€ƒæ…®é€²ä¸€æ­¥ç°¡åŒ–æ¨¡å‹")
            return results
            
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {csv_file}")
        print("ğŸ’¡ è«‹ç¢ºä¿æª”æ¡ˆè·¯å¾‘æ­£ç¢º")
        return None
    except Exception as e:
        print(f"âŒ æ¶æ•‘å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_with_previous_results():
    """èˆ‡ä¹‹å‰çµæœæ¯”è¼ƒ"""
    
    print("\nğŸ“Š èˆ‡ä¹‹å‰çµæœæ¯”è¼ƒ")
    print("-" * 40)
    print("ä¹‹å‰çµæœ (å¼·ç´„æŸç­–ç•¥):")
    print("   RÌ‚: 1.640, ESS: 7, ç™¼æ•£: 6, æ™‚é–“: 4.0åˆ†")
    print("   å·¦é€šé“è¾¨åˆ¥: 1.406, å³é€šé“è¾¨åˆ¥: 1.322")
    print("   å°ç¨±æ€§: âœ… æ”¯æŒ")
    print()
    print("è¶…ä¿å®ˆæ¶æ•‘ç›®æ¨™:")
    print("   RÌ‚: < 1.05, ESS: > 200, ç™¼æ•£: 0")
    print("   ä¿æŒåƒæ•¸ä¼°è¨ˆçš„åˆç†æ€§")
    print("   ç¢ºä¿ç†è«–è§£é‡‹çš„æœ‰æ•ˆæ€§")

if __name__ == "__main__":
    print("ğŸš¨ è¶…ä¿å®ˆæ¶æ•‘æ–¹æ¡ˆé¸é …:")
    print("1. é‹è¡Œè¶…ä¿å®ˆæ¶æ•‘ (è‡ªå‹•é¸æ“‡å—è©¦è€…)")
    print("2. é‹è¡Œè¶…ä¿å®ˆæ¶æ•‘ (æŒ‡å®šå—è©¦è€…)")
    print("3. èˆ‡ä¹‹å‰çµæœæ¯”è¼ƒ")
    
    try:
        choice = input("\nè«‹é¸æ“‡ (1-3): ").strip()
        
        if choice == '1':
            print("\nğŸ›¡ï¸ é‹è¡Œè¶…ä¿å®ˆæ¶æ•‘ (è‡ªå‹•é¸æ“‡)...")
            result = run_ultra_conservative_rescue()
            
        elif choice == '2':
            csv_file = input("è«‹è¼¸å…¥CSVæª”æ¡ˆè·¯å¾‘: ").strip()
            subject_id = int(input("è«‹è¼¸å…¥å—è©¦è€…ID: "))
            print(f"\nğŸ›¡ï¸ é‹è¡Œè¶…ä¿å®ˆæ¶æ•‘ (å—è©¦è€… {subject_id})...")
            result = run_ultra_conservative_rescue(csv_file, subject_id)
            
        elif choice == '3':
            compare_with_previous_results()
            
        else:
            print("ç„¡æ•ˆé¸æ“‡")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¶æ•‘è¢«ä¸­æ–·")
    except Exception as e:
        print(f"\nğŸ’¥ éŒ¯èª¤: {e}")

# ============================================================================
# è¶…ä¿å®ˆæ¶æ•‘æ–¹æ¡ˆèªªæ˜
# ============================================================================

"""
ğŸ›¡ï¸ è¶…ä¿å®ˆæ¶æ•‘æ–¹æ¡ˆç‰¹è‰²ï¼š

1. **æ¥µç«¯ä¿å®ˆçš„MCMCè¨­å®š**ï¼š
   - draws=1000, tune=2500 (æ¥µé•·èª¿å„ªæœŸ)
   - chains=6 (æ›´å¤šéˆå¢åŠ ç©©å®šæ€§)
   - target_accept=0.995 (å¹¾ä¹å®Œç¾æ¥å—ç‡)
   - max_treedepth=25 (æ¥µæ·±æ¨¹çµæ§‹)
   - step_scale=0.05 (æ¥µå°æ­¥é•·)

2. **éšå±¤å…ˆé©—çµæ§‹**ï¼š
   - ç¾¤çµ„ç´šåƒæ•¸æ§åˆ¶å€‹åˆ¥åƒæ•¸
   - ä¿ƒé€²å·¦å³é€šé“åƒæ•¸ç›¸ä¼¼æ€§
   - æ¸›å°‘åƒæ•¸ç©ºé–“è¤‡é›œåº¦

3. **è¶…å¼·ç´„æŸ**ï¼š
   - symmetry_weight=0.8 (80%å°ç¨±æ€§)
   - å¼·åˆ¶åƒæ•¸é †åº (match > mismatch)
   - è»Ÿç´„æŸé˜²æ­¢æ¥µç«¯å€¼
   - åˆç†çš„æ•ˆç‡æ¯”ç´„æŸ

4. **æ¥µä¿å®ˆçš„æ•¸å€¼è™•ç†**ï¼š
   - æ›´åš´æ ¼çš„åƒæ•¸é‚Šç•Œ
   - æ›´å°çš„è£å‰ªç¯„åœ (-2.5, 2.5)
   - æ›´é«˜çš„ä¸‹é™é–¾å€¼ (1e-5, 1e-6)
   - é˜²æ­¢ä»»ä½•æ•¸å€¼çˆ†ç‚¸

5. **æ™ºèƒ½å—è©¦è€…é¸æ“‡**ï¼š
   - è‡ªå‹•è¨ˆç®—æ•¸æ“šå“è³ªåˆ†æ•¸
   - åå¥½é«˜æº–ç¢ºç‡ã€è¶³å¤ è©¦é©—æ•¸çš„å—è©¦è€…
   - é¿å…RTè®Šç•°éå¤§çš„æ•¸æ“š

é æœŸæ•ˆæœï¼š
âœ… RÌ‚ < 1.05 (å¾1.640 â†’ <1.05)
âœ… ESS > 200 (å¾7 â†’ >200) 
âœ… ç™¼æ•£æ¨£æœ¬ = 0 (å¾6 â†’ 0)
âœ… ä¿æŒåƒæ•¸ä¼°è¨ˆåˆç†æ€§
âœ… ç¶­æŒç†è«–è§£é‡‹æœ‰æ•ˆæ€§

ä½¿ç”¨å»ºè­°ï¼š
1. é¸æ“‡é¸é …1è®“ç³»çµ±è‡ªå‹•é¸æ“‡æœ€ä½³å—è©¦è€…
2. æº–å‚™ç­‰å¾…10-30åˆ†é˜çš„æ¡æ¨£æ™‚é–“
3. å¦‚æœä»æœ‰å•é¡Œï¼Œè€ƒæ…®ï¼š
   - å˜—è©¦å…¶ä»–å—è©¦è€…
   - é€²ä¸€æ­¥å¢åŠ tuneæ™‚é–“
   - æª¢æŸ¥æ•¸æ“šå“è³ª

é€™å€‹æ–¹æ¡ˆæ˜¯ç›®å‰æœ€ä¿å®ˆçš„è¨­å®šï¼Œå°ˆé–€ç”¨ä¾†è§£æ±ºé ‘å›ºçš„æ”¶æ–‚å•é¡Œï¼
"""