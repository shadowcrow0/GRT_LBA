# ------------------------------------------------------------------
# Enhanced GRT-LBA Analysis with Full Covariance Matrix
# Two-Channel Four-Choice Task with Bayesian Inference
# Fixed Version - No Indentation Errors
# ------------------------------------------------------------------
import pymc as pm
import pandas as pd
import numpy as np
import arviz as az
import pytensor.tensor as pt
import matplotlib.pyplot as plt
import pickle
import os
from datetime import datetime
from scipy.stats import multivariate_normal
import warnings
warnings.filterwarnings('ignore')

# ------------------------------------------------------------------
# 1. Enhanced Two-Channel LBA Log-Likelihood Function
# ------------------------------------------------------------------
def lba_loglike_2channel_enhanced(rt, choice, v, b, A, tau, s=0.1):
    """
    Enhanced LBA log-likelihood for 2-channel, 4-choice task with full covariance.
    """
    epsilon = 1e-8
    n_choices = 4
    
    v_col = v.T
    rt = rt - tau
    rt = pt.clip(rt, epsilon, np.inf)
    mu_v = v_col * rt
    
    B_upper = pt.clip(b, A + epsilon, np.inf)
    
    term1 = (B_upper - A - mu_v) / s
    term2 = (B_upper - mu_v) / s
    
    logp_norm_term1 = pm.logp(pm.Normal.dist(0, 1), term1)
    pdf_term1 = pt.exp(logp_norm_term1)
    cdf_term1 = pm.logcdf(pm.Normal.dist(0,1), term1)
    
    logp_norm_term2 = pm.logp(pm.Normal.dist(0, 1), term2)
    pdf_term2 = pt.exp(logp_norm_term2)
    cdf_term2 = pm.logcdf(pm.Normal.dist(0,1), term2)
    
    single_lk = (v_col * (pt.exp(cdf_term1) - pt.exp(cdf_term2))) + (s * (pdf_term2 - pdf_term1))
    single_lk_clipped = pt.clip(single_lk, epsilon, 1.0)
    
    denom_logp = pm.logcdf(pm.Normal.dist(0, 1), (B_upper - mu_v) / s)
    logp_chosen = pt.log(single_lk_clipped)
    
    total_logp = 0
    total_denom_logp = pt.sum(denom_logp, axis=0)
    for k in range(n_choices):
        mask = pt.eq(choice, k)
        other_logp_sum = total_denom_logp - denom_logp[k]
        total_logp += (logp_chosen[k] + other_logp_sum) * mask
        
    return pt.sum(total_logp - pt.log(A))

# ------------------------------------------------------------------
# 2. Advanced GRT Drift Rate Computation with Full Covariance
# ------------------------------------------------------------------
def compute_grt_drift_rates_with_covariance(stimulus_vals, db1, db2, sigma_matrix):
    """
    Compute GRT drift rates considering full covariance structure.
    Simplified version for computational stability.
    """
    c1, c2 = stimulus_vals[0], stimulus_vals[1]
    
    # Extract variance and covariance components
    var1 = sigma_matrix[0, 0]
    var2 = sigma_matrix[1, 1]
    cov12 = sigma_matrix[0, 1]
    
    # Convert to standard deviations and correlation
    std1 = pt.sqrt(var1)
    std2 = pt.sqrt(var2)
    rho = cov12 / (std1 * std2)
    
    # Standardized distances to decision boundaries
    z1 = (db1 - c1) / std1
    z2 = (db2 - c2) / std2
    
    # Basic probabilities using sigmoid approximation
    p1_below = pm.math.sigmoid(z1)
    p1_above = 1 - p1_below
    p2_below = pm.math.sigmoid(z2)  
    p2_above = 1 - p2_below
    
    # Compute region probabilities with correlation adjustment
    # Region (0,0): both below boundaries
    p_00_base = p1_below * p2_below
    p_00 = p_00_base * (1 + 0.2 * rho)  # Positive correlation increases joint probability
    
    # Region (0,1): ch1 below, ch2 above
    p_01_base = p1_below * p2_above
    p_01 = p_01_base * (1 - 0.2 * rho)  # Negative correlation effect
    
    # Region (1,0): ch1 above, ch2 below
    p_10_base = p1_above * p2_below
    p_10 = p_10_base * (1 - 0.2 * rho)  # Negative correlation effect
    
    # Region (1,1): both above boundaries
    p_11_base = p1_above * p2_above
    p_11 = p_11_base * (1 + 0.2 * rho)  # Positive correlation increases joint probability
    
    # Ensure all probabilities are positive and normalize
    epsilon = 1e-6
    p_00_clipped = pt.clip(p_00, epsilon, 1-epsilon)
    p_01_clipped = pt.clip(p_01, epsilon, 1-epsilon)
    p_10_clipped = pt.clip(p_10, epsilon, 1-epsilon)
    p_11_clipped = pt.clip(p_11, epsilon, 1-epsilon)
    
    # Normalize to sum to 1
    total = p_00_clipped + p_01_clipped + p_10_clipped + p_11_clipped
    
    normalized_rates = [
        p_00_clipped / total,
        p_01_clipped / total,
        p_10_clipped / total,
        p_11_clipped / total
    ]
    
    return normalized_rates

# ------------------------------------------------------------------
# 3. Data Preparation Function
# ------------------------------------------------------------------
def prepare_data(df):
    """
    Prepare data for analysis with stimulus coding.
    """
    df = df.copy()
    
    # Create stimulus mapping: (Ch1, Ch2) -> choice
    df['stimulus_type'] = df['Chanel1'] * 2 + df['Chanel2']
    df['choice'] = df['Response'].astype(int)
    
    # Ensure choices are 0,1,2,3
    if df['choice'].min() == 1:
        df['choice'] = df['choice'] - 1
    
    return df

# ------------------------------------------------------------------
# 4. Enhanced Individual Participant Analysis
# ------------------------------------------------------------------
def analyze_participant_with_covariance(participant_id, df_full, n_samples=1000, n_tune=1000, results_dir=None):
    """
    Enhanced Bayesian GRT-LBA analysis with full covariance matrix.
    """
    print(f"\nüß† Enhanced GRT-LBA Analysis - Participant {participant_id}")
    print("Bayesian inference with full covariance matrix")
    print("="*60)
    
    # Filter and prepare data
    df = df_full[df_full['participant'] == participant_id].copy()
    
    # Check if participant exists and has data
    if len(df) == 0:
        print(f"‚ùå No data found for participant {participant_id}")
        print(f"Available participants: {sorted(df_full['participant'].unique())}")
        return None, None, None
    
    df = prepare_data(df)
    
    # Data validation
    if len(df) < 50:  # Minimum trials needed
        print(f"‚ùå Insufficient data: {len(df)} trials (minimum 50 required)")
        return None, None, None
    
    print(f"üìä Data Summary:")
    print(f"   Total trials: {len(df)}")
    print(f"   RT range: {df['RT'].min():.3f}s - {df['RT'].max():.3f}s")
    print(f"   Choice distribution: {dict(df['choice'].value_counts().sort_index())}")
    
    # Stimulus conditions
    unique_stimuli = df[['Chanel1', 'Chanel2']].drop_duplicates().sort_values(['Chanel1', 'Chanel2'])
    print(f"   Stimulus conditions: {len(unique_stimuli)} types")
    print(unique_stimuli.to_string(index=False))
    
    # Validate stimulus conditions
    if len(unique_stimuli) == 0:
        print(f"‚ùå No stimulus conditions found")
        return None, None, None
    
    # File paths for intelligent caching
    if results_dir:
        idata_path = f"{results_dir}/participant_{participant_id}_covariance_idata.nc"
        # Note: Model object cannot be reliably saved due to pickle limitations
    else:
        idata_path = f"participant_{participant_id}_covariance_idata.nc"
    
    # Check existing results
    if os.path.exists(idata_path):
        print(f"üìÇ Found existing results, loading {idata_path}...")
        try:
            idata = az.from_netcdf(idata_path)
            # Model cannot be loaded from pickle due to functools.partial issues
            model = None  # Will be None but analysis can still proceed
            print("‚úÖ Successfully loaded existing analysis results")
            return model, idata, df
        except Exception as e:
            print(f"‚ö†Ô∏è Loading failed, reanalysing: {e}")
    
    # Build enhanced Bayesian model
    print(f"\nüîß Building enhanced Bayesian model...")
    try:
        with pm.Model() as model:
            print("   üß† Setting GRT parameters...")
            
            # === GRT Parameters with Full Covariance ===
            # Decision boundaries (transformed for unbounded sampling)
            db1_raw = pm.Normal('db1_raw', mu=0, sigma=1)
            db2_raw = pm.Normal('db2_raw', mu=0, sigma=1)
            
            # Transform to [0,1] range
            db1 = pm.Deterministic('db1', pm.math.invlogit(db1_raw))
            db2 = pm.Deterministic('db2', pm.math.invlogit(db2_raw))
            
            # === Perceptual Covariance Matrix (Key Enhancement) ===
            print("   üìä Setting covariance matrix...")
            
            # Standard deviations for each channel
            sigma1 = pm.LogNormal('sigma1', mu=np.log(0.3), sigma=0.3)
            sigma2 = pm.LogNormal('sigma2', mu=np.log(0.3), sigma=0.3)
            
            # Correlation coefficient with Uniform prior for simplicity
            rho = pm.Uniform('rho', lower=-0.8, upper=0.8)  # Slightly constrained for stability
            
            # Construct covariance matrix
            sigma_matrix = pm.Deterministic('sigma_matrix', 
                pt.stack([[sigma1**2, rho*sigma1*sigma2],
                          [rho*sigma1*sigma2, sigma2**2]]))
            
            # Extract interpretable components
            correlation = pm.Deterministic('correlation', rho)
            variance_ch1 = pm.Deterministic('variance_ch1', sigma1**2)
            variance_ch2 = pm.Deterministic('variance_ch2', sigma2**2)
            covariance = pm.Deterministic('covariance', rho*sigma1*sigma2)
            
            # === LBA Parameters ===
            print("   ‚ö° Setting LBA parameters...")
            A = pm.LogNormal('A', mu=np.log(0.4), sigma=0.3)
            b_minus_A = pm.LogNormal('b_minus_A', mu=np.log(0.3), sigma=0.5)
            b = pm.Deterministic('b', A + b_minus_A)
            tau = pm.Uniform('tau', lower=0, upper=df['RT'].quantile(0.1))
            s = pm.LogNormal('s', mu=np.log(0.3), sigma=0.4)
            
            # === Enhanced GRT Drift Rate Computation ===
            print("   üßÆ Computing enhanced GRT drift rates...")
            
            drift_rates = []
            for _, stim in unique_stimuli.iterrows():
                c1, c2 = float(stim['Chanel1']), float(stim['Chanel2'])
                
                # Compute drift rates using simplified but stable approach
                try:
                    stim_drifts = compute_grt_drift_rates_with_covariance(
                        [c1, c2], db1, db2, sigma_matrix
                    )
                    drift_rates.append(pt.stack(stim_drifts))
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Stimulus ({c1},{c2}) computation failed: {e}")
                    # Fallback to simple independent computation
                    epsilon = 1e-6
                    fallback_drifts = [0.25, 0.25, 0.25, 0.25]  # Equal probabilities
                    drift_rates.append(pt.stack([pt.constant(d) for d in fallback_drifts]))
            
            # Check if we have any drift rates
            if not drift_rates:
                print("   ‚ùå No valid drift rates computed")
                return None, None, df
            
            # Organize drift rates by trial
            v_matrix = pt.stack(drift_rates, axis=1)  # Shape: (4_choices, n_stimuli)
            trial_stimuli = df['stimulus_type'].values
            v_trials = v_matrix[:, trial_stimuli].T  # Shape: (n_trials, 4_choices)
            
            # === Likelihood ===
            print("   üìà Setting likelihood function...")
            
            # Define likelihood function with proper naming for PyMC
            def lba_likelihood_logp(value, v, b, A, tau, s):
                """Named likelihood function for PyMC CustomDist"""
                return lba_loglike_2channel_enhanced(value[0], value[1], v, b, A, tau, s)
            
            likelihood = pm.CustomDist(
                'likelihood',
                v_trials, b, A, tau, s,
                logp=lba_likelihood_logp,
                observed=(df['RT'].values, df['choice'].values)
            )
            
            print("   ‚úÖ Model construction complete")
            
    except Exception as e:
        print(f"‚ùå Model construction failed: {e}")
        print(f"Detailed error information:")
        import traceback
        traceback.print_exc()
        return None, None, df

    # === Bayesian MCMC Sampling ===
    try:
        with model:
            print(f"\nüöÄ Starting enhanced Bayesian sampling...")
            print(f"   üìä Settings: {n_tune} tune + {n_samples} samples √ó 4 chains")
            print(f"   üß† Model: GRT + LBA + full covariance matrix")
            print(f"   ‚è±Ô∏è Estimated time: 30-60 minutes")
            print(f"   üíæ Results will be saved to: {idata_path}")
            
            # Test compilation first
            print("   üîß Testing model compilation...")
            with model:
                # Quick test sample
                test_trace = pm.sample(
                    draws=10, 
                    tune=10, 
                    chains=1, 
                    progressbar=False,
                    return_inferencedata=True
                )
            print("   ‚úÖ Model compilation successful!")
            
            # Full sampling
            print("   üöÄ Starting full sampling...")
            idata = pm.sample(
                draws=n_samples,
                tune=n_tune,
                chains=4,
                cores=1,
                target_accept=0.80,  # Lower for stability
                max_treedepth=10,
                init="adapt_diag",   # More robust initialization
                progressbar=True,
                return_inferencedata=True,
                compute_convergence_checks=True
            )
            
            # Save enhanced results
            print(f"\nüíæ Saving enhanced analysis results...")
            az.to_netcdf(idata, idata_path)
            
            # Note: Skip saving the model object due to pickle limitations with PyMC models
            # The model can be reconstructed from the saved parameters if needed
            print("   ‚úÖ Analysis results saved (idata only)")
            print("   ‚ÑπÔ∏è Model object not saved due to pickle limitations")
            
            print("‚úÖ Enhanced Bayesian analysis complete!")
            
    except Exception as e:
        print(f"‚ùå Sampling failed: {e}")
        print("Error details:")
        import traceback
        traceback.print_exc()
        
        # Diagnostic suggestions
        print(f"\nüîç Diagnostic suggestions:")
        print("   1. Check data format is correct")
        print("   2. Try reducing sample size")
        print("   3. Use simpler model version")
        
        return None, None, df
    
    return model, idata, df

# ------------------------------------------------------------------
# 5. GRT Theoretical Analysis Functions
# ------------------------------------------------------------------
def analyze_grt_assumptions_enhanced(idata, participant_id):
    """
    Enhanced GRT theoretical analysis with full covariance insights.
    """
    print(f"\nüß† Enhanced GRT Theoretical Analysis - Participant {participant_id}")
    print("="*60)
    
    # Extract posterior samples safely
    samples = {}
    param_names = ['db1', 'db2', 'correlation', 'sigma1', 'sigma2', 
                   'variance_ch1', 'variance_ch2', 'covariance']
    
    for param in param_names:
        try:
            samples[param] = az.extract(idata, var_names=[param])[param].values
        except Exception as e:
            print(f"‚ö†Ô∏è Cannot extract parameter {param}: {e}")
            continue
    
    results = {}
    
    # === 1. Perceptual Independence Analysis ===
    print("\n1Ô∏è‚É£ Perceptual Independence Analysis")
    if 'correlation' in samples:
        try:
            rho_samples = samples['correlation']
            rho_mean = float(np.mean(rho_samples))
            rho_ci = np.percentile(rho_samples, [2.5, 97.5])
            
            # Independence test: |œÅ| significantly different from 0?
            independent = abs(rho_mean) < 0.1 and 0 >= rho_ci[0] and 0 <= rho_ci[1]
            
            print(f"   Correlation coefficient œÅ: {rho_mean:.3f} [{rho_ci[0]:.3f}, {rho_ci[1]:.3f}]")
            
            if independent:
                print("   ‚úÖ Supports perceptual independence hypothesis")
                print("   ‚Üí Two channels processed independently at perceptual level")
            else:
                if rho_mean > 0:
                    print("   ‚ùå Perceptual positive correlation")
                    print("   ‚Üí Channels exhibit positive coupling (shared enhancement/inhibition)")
                else:
                    print("   ‚ùå Perceptual negative correlation") 
                    print("   ‚Üí Channels exhibit competitive inhibition mechanism")
            
            # Correlation strength interpretation
            abs_rho = abs(rho_mean)
            if abs_rho < 0.1:
                strength = "negligible"
            elif abs_rho < 0.3:
                strength = "weak"
            elif abs_rho < 0.5:
                strength = "moderate"
            else:
                strength = "strong"
            
            print(f"   Strength: {strength} correlation")
            
            results['independence'] = {
                'independent': independent,
                'correlation_mean': rho_mean,
                'correlation_ci': rho_ci.tolist(),
                'strength': strength
            }
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error in independence analysis: {e}")
    
    # === 2. Decision Boundary Analysis ===
    print(f"\n2Ô∏è‚É£ Decision Boundary Analysis")
    if 'db1' in samples and 'db2' in samples:
        try:
            db1_mean = float(np.mean(samples['db1']))
            db2_mean = float(np.mean(samples['db2']))
            db1_ci = np.percentile(samples['db1'], [2.5, 97.5])
            db2_ci = np.percentile(samples['db2'], [2.5, 97.5])
            
            print(f"   Channel 1 boundary: {db1_mean:.3f} [{db1_ci[0]:.3f}, {db1_ci[1]:.3f}]")
            print(f"   Channel 2 boundary: {db2_mean:.3f} [{db2_ci[0]:.3f}, {db2_ci[1]:.3f}]")
            
            # Bias analysis (deviation from optimal 0.5)
            db1_bias = abs(db1_mean - 0.5)
            db2_bias = abs(db2_mean - 0.5)
            
            bias1_direction = "conservative" if db1_mean > 0.5 else "liberal"
            bias2_direction = "conservative" if db2_mean > 0.5 else "liberal"
            
            print(f"   Channel 1 bias: {db1_bias:.3f} ({bias1_direction})")
            print(f"   Channel 2 bias: {db2_bias:.3f} ({bias2_direction})")
            
            # Asymmetry analysis
            if abs(db1_bias - db2_bias) > 0.1:
                print("   ‚ö†Ô∏è Asymmetric bias between channels")
            else:
                print("   ‚úÖ Symmetric bias across channels")
            
            results['boundaries'] = {
                'db1_mean': db1_mean, 'db1_ci': db1_ci.tolist(), 'db1_bias': db1_bias,
                'db2_mean': db2_mean, 'db2_ci': db2_ci.tolist(), 'db2_bias': db2_bias
            }
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error in boundary analysis: {e}")
    
    # === 3. Perceptual Noise Analysis ===
    print(f"\n3Ô∏è‚É£ Perceptual Noise Analysis")
    if 'sigma1' in samples and 'sigma2' in samples:
        try:
            sigma1_mean = float(np.mean(samples['sigma1']))
            sigma2_mean = float(np.mean(samples['sigma2']))
            
            print(f"   Channel 1 standard deviation: {sigma1_mean:.3f}")
            print(f"   Channel 2 standard deviation: {sigma2_mean:.3f}")
            
            # Noise asymmetry
            noise_ratio = sigma1_mean / sigma2_mean
            print(f"   Noise ratio: {noise_ratio:.3f}")
            
            if abs(noise_ratio - 1) < 0.2:
                print("   ‚úÖ Equal channel noise")
            elif noise_ratio > 1.2:
                print("   ‚ö†Ô∏è Channel 1 has higher noise")
            else:
                print("   ‚ö†Ô∏è Channel 2 has higher noise")
            
            results['noise'] = {
                'sigma1': sigma1_mean, 'sigma2': sigma2_mean,
                'ratio': noise_ratio
            }
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error in noise analysis: {e}")
    
    # === 4. Cognitive Strategy Classification ===
    print(f"\n4Ô∏è‚É£ Cognitive Strategy Classification")
    
    try:
        independent = results.get('independence', {}).get('independent', False)
        rho_mean = results.get('independence', {}).get('correlation_mean', 0)
        
        if independent:
            db1_bias = results.get('boundaries', {}).get('db1_bias', 0)
            db2_bias = results.get('boundaries', {}).get('db2_bias', 0)
            if db1_bias < 0.1 and db2_bias < 0.1:
                strategy = "Optimal Independent Processing"
                print("   üéØ Strategy: Optimal Independent Processing")
                print("   ‚Üí Fully independent and near-optimal dual-channel processing")
            else:
                strategy = "Suboptimal Independent Processing"
                print("   üéØ Strategy: Suboptimal Independent Processing")
                print("   ‚Üí Independent processing but with systematic biases")
        else:
            if abs(rho_mean) < 0.3:
                strategy = "Weak Coupling Processing"
                print("   üéØ Strategy: Weak Coupling Processing")
                coupling_type = "cooperation" if rho_mean > 0 else "competition"
                print(f"   ‚Üí Slight inter-channel {coupling_type}")
            else:
                strategy = "Strong Coupling Processing"  
                print("   üéØ Strategy: Strong Coupling Processing")
                coupling_type = "integration" if rho_mean > 0 else "inhibition"
                print(f"   ‚Üí Significant inter-channel {coupling_type}")
        
        results['strategy'] = strategy
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error in strategy classification: {e}")
        results['strategy'] = "Classification Error"
    
    # === 5. Uncertainty Quantification ===
    print(f"\n5Ô∏è‚É£ Uncertainty Quantification")
    
    if 'correlation' in samples:
        try:
            rho_uncertainty = float(np.std(samples['correlation']))
            print(f"   Correlation coefficient uncertainty: ¬±{rho_uncertainty:.3f}")
            
            if rho_uncertainty > 0.2:
                print("   ‚ö†Ô∏è High correlation uncertainty, consider more data")
            else:
                print("   ‚úÖ Stable correlation estimate")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error in uncertainty quantification: {e}")
    
    return results

# ------------------------------------------------------------------
# 6. Enhanced Batch Analysis  
# ------------------------------------------------------------------
def batch_analysis_with_covariance(csv_file, participants=None, save_results=True, 
                                  n_samples=1000, n_tune=1000):
    """
    Enhanced batch analysis with full covariance matrix and robust error handling.
    """
    try:
        df_full = pd.read_csv(csv_file)
        print(f"üìä Data loaded successfully: {len(df_full)} trials")
    except FileNotFoundError:
        print(f"‚ùå Error: File '{csv_file}' not found")
        return None
    
    # Data validation
    print(f"üîç Data validation:")
    print(f"   Total participants in data: {df_full['participant'].nunique()}")
    print(f"   Available participants: {sorted(df_full['participant'].unique())}")
    
    if participants is None:
        participants = sorted(df_full['participant'].unique())
    
    # Filter participants with sufficient data
    valid_participants = []
    for p_id in participants:
        p_data = df_full[df_full['participant'] == p_id]
        if len(p_data) >= 50:  # Minimum trials threshold
            valid_participants.append(p_id)
        else:
            print(f"   ‚ö†Ô∏è Participant {p_id}: {len(p_data)} trials (too few, skipping)")
    
    if not valid_participants:
        print("‚ùå No participants with sufficient data found")
        return None
    
    print(f"\nüöÄ Enhanced Batch Analysis (with full covariance)")
    print(f"   Valid participants: {len(valid_participants)} out of {len(participants)}")
    print(f"   Participant list: {valid_participants}")
    print(f"   MCMC settings: {n_tune} tune + {n_samples} samples √ó 4 chains")
    print(f"   Model: GRT + LBA + covariance matrix")
    
    results = {}
    
    if save_results:
        results_dir = f"enhanced_grt_lba_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(results_dir, exist_ok=True)
        print(f"üíæ Results directory: {results_dir}")
    else:
        results_dir = None
    
    successful = 0
    for i, participant_id in enumerate(valid_participants):
        start_time = datetime.now()
        print(f"\n{'='*70}")
        print(f"üìä Progress: {i+1}/{len(valid_participants)} - Participant {participant_id}")
        print(f"{'='*70}")
        
        try:
            model, idata, df = analyze_participant_with_covariance(
                participant_id, df_full, n_samples=n_samples, 
                n_tune=n_tune, results_dir=results_dir
            )
            
            if idata is None:  # Only check idata since model might be None due to pickle issues
                print(f"‚ùå Analysis failed for participant {participant_id}")
                results[participant_id] = {'error': 'Sampling failed', 'status': 'failed'}
                continue
            
            # Extract posterior samples safely
            try:
                divergences = int(idata.sample_stats.diverging.sum().item())
                
                # Get R-hat and ESS values more carefully
                rhat_values = az.rhat(idata)
                if hasattr(rhat_values, 'max'):
                    max_rhat = float(rhat_values.max().values)
                else:
                    # Handle case where rhat might return different structure
                    max_rhat = float(max([float(v.max()) for v in rhat_values.data_vars.values()]))
                
                ess_values = az.ess(idata)
                if hasattr(ess_values, 'min'):
                    min_ess = float(ess_values.min().values)
                else:
                    # Handle case where ess might return different structure
                    min_ess = float(min([float(v.min()) for v in ess_values.data_vars.values()]))
                    
            except Exception as diag_error:
                print(f"‚ö†Ô∏è Error extracting diagnostics: {diag_error}")
                divergences = 0
                max_rhat = 1.0
                min_ess = 1000.0
            
            print(f"\nüìà Bayesian Diagnostics:")
            div_status = "‚úÖ" if divergences < 100 else "‚ö†Ô∏è"
            rhat_status = "‚úÖ" if max_rhat < 1.1 else "‚ö†Ô∏è"
            ess_status = "‚úÖ" if min_ess > 400 else "‚ö†Ô∏è"
            
            print(f"   Divergences: {divergences} {div_status}")
            print(f"   Max RÃÇ: {max_rhat:.3f} {rhat_status}")
            print(f"   Min ESS: {min_ess:.0f} {ess_status}")
            
            # GRT theoretical analysis with better error handling
            try:
                print(f"\nüß† Starting GRT theoretical analysis...")
                grt_results = analyze_grt_assumptions_enhanced(idata, participant_id)
                print(f"‚úÖ GRT analysis completed successfully")
            except Exception as grt_error:
                print(f"‚ùå GRT analysis failed: {grt_error}")
                print("   Detailed error:")
                import traceback
                traceback.print_exc()
                print("   Continuing with basic diagnostics only...")
                grt_results = {'error': str(grt_error)}
                
                # Try a simpler alternative analysis
                print(f"\nüîß Attempting simplified analysis...")
                try:
                    simple_results = {}
                    # Try to extract just basic parameters
                    if 'correlation' in idata.posterior.data_vars:
                        corr_samples = idata.posterior['correlation'].values
                        simple_results['correlation_mean'] = float(np.mean(corr_samples))
                        print(f"   Correlation estimate: {simple_results['correlation_mean']:.3f}")
                    
                    if 'db1' in idata.posterior.data_vars:
                        db1_samples = idata.posterior['db1'].values
                        simple_results['db1_mean'] = float(np.mean(db1_samples))
                        print(f"   DB1 estimate: {simple_results['db1_mean']:.3f}")
                    
                    if 'db2' in idata.posterior.data_vars:
                        db2_samples = idata.posterior['db2'].values
                        simple_results['db2_mean'] = float(np.mean(db2_samples))
                        print(f"   DB2 estimate: {simple_results['db2_mean']:.3f}")
                        
                    grt_results.update(simple_results)
                    
                except Exception as simple_error:
                    print(f"   Even simplified analysis failed: {simple_error}")
            
            results[participant_id] = {
                'model': model, 'idata': idata, 'data': df,
                'grt_analysis': grt_results,
                'diagnostics': {
                    'divergences': divergences,
                    'max_rhat': max_rhat,
                    'min_ess': min_ess
                },
                'status': 'success'
            }
            
            successful += 1
            elapsed = datetime.now() - start_time
            print(f"‚è±Ô∏è Analysis time: {elapsed}")
            print(f"‚úÖ Participant {participant_id} analysis completed successfully")
            
        except Exception as e:
            print(f"‚ùå Analysis failed: {e}")
            results[participant_id] = {'error': str(e), 'status': 'failed'}
    
    print(f"\nüéâ Batch analysis complete!")
    print(f"   ‚úÖ Successful: {successful}/{len(valid_participants)}")
    print(f"   ‚ùå Failed: {len(valid_participants) - successful}/{len(valid_participants)}")
    
    return results

# ------------------------------------------------------------------
# 7. Main Execution with Enhanced Options
# ------------------------------------------------------------------
if __name__ == "__main__":
    csv_file = 'GRT_LBA.csv'
    
    # First, let's check what participants are actually in the data
    print("üîç Data Exploration")
    print("="*50)
    
    try:
        df_check = pd.read_csv(csv_file)
        print(f"‚úÖ File loaded: {len(df_check)} total trials")
        
        # Check participant distribution
        participant_counts = df_check['participant'].value_counts().sort_index()
        print(f"\nParticipant trial counts:")
        for p_id, count in participant_counts.items():
            status = "‚úÖ" if count >= 50 else "‚ùå"
            print(f"   Participant {p_id}: {count} trials {status}")
        
        # Filter valid participants
        valid_participants = participant_counts[participant_counts >= 50].index.tolist()
        print(f"\nValid participants (‚â•50 trials): {valid_participants}")
        
        if not valid_participants:
            print("‚ùå No participants with sufficient data found!")
            print("üí° Suggestion: Check your data file and participant coding")
            exit()
            
    except FileNotFoundError:
        print(f"‚ùå Error: File '{csv_file}' not found")
        print("üí° Please ensure the CSV file is in the current directory")
        exit()
    except Exception as e:
        print(f"‚ùå Error reading data: {e}")
        exit()
    
    # Updated participant lists based on actual data
    test_participants = valid_participants[:1] if valid_participants else []
    all_participants = valid_participants
    
    # MCMC settings
    mcmc_settings = {
        'n_samples': 1000,  # Reduced for faster testing
        'n_tune': 800       # Sufficient tuning
    }
    
    print("\nüöÄ Enhanced GRT-LBA Bayesian Analysis System")
    print("Full covariance matrix perceptual decision model")
    print("="*80)
    print("üß† Model Features:")
    print("   ‚Ä¢ General Recognition Theory (GRT)")
    print("   ‚Ä¢ Linear Ballistic Accumulator (LBA)")  
    print("   ‚Ä¢ Full 2√ó2 covariance matrix")
    print("   ‚Ä¢ Perceptual independence & separability tests")
    print("   ‚Ä¢ Cognitive strategy classification")
    print("="*80)
    
    print("\nüéõÔ∏è Analysis Options:")
    print("1 - üß™ Test analysis (first valid participant, quick validation)")
    print("2 - üè≠ Full batch analysis (all valid participants)")
    print("3 - üìä Load existing results for analysis")
    print("4 - ‚öôÔ∏è Custom parameter analysis")
    
    choice = input("\nSelect option (1-4): ").strip()
    
    if choice == "1":
        if not test_participants:
            print("‚ùå No valid participants for testing")
            exit()
            
        print(f"\nüß™ Running test analysis...")
        print(f"   Model: Enhanced GRT-LBA (with covariance)")
        print(f"   Participant: {test_participants[0]}")
        print(f"   Estimated time: 30-60 minutes")
        
        results = batch_analysis_with_covariance(
            csv_file=csv_file,
            participants=test_participants,
            save_results=True,
            **mcmc_settings
        )
        
        if results and test_participants[0] in results:
            participant_id = test_participants[0]
            result_data = results[participant_id]
            
            if result_data.get('status') == 'success':
                print(f"\nüéØ Test analysis successfully completed!")
                
                # Enhanced diagnostics display
                idata = result_data['idata']
                diagnostics = result_data.get('diagnostics', {})
                grt_analysis = result_data.get('grt_analysis', {})
                
                print(f"\nüìä Model Diagnostics:")
                print(f"   Divergences: {diagnostics.get('divergences', 'Unknown')}")
                print(f"   Max RÃÇ: {diagnostics.get('max_rhat', 'Unknown')}")
                print(f"   Min ESS: {diagnostics.get('min_ess', 'Unknown')}")
                
                # Check if GRT analysis was successful
                if 'error' in grt_analysis:
                    print(f"\n‚ö†Ô∏è GRT Analysis encountered errors:")
                    print(f"   Error: {grt_analysis['error']}")
                    
                    # Show any simplified results that were extracted
                    if 'correlation_mean' in grt_analysis:
                        print(f"\nüìä Basic Parameter Estimates:")
                        print(f"   Correlation: {grt_analysis['correlation_mean']:.3f}")
                    if 'db1_mean' in grt_analysis:
                        print(f"   Decision Boundary 1: {grt_analysis['db1_mean']:.3f}")
                    if 'db2_mean' in grt_analysis:
                        print(f"   Decision Boundary 2: {grt_analysis['db2_mean']:.3f}")
                        
                else:
                    print(f"\nüß† GRT Analysis Summary:")
                    if 'independence' in grt_analysis:
                        ind = grt_analysis['independence']
                        independence_status = "‚úÖ Independent" if ind.get('independent', False) else "‚ùå Correlated"
                        print(f"   Perceptual independence: {independence_status}")
                        if 'correlation_mean' in ind:
                            print(f"   Correlation coefficient: {ind['correlation_mean']:.3f}")
                    
                    if 'strategy' in grt_analysis:
                        print(f"   Cognitive strategy: {grt_analysis['strategy']}")
                
                # Try to show what parameters are available in the results
                print(f"\nüìã Available parameters in results:")
                try:
                    param_list = list(idata.posterior.data_vars.keys())
                    print(f"   Parameters: {param_list}")
                except:
                    print(f"   Could not list parameters")
                
                print(f"\n‚úÖ Analysis data successfully saved and can be reloaded")
                
            else:
                print(f"\n‚ùå Test analysis failed for participant {participant_id}")
                if 'error' in result_data:
                    print(f"   Error: {result_data['error']}")
                    
        else:
            print("‚ùå Test analysis failed - no results generated")
                fig, axes = plt.subplots(2, 3, figsize=(15, 10))
                
                # Trace plots for key parameters
                az.plot_trace(idata, var_names=['db1', 'db2'], axes=axes[0, :2], compact=True)
                axes[0, 2].axis('off')  # Remove empty subplot
                
                # Posterior distributions for covariance components
                if 'correlation' in [var for var in idata.posterior.data_vars]:
                    az.plot_posterior(idata, var_names=['correlation', 'sigma1', 'sigma2'], 
                                    ax=axes[1, :], textsize=10)
                else:
                    print("‚ö†Ô∏è Correlation parameter not found in results")
                
                plt.suptitle(f"Enhanced GRT-LBA Analysis - Participant {test_participants[0]}", 
                            fontsize=14, y=0.98)
                plt.tight_layout()
                plt.show()
                
                # 2. GRT theoretical space visualization
                plt.figure(figsize=(10, 8))
                
                # Plot decision boundaries and regions
                db1_mean = np.mean(az.extract(idata, var_names=['db1'])['db1'].values)
                db2_mean = np.mean(az.extract(idata, var_names=['db2'])['db2'].values)
                
                # Create perceptual space
                x = np.linspace(-0.5, 1.5, 100)
                y = np.linspace(-0.5, 1.5, 100)
                X, Y = np.meshgrid(x, y)
                
                # Plot decision regions
                Z = (X > db1_mean).astype(int) + 2*(Y > db2_mean).astype(int)
                plt.contourf(X, Y, Z, levels=[0, 1, 2, 3, 4], alpha=0.3, 
                           colors=['lightblue', 'lightgreen', 'lightyellow', 'lightcoral'])
                
                # Plot stimulus locations
                stimulus_points = [(0, 0), (0, 1), (1, 0), (1, 1)]
                colors = ['purple', 'orange', 'cyan', 'magenta']
                labels = ['(0,0)', '(0,1)', '(1,0)', '(1,1)']
                
                for i, (sx, sy) in enumerate(stimulus_points):
                    plt.scatter(sx, sy, c=colors[i], s=200, marker='o', 
                              label=f'Stimulus {labels[i]}', edgecolor='black', linewidth=2)
                
                # Decision boundaries
                plt.axvline(db1_mean, color='red', linestyle='--', linewidth=2, 
                           label=f'DB1 = {db1_mean:.3f}')
                plt.axhline(db2_mean, color='blue', linestyle='--', linewidth=2, 
                           label=f'DB2 = {db2_mean:.3f}')
                
                plt.xlabel('Channel 1 (Left Line Rotation)')
                plt.ylabel('Channel 2 (Right Line Rotation)')
                plt.title('GRT Perceptual Space and Decision Boundaries')
                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                plt.grid(True, alpha=0.3)
                plt.xlim(-0.2, 1.2)
                plt.ylim(-0.2, 1.2)
                plt.tight_layout()
                plt.show()
                
            except Exception as e:
                print(f"‚ö†Ô∏è Visualization generation partially failed: {e}")
        
        else:
            print("‚ùå Test analysis failed")
    
    elif choice == "2":
        print(f"\nüè≠ Running full batch analysis...")
        print(f"   Number of participants: {len(all_participants)}")
        print(f"   Estimated total time: {len(all_participants) * 45 // 60:.1f} hours")
        print(f"   Recommendation: Use screen or tmux for background execution")
        
        confirm = input(f"\n‚ö†Ô∏è This will require significant computation time, continue? (y/n): ")
        if confirm.lower() == 'y':
            results = batch_analysis_with_covariance(
                csv_file=csv_file,
                participants=all_participants,
                save_results=True,
                **mcmc_settings
            )
            
            if results:
                successful = sum(1 for r in results.values() if r.get('status') == 'success')
                print(f"\nüéä Batch analysis complete!")
                print(f"   ‚úÖ Successful: {successful}/{len(all_participants)} participants")
                print(f"   ‚ùå Failed: {len(all_participants) - successful}/{len(all_participants)} participants")
                
                # Generate group analysis
                print(f"\nüìä Generating group analysis...")
                group_strategies = {}
                group_correlations = []
                
                for p_id, result in results.items():
                    if result.get('status') == 'success' and 'grt_analysis' in result:
                        grt = result['grt_analysis']
                        if 'strategy' in grt:
                            strategy = grt['strategy']
                            group_strategies[strategy] = group_strategies.get(strategy, 0) + 1
                        
                        if 'independence' in grt:
                            group_correlations.append(grt['independence']['correlation_mean'])
                
                print(f"\nüìã Group cognitive strategy distribution:")
                for strategy, count in group_strategies.items():
                    percentage = count / successful * 100
                    print(f"   {strategy}: {count} participants ({percentage:.1f}%)")
                
                if group_correlations:
                    print(f"\nüìã Group perceptual correlations:")
                    print(f"   Mean correlation coefficient: {np.mean(group_correlations):.3f}")
                    print(f"   Standard deviation: {np.std(group_correlations):.3f}")
                    print(f"   Range: [{np.min(group_correlations):.3f}, {np.max(group_correlations):.3f}]")
        else:
            print("üö´ Batch analysis cancelled")
    
    elif choice == "3":
        results_dir = input(f"\nüìÅ Enter results directory path: ").strip()
        if os.path.exists(results_dir):
            print(f"üìä Loading enhanced analysis results...")
            
            # Find all participant files
            participant_files = [f for f in os.listdir(results_dir) if f.endswith('_covariance_idata.nc')]
            participants_found = []
            
            for file in participant_files:
                try:
                    p_id = int(file.split('_')[1])
                    participants_found.append(p_id)
                except:
                    continue
            
            participants_found.sort()
            print(f"   Found {len(participants_found)} participant results")
            
            # Load and analyze each participant
            enhanced_results = {}
            for p_id in participants_found:
                try:
                    idata_path = f"{results_dir}/participant_{p_id}_covariance_idata.nc"
                    idata = az.from_netcdf(idata_path)
                    grt_analysis = analyze_grt_assumptions_enhanced(idata, p_id)
                    enhanced_results[p_id] = {
                        'idata': idata,
                        'grt_analysis': grt_analysis
                    }
                    print(f"   ‚úÖ Loaded participant {p_id}")
                except Exception as e:
                    print(f"   ‚ùå Failed to load participant {p_id}: {e}")
            
            if enhanced_results:
                print(f"\nüìä Generating group comparison analysis...")
                
                # Extract group statistics
                correlations = []
                strategies = []
                boundary_biases = []
                
                for p_id, result in enhanced_results.items():
                    grt = result['grt_analysis']
                    if 'independence' in grt:
                        correlations.append(grt['independence']['correlation_mean'])
                    if 'strategy' in grt:
                        strategies.append(grt['strategy'])
                    if 'boundaries' in grt:
                        b = grt['boundaries']
                        avg_bias = (b['db1_bias'] + b['db2_bias']) / 2
                        boundary_biases.append(avg_bias)
                
                # Visualization
                fig, axes = plt.subplots(2, 2, figsize=(12, 10))
                
                # 1. Correlation distribution
                if correlations:
                    axes[0, 0].hist(correlations, bins=15, alpha=0.7, edgecolor='black')
                    axes[0, 0].axvline(0, color='red', linestyle='--', 
                                      label='Independence (œÅ=0)')
                    axes[0, 0].set_xlabel('Perceptual Correlation (œÅ)')
                    axes[0, 0].set_ylabel('Number of Participants')
                    axes[0, 0].set_title('Distribution of Perceptual Correlations')
                    axes[0, 0].legend()
                
                # 2. Strategy distribution
                if strategies:
                    strategy_counts = {s: strategies.count(s) for s in set(strategies)}
                    axes[0, 1].pie(strategy_counts.values(), labels=strategy_counts.keys(), 
                                  autopct='%1.1f%%', startangle=90)
                    axes[0, 1].set_title('Cognitive Strategy Distribution')
                
                # 3. Correlation vs boundary bias
                if correlations and boundary_biases:
                    axes[1, 0].scatter(correlations, boundary_biases, alpha=0.7)
                    axes[1, 0].set_xlabel('Perceptual Correlation')
                    axes[1, 0].set_ylabel('Average Boundary Bias')
                    axes[1, 0].set_title('Correlation vs Decision Bias')
                
                # 4. Individual differences
                if len(enhanced_results) > 1:
                    participant_ids = list(enhanced_results.keys())
                    if correlations:
                        axes[1, 1].plot(participant_ids, correlations, 'o-', alpha=0.7)
                        axes[1, 1].set_xlabel('Participant ID')
                        axes[1, 1].set_ylabel('Perceptual Correlation')
                        axes[1, 1].set_title('Individual Differences in Correlation')
                        axes[1, 1].tick_params(axis='x', rotation=45)
                
                plt.tight_layout()
                plt.savefig(f"{results_dir}/enhanced_group_analysis.png", dpi=300, bbox_inches='tight')
                plt.show()
                
                print(f"‚úÖ Group analysis complete, charts saved")
        else:
            print("‚ùå Directory does not exist")
    
    elif choice == "4":
        print(f"\n‚öôÔ∏è Custom parameter analysis")
        
        # Custom participant selection
        print(f"Available participants: {valid_participants}")
        custom_input = input("Participant IDs (comma-separated): ").strip()
        try:
            custom_participants = [int(x.strip()) for x in custom_input.split(',')]
            # Validate participants
            custom_participants = [p for p in custom_participants if p in valid_participants]
            if not custom_participants:
                print("‚ùå No valid participants selected, using first available")
                custom_participants = valid_participants[:1]
        except:
            print("‚ùå Input format error, using default")
            custom_participants = valid_participants[:1]
        
        # Custom MCMC settings
        try:
            custom_tune = int(input(f"Tune samples (default {mcmc_settings['n_tune']}): ") or mcmc_settings['n_tune'])
            custom_samples = int(input(f"Draw samples (default {mcmc_settings['n_samples']}): ") or mcmc_settings['n_samples'])
        except:
            custom_tune = mcmc_settings['n_tune']
            custom_samples = mcmc_settings['n_samples']
        
        print(f"\n‚öôÔ∏è Custom settings:")
        print(f"   Participants: {custom_participants}")
        print(f"   MCMC: {custom_tune} tune + {custom_samples} samples")
        
        results = batch_analysis_with_covariance(
            csv_file=csv_file,
            participants=custom_participants,
            save_results=True,
            n_tune=custom_tune,
            n_samples=custom_samples
        )
        
        if results:
            successful = sum(1 for r in results.values() if r.get('status') == 'success')
            print(f"\n‚úÖ Custom analysis complete: {successful}/{len(custom_participants)} participants")
    
    else:
        print("‚ùå Invalid selection, running default test")
        choice = "1"
    
    print(f"\n" + "="*80)
    print("‚ú® Enhanced GRT-LBA Bayesian Analysis Complete!")
    print("="*80)
    print(f"\nüéì Theoretical Contributions:")
    print("   ‚Ä¢ Quantitative tests of perceptual independence")
    print("   ‚Ä¢ Precise estimation of inter-channel correlations")
    print("   ‚Ä¢ Objective classification of cognitive strategies")
    print("   ‚Ä¢ Bayesian quantification of individual differences")
    print(f"\nüí° Next Steps Recommendations:")
    print("   ‚Ä¢ Use az.compare() for model comparison")
    print("   ‚Ä¢ Conduct posterior predictive checks (PPC)")
    print("   ‚Ä¢ Analyze conditional effects and learning curves")
    print("   ‚Ä¢ Investigate group-level hierarchical models")
