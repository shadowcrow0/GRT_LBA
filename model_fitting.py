# -*- coding: utf-8 -*-
"""
model_fitting.py - åºåˆ—LBAæ¨¡å‹æ“¬åˆå™¨
Sequential Processing LBA - Model Fitting Module

é‡æ–°è¨­è¨ˆçš„å®Œæ•´åŠŸèƒ½ï¼š
- å–®ä¸€å’Œæ‰¹æ¬¡å—è©¦è€…æ“¬åˆ
- å®Œæ•´çš„æ”¶æ–‚è¨ºæ–·
- åƒæ•¸ä¼°è¨ˆå’Œæ¨¡å‹è©•ä¼°
- çµæœå„²å­˜å’Œç®¡ç†
- éŒ¯èª¤è™•ç†å’Œæ¢å¾©
"""

import numpy as np
import pandas as pd
import pymc as pm
import arviz as az
import time
import warnings
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union
from sequential_model import SequentialLBA

warnings.filterwarnings('ignore')

class SequentialModelFitter:
    """åºåˆ—LBAæ¨¡å‹æ“¬åˆå™¨"""
    
    def __init__(self, first_side='left', time_split_ratio=0.6, mcmc_config=None):
        """
        åˆå§‹åŒ–åºåˆ—æ¨¡å‹æ“¬åˆå™¨
        
        Args:
            first_side: é¦–å…ˆè™•ç†çš„é€šé“ ('left' æˆ– 'right')
            time_split_ratio: æ™‚é–“åˆ†å‰²æ¯”ä¾‹ (0-1)
            mcmc_config: MCMCé…ç½®å­—å…¸
        """
        
        # åˆå§‹åŒ–åºåˆ—LBAæ¨¡å‹
        self.model = SequentialLBA(first_side, time_split_ratio)
        
        # è¨­å®šMCMCé…ç½®
        self.mcmc_config = self._setup_mcmc_config(mcmc_config)
        
        # è¨­å®šæ”¶æ–‚æ¨™æº–
        self.convergence_thresholds = self._setup_convergence_thresholds()
        
        print(f"âœ… åºåˆ—LBAæ“¬åˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è™•ç†é †åº: {self.model.first_side} å…ˆè™•ç†")
        print(f"   æ™‚é–“åˆ†å‰²: {self.model.time_split_ratio:.1%}")
        print(f"   MCMCè¨­å®š: {self.mcmc_config['draws']} draws Ã— {self.mcmc_config['chains']} chains")
        print(f"   ç¸½åƒæ•¸æ•¸: {len(self.model.all_param_names)}")
    
    def _setup_mcmc_config(self, user_config):
        """è¨­å®šMCMCé…ç½®"""
        
        default_config = {
            'draws': 400,
            'tune': 400,
            'chains': 2,
            'cores': 1,
            'target_accept': 0.85,
            'max_treedepth': 8,
            'init': 'jitter+adapt_diag',
            'random_seed': 42,
            'progressbar': True,
            'return_inferencedata': True
        }
        
        if user_config:
            default_config.update(user_config)
        
        return default_config
    
    def _setup_convergence_thresholds(self):
        """è¨­å®šæ”¶æ–‚è¨ºæ–·æ¨™æº–"""
        
        return {
            'rhat_good': 1.01,
            'rhat_acceptable': 1.05,
            'rhat_problematic': 1.10,
            'ess_minimum': 100,
            'ess_good': 400,
            'max_divergent': 0,
            'energy_threshold': 0.3
        }
    
    def fit_subject(self, subject_data, verbose=True):
        """
        æ“¬åˆå–®ä¸€å—è©¦è€…
        
        Args:
            subject_data: å—è©¦è€…è³‡æ–™å­—å…¸
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°è¨Šæ¯
            
        Returns:
            dict: å®Œæ•´æ“¬åˆçµæœ
        """
        
        subject_id = subject_data['subject_id']
        start_time = time.time()
        
        if verbose:
            print(f"\nğŸ”§ æ“¬åˆå—è©¦è€… {subject_id}")
            print(f"   è©¦é©—æ•¸: {subject_data['n_trials']}")
            print(f"   æº–ç¢ºç‡: {subject_data['accuracy']:.1%}")
            print(f"   å¹³å‡RT: {np.mean(subject_data['rt']):.3f}s")
        
        # åŸºæœ¬çµæœçµæ§‹
        result = {
            'subject_id': subject_id,
            'success': False,
            'converged': False,
            'error': None,
            'sampling_time_minutes': 0.0,
            'n_trials': subject_data['n_trials'],
            'model_config': self.model.get_model_info(),
            'mcmc_config': self.mcmc_config
        }
        
        try:
            # 1. è³‡æ–™é©—è­‰
            if not self._validate_subject_data(subject_data, verbose):
                result['error'] = 'Data validation failed'
                return result
            
            # 2. æ¨¡å‹å»ºæ§‹
            if verbose:
                print("   ğŸ”§ å»ºæ§‹PyMCæ¨¡å‹...")
            
            pymc_model = self.model.build_model(subject_data)
            
            # 3. æ¨¡å‹é©—è­‰
            if not self._validate_model(pymc_model, verbose):
                result['error'] = 'Model validation failed'
                return result
            
            # 4. MCMCæ¡æ¨£
            if verbose:
                print("   ğŸ² åŸ·è¡ŒMCMCæ¡æ¨£...")
            
            trace = self._run_mcmc_sampling(pymc_model, verbose)
            
            if trace is None:
                result['error'] = 'MCMC sampling failed'
                return result
            
            # 5. çµæœè™•ç†
            sampling_time = time.time() - start_time
            result['sampling_time_minutes'] = sampling_time / 60
            result['trace'] = trace
            
            # 6. åƒæ•¸ä¼°è¨ˆ
            parameter_estimates = self._extract_parameter_estimates(trace, verbose)
            result.update(parameter_estimates)
            
            # 7. æ”¶æ–‚è¨ºæ–·
            convergence_diagnostics = self._diagnose_convergence(trace, verbose)
            result['convergence_diagnostics'] = convergence_diagnostics
            result['converged'] = convergence_diagnostics['converged']
            
            # 8. æ¨¡å‹è©•ä¼°
            model_evaluation = self._evaluate_model_fit(trace, subject_data, verbose)
            result['model_evaluation'] = model_evaluation
            
            # 9. è§€å¯Ÿè³‡æ–™çµ±è¨ˆ
            result.update(self._extract_observed_statistics(subject_data))
            
            result['success'] = True
            
            if verbose:
                status = "âœ… æ”¶æ–‚" if result['converged'] else "âš ï¸ æ”¶æ–‚è­¦å‘Š"
                print(f"   {status} (è€—æ™‚ {sampling_time/60:.1f} åˆ†é˜)")
                print(f"   RÌ‚_max = {convergence_diagnostics['rhat_max']:.3f}")
                print(f"   ESS_min = {convergence_diagnostics['ess_bulk_min']:.0f}")
            
            return result
            
        except Exception as e:
            result['error'] = str(e)
            result['sampling_time_minutes'] = (time.time() - start_time) / 60
            
            if verbose:
                print(f"   âŒ æ“¬åˆå¤±æ•—: {e}")
            
            return result
    
    def _validate_subject_data(self, subject_data, verbose=True):
        """é©—è­‰å—è©¦è€…è³‡æ–™"""
        
        required_fields = [
            'subject_id', 'n_trials', 'choices', 'rt',
            'left_stimuli', 'left_choices', 'right_stimuli', 'right_choices'
        ]
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        for field in required_fields:
            if field not in subject_data:
                if verbose:
                    print(f"   âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
                return False
        
        # æª¢æŸ¥è³‡æ–™å……è¶³æ€§
        if subject_data['n_trials'] < 50:
            if verbose:
                print(f"   âŒ è³‡æ–™ä¸è¶³: {subject_data['n_trials']} < 50 trials")
            return False
        
        # æª¢æŸ¥è³‡æ–™é•·åº¦ä¸€è‡´æ€§
        n_trials = subject_data['n_trials']
        for field in ['choices', 'rt', 'left_stimuli', 'left_choices', 'right_stimuli', 'right_choices']:
            if len(subject_data[field]) != n_trials:
                if verbose:
                    print(f"   âŒ è³‡æ–™é•·åº¦ä¸ä¸€è‡´: {field}")
                return False
        
        # æª¢æŸ¥è³‡æ–™ç¯„åœ
        if not np.all(np.isin(subject_data['choices'], [0, 1, 2, 3])):
            if verbose:
                print("   âŒ é¸æ“‡è³‡æ–™ç¯„åœéŒ¯èª¤")
            return False
        
        if np.any(subject_data['rt'] <= 0):
            if verbose:
                print("   âŒ åæ‡‰æ™‚é–“åŒ…å«éæ­£å€¼")
            return False
        
        return True
    
    def _validate_model(self, pymc_model, verbose=True):
        """é©—è­‰PyMCæ¨¡å‹"""
        
        try:
            with pymc_model:
                test_point = pymc_model.initial_point()
                log_prob = pymc_model.compile_logp()(test_point)
                
                if not np.isfinite(log_prob):
                    if verbose:
                        print(f"   âŒ ç„¡æ•ˆçš„åˆå§‹å°æ•¸æ©Ÿç‡: {log_prob}")
                    return False
                
                if verbose:
                    print(f"   âœ… æ¨¡å‹é©—è­‰é€šé (log_prob = {log_prob:.2f})")
                
                return True
                
        except Exception as e:
            if verbose:
                print(f"   âŒ æ¨¡å‹é©—è­‰å¤±æ•—: {e}")
            return False
    
    def _run_mcmc_sampling(self, pymc_model, verbose=True):
        """åŸ·è¡ŒMCMCæ¡æ¨£"""
        
        try:
            with pymc_model:
                # MAPä¼°è¨ˆï¼ˆå¯é¸ï¼‰
                map_estimate = None
                try:
                    if verbose:
                        print("   ğŸ¯ MAPä¼°è¨ˆ...")
                    map_estimate = pm.find_MAP(method='BFGS', maxeval=800)
                    if verbose:
                        print("   âœ… MAPä¼°è¨ˆå®Œæˆ")
                except Exception as e:
                    if verbose:
                        print(f"   âš ï¸ MAPä¼°è¨ˆå¤±æ•—: {e}")
                
                # NUTSæ¡æ¨£
                trace = pm.sample(
                    draws=self.mcmc_config['draws'],
                    tune=self.mcmc_config['tune'],
                    chains=self.mcmc_config['chains'],
                    cores=self.mcmc_config['cores'],
                    target_accept=self.mcmc_config['target_accept'],
                    max_treedepth=self.mcmc_config['max_treedepth'],
                    init=self.mcmc_config['init'],
                    initvals=map_estimate,
                    random_seed=self.mcmc_config['random_seed'],
                    progressbar=self.mcmc_config['progressbar'] and verbose,
                    return_inferencedata=self.mcmc_config['return_inferencedata']
                )
                
                return trace
                
        except Exception as e:
            if verbose:
                print(f"   âŒ MCMCæ¡æ¨£å¤±æ•—: {e}")
            return None
    
    def _extract_parameter_estimates(self, trace, verbose=True):
        """æå–åƒæ•¸ä¼°è¨ˆ"""
        
        try:
            summary = az.summary(trace, round_to=4)
            
            posterior_means = {}
            posterior_stds = {}
            credible_intervals = {}
            
            for param_name in self.model.all_param_names:
                if param_name in summary.index:
                    posterior_means[param_name] = float(summary.loc[param_name, 'mean'])
                    posterior_stds[param_name] = float(summary.loc[param_name, 'sd'])
                    
                    # 95%å¯ä¿¡å€é–“
                    if 'hdi_2.5%' in summary.columns and 'hdi_97.5%' in summary.columns:
                        credible_intervals[param_name] = [
                            float(summary.loc[param_name, 'hdi_2.5%']),
                            float(summary.loc[param_name, 'hdi_97.5%'])
                        ]
                else:
                    posterior_means[param_name] = np.nan
                    posterior_stds[param_name] = np.nan
                    credible_intervals[param_name] = [np.nan, np.nan]
            
            if verbose:
                n_valid_params = sum(1 for v in posterior_means.values() if not np.isnan(v))
                print(f"   ğŸ“Š æå–åƒæ•¸: {n_valid_params}/{len(self.model.all_param_names)}")
            
            return {
                'posterior_means': posterior_means,
                'posterior_stds': posterior_stds,
                'credible_intervals': credible_intervals,
                'parameter_summary': summary
            }
            
        except Exception as e:
            if verbose:
                print(f"   âš ï¸ åƒæ•¸æå–å¤±æ•—: {e}")
            
            nan_dict = {name: np.nan for name in self.model.all_param_names}
            return {
                'posterior_means': nan_dict,
                'posterior_stds': nan_dict,
                'credible_intervals': {name: [np.nan, np.nan] for name in self.model.all_param_names},
                'parameter_summary': None
            }
    
    def _diagnose_convergence(self, trace, verbose=True):
        """å®Œæ•´çš„æ”¶æ–‚è¨ºæ–·"""
        
        if verbose:
            print("   ğŸ” æ”¶æ–‚è¨ºæ–·...")
        
        diagnostics = {
            'converged': False,
            'overall_status': 'failed',
            'rhat_max': np.nan,
            'rhat_mean': np.nan,
            'ess_bulk_min': np.nan,
            'ess_bulk_mean': np.nan,
            'ess_tail_min': np.nan,
            'ess_tail_mean': np.nan,
            'n_divergent': 0,
            'max_tree_depth': 0,
            'n_problematic_params': 0,
            'problematic_params': [],
            'warnings': [],
            'recommendations': []
        }
        
        try:
            summary = az.summary(trace, round_to=4)
            
            # RÌ‚ çµ±è¨ˆ
            if 'r_hat' in summary.columns:
                rhat_values = summary['r_hat'].dropna()
                if len(rhat_values) > 0:
                    diagnostics['rhat_max'] = float(rhat_values.max())
                    diagnostics['rhat_mean'] = float(rhat_values.mean())
            
            # ESS çµ±è¨ˆ
            if 'ess_bulk' in summary.columns:
                ess_bulk = summary['ess_bulk'].dropna()
                if len(ess_bulk) > 0:
                    diagnostics['ess_bulk_min'] = float(ess_bulk.min())
                    diagnostics['ess_bulk_mean'] = float(ess_bulk.mean())
            
            if 'ess_tail' in summary.columns:
                ess_tail = summary['ess_tail'].dropna()
                if len(ess_tail) > 0:
                    diagnostics['ess_tail_min'] = float(ess_tail.min())
                    diagnostics['ess_tail_mean'] = float(ess_tail.mean())
            
            # NUTSè¨ºæ–·
            try:
                if hasattr(trace, 'sample_stats'):
                    if 'diverging' in trace.sample_stats:
                        diagnostics['n_divergent'] = int(trace.sample_stats['diverging'].sum())
                    
                    if 'tree_depth' in trace.sample_stats:
                        diagnostics['max_tree_depth'] = int(trace.sample_stats['tree_depth'].max())
            except:
                pass
            
            # å•é¡Œåƒæ•¸è­˜åˆ¥
            problematic_params = []
            for param_name in summary.index:
                issues = []
                
                if 'r_hat' in summary.columns:
                    rhat = summary.loc[param_name, 'r_hat']
                    if not pd.isna(rhat) and rhat > self.convergence_thresholds['rhat_good']:
                        issues.append(f"RÌ‚={rhat:.3f}")
                
                if 'ess_bulk' in summary.columns:
                    ess = summary.loc[param_name, 'ess_bulk']
                    if not pd.isna(ess) and ess < self.convergence_thresholds['ess_minimum']:
                        issues.append(f"ESS={ess:.0f}")
                
                if issues:
                    problematic_params.append({
                        'parameter': param_name,
                        'issues': issues,
                        'rhat': float(summary.loc[param_name, 'r_hat']) if 'r_hat' in summary.columns else np.nan,
                        'ess_bulk': float(summary.loc[param_name, 'ess_bulk']) if 'ess_bulk' in summary.columns else np.nan
                    })
            
            diagnostics['problematic_params'] = problematic_params
            diagnostics['n_problematic_params'] = len(problematic_params)
            
            # æ•´é«”æ”¶æ–‚åˆ¤æ–·
            rhat_ok = diagnostics['rhat_max'] <= self.convergence_thresholds['rhat_good']
            ess_ok = (diagnostics['ess_bulk_min'] >= self.convergence_thresholds['ess_minimum'] and
                     diagnostics['ess_tail_min'] >= self.convergence_thresholds['ess_minimum'])
            no_divergence = diagnostics['n_divergent'] == 0
            
            if rhat_ok and ess_ok and no_divergence:
                diagnostics['converged'] = True
                diagnostics['overall_status'] = 'converged'
            elif diagnostics['rhat_max'] <= self.convergence_thresholds['rhat_acceptable']:
                diagnostics['overall_status'] = 'warning'
            else:
                diagnostics['overall_status'] = 'failed'
            
            # ç”Ÿæˆå»ºè­°
            if not diagnostics['converged']:
                if diagnostics['rhat_max'] > self.convergence_thresholds['rhat_good']:
                    diagnostics['recommendations'].append("å¢åŠ æ¡æ¨£æ•¸æˆ–éˆæ•¸")
                if diagnostics['ess_bulk_min'] < self.convergence_thresholds['ess_minimum']:
                    diagnostics['recommendations'].append("å¢åŠ drawsæ•¸é‡")
                if diagnostics['n_divergent'] > 0:
                    diagnostics['recommendations'].append("é™ä½target_acceptæˆ–å¢åŠ adapt_delta")
            
            if verbose:
                if diagnostics['converged']:
                    print(f"      âœ… æ”¶æ–‚è‰¯å¥½")
                else:
                    print(f"      âš ï¸ æ”¶æ–‚å•é¡Œ: {len(problematic_params)} å€‹åƒæ•¸")
            
            return diagnostics
            
        except Exception as e:
            if verbose:
                print(f"   âŒ æ”¶æ–‚è¨ºæ–·å¤±æ•—: {e}")
            diagnostics['error'] = str(e)
            return diagnostics
    
    def _evaluate_model_fit(self, trace, subject_data, verbose=True):
        """è©•ä¼°æ¨¡å‹æ“¬åˆå“è³ª"""
        
        evaluation = {
            'waic': np.nan,
            'waic_se': np.nan,
            'loo': np.nan,
            'loo_se': np.nan,
            'mean_ess': np.nan,
            'mean_rhat': np.nan
        }
        
        try:
            # WAIC
            try:
                waic_result = az.waic(trace)
                evaluation['waic'] = float(waic_result.waic)
                evaluation['waic_se'] = float(waic_result.se)
            except:
                pass
            
            # LOO
            try:
                loo_result = az.loo(trace)
                evaluation['loo'] = float(loo_result.loo)
                evaluation['loo_se'] = float(loo_result.se)
            except:
                pass
            
            # å¹³å‡çµ±è¨ˆ
            try:
                ess_stats = az.ess(trace)
                evaluation['mean_ess'] = float(ess_stats.to_array().mean())
                
                rhat_stats = az.rhat(trace)
                evaluation['mean_rhat'] = float(rhat_stats.to_array().mean())
            except:
                pass
            
            if verbose:
                print(f"   ğŸ“ˆ æ¨¡å‹è©•ä¼°å®Œæˆ")
                if not np.isnan(evaluation['waic']):
                    print(f"      WAIC = {evaluation['waic']:.1f}")
            
            return evaluation
            
        except Exception as e:
            if verbose:
                print(f"   âš ï¸ æ¨¡å‹è©•ä¼°å¤±æ•—: {e}")
            evaluation['error'] = str(e)
            return evaluation
    
    def _extract_observed_statistics(self, subject_data):
        """æå–è§€å¯Ÿè³‡æ–™çµ±è¨ˆ"""
        
        return {
            'observed_accuracy': subject_data['accuracy'],
            'observed_mean_rt': float(np.mean(subject_data['rt'])),
            'observed_std_rt': float(np.std(subject_data['rt'])),
            'observed_left_accuracy': subject_data.get('left_accuracy', np.nan),
            'observed_right_accuracy': subject_data.get('right_accuracy', np.nan)
        }
    
    def fit_multiple_subjects(self, subjects_data, max_subjects=None, 
                            continue_on_failure=True, verbose=True):
        """
        æ‰¹æ¬¡æ“¬åˆå¤šå€‹å—è©¦è€…
        
        Args:
            subjects_data: å—è©¦è€…è³‡æ–™åˆ—è¡¨
            max_subjects: æœ€å¤§å—è©¦è€…æ•¸é™åˆ¶
            continue_on_failure: æ˜¯å¦åœ¨å¤±æ•—æ™‚ç¹¼çºŒ
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°è¨Šæ¯
            
        Returns:
            list: æ‰€æœ‰å—è©¦è€…çš„æ“¬åˆçµæœ
        """
        
        if max_subjects:
            subjects_data = subjects_data[:max_subjects]
        
        n_subjects = len(subjects_data)
        
        if verbose:
            print(f"\nğŸ¯ æ‰¹æ¬¡æ“¬åˆé–‹å§‹")
            print(f"   å—è©¦è€…æ•¸: {n_subjects}")
            print(f"   æ¨¡å‹: {self.model.first_side} å…ˆè™•ç†")
            print(f"   MCMC: {self.mcmc_config['draws']} draws Ã— {self.mcmc_config['chains']} chains")
            print("="*60)
        
        results = []
        batch_start_time = time.time()
        successful_count = 0
        converged_count = 0
        
        for i, subject_data in enumerate(subjects_data, 1):
            if verbose:
                print(f"\nğŸ“ é€²åº¦: {i}/{n_subjects} ({i/n_subjects*100:.1f}%)")
            
            # æ“¬åˆå–®ä¸€å—è©¦è€…
            result = self.fit_subject(subject_data, verbose=verbose)
            results.append(result)
            
            # æ›´æ–°çµ±è¨ˆ
            if result['success']:
                successful_count += 1
                if result['converged']:
                    converged_count += 1
                
                if verbose:
                    status = "âœ… æ”¶æ–‚" if result['converged'] else "âš ï¸ è­¦å‘Š"
                    print(f"   {status} å—è©¦è€… {result['subject_id']}")
            else:
                if verbose:
                    print(f"   âŒ å¤±æ•— å—è©¦è€… {result['subject_id']}: {result['error']}")
                
                # æª¢æŸ¥æ˜¯å¦ç¹¼çºŒ
                if not continue_on_failure:
                    print("   ğŸ›‘ åœæ­¢æ‰¹æ¬¡è™•ç†")
                    break
            
            # æ—©æœŸå¤±æ•—æª¢æ¸¬
            if i >= 3:
                recent_failures = sum(1 for r in results[-3:] if not r['success'])
                if recent_failures >= 3:
                    if verbose:
                        print(f"\nâš ï¸ è­¦å‘Š: é€£çºŒ3å€‹å—è©¦è€…å¤±æ•—")
                        user_input = input("æ˜¯å¦ç¹¼çºŒ? (y/n): ")
                        if user_input.lower() != 'y':
                            print("æ‰¹æ¬¡è™•ç†çµ‚æ­¢")
                            break
        
        # æ‰¹æ¬¡æ‘˜è¦
        batch_time = time.time() - batch_start_time
        
        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ‰ æ‰¹æ¬¡æ“¬åˆå®Œæˆ")
            print(f"â±ï¸ ç¸½æ™‚é–“: {batch_time/60:.1f} åˆ†é˜")
            print(f"âœ… æˆåŠŸ: {successful_count}/{len(results)} ({successful_count/len(results)*100:.1f}%)")
            if successful_count > 0:
                print(f"ğŸ”„ æ”¶æ–‚: {converged_count}/{successful_count} ({converged_count/successful_count*100:.1f}%)")
                avg_time = np.mean([r['sampling_time_minutes'] for r in results if r['success']])
                print(f"â±ï¸ å¹³å‡æ™‚é–“: {avg_time:.1f} åˆ†é˜/å—è©¦è€…")
        
        return results
    
    def save_results(self, results, output_prefix="sequential_lba_results"):
        """
        å„²å­˜æ“¬åˆçµæœåˆ°å¤šå€‹æª”æ¡ˆ
        
        Args:
            results: æ“¬åˆçµæœåˆ—è¡¨
            output_prefix: è¼¸å‡ºæª”åå‰ç¶´
            
        Returns:
            dict: å„²å­˜çš„æª”æ¡ˆè·¯å¾‘å­—å…¸
        """
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_files = {}
        
        try:
            print(f"\nğŸ’¾ å„²å­˜çµæœ...")
            
            # 1. ä¸»è¦çµæœæª”æ¡ˆ
            main_data = []
            for result in results:
                main_row = {
                    'subject_id': result['subject_id'],
                    'success': result['success'],
                    'converged': result['converged'],
                    'error': result.get('error', ''),
                    'n_trials': result['n_trials'],
                    'sampling_time_minutes': result['sampling_time_minutes'],
                    'rhat_max': result.get('convergence_diagnostics', {}).get('rhat_max', np.nan),
                    'ess_bulk_min': result.get('convergence_diagnostics', {}).get('ess_bulk_min', np.nan),
                    'n_divergent': result.get('convergence_diagnostics', {}).get('n_divergent', 0),
                    'waic': result.get('model_evaluation', {}).get('waic', np.nan),
                    'observed_accuracy': result.get('observed_accuracy', np.nan),
                    'observed_mean_rt': result.get('observed_mean_rt', np.nan)
                }
                main_data.append(main_row)
            
            main_df = pd.DataFrame(main_data)
            main_filename = f"{output_prefix}_main_{timestamp}.csv"
            main_df.to_csv(main_filename, index=False, encoding='utf-8-sig')
            saved_files['main_results'] = main_filename
            
            # 2. åƒæ•¸ä¼°è¨ˆæª”æ¡ˆ
            successful_results = [r for r in results if r['success']]
            if successful_results:
                params_data = []
                for result in successful_results:
                    param_row = {'subject_id': result['subject_id']}
                    
                    # å¾Œé©—å‡å€¼
                    param_row.update(result.get('posterior_means', {}))
                    
                    # å¾Œé©—æ¨™æº–å·® (åŠ ä¸Š_stdå¾Œç¶´)
                    for param, std_val in result.get('posterior_stds', {}).items():
                        param_row[f"{param}_std"] = std_val
                    
                    params_data.append(param_row)
                
                params_df = pd.DataFrame(params_data)
                params_filename = f"{output_prefix}_parameters_{timestamp}.csv"
                params_df.to_csv(params_filename, index=False, encoding='utf-8-sig')
                saved_files['parameters'] = params_filename
                
                # 3. æ”¶æ–‚è¨ºæ–·æª”æ¡ˆ
                convergence_data = []
                for result in successful_results:
                    conv_diag = result.get('convergence_diagnostics', {})
                    conv_row = {
                        'subject_id': result['subject_id'],
                        'converged': conv_diag.get('converged', False),
                        'overall_status': conv_diag.get('overall_status', 'unknown'),
                        'rhat_max': conv_diag.get('rhat_max', np.nan),
                        'rhat_mean': conv_diag.get('rhat_mean', np.nan),
                        'ess_bulk_min': conv_diag.get('ess_bulk_min', np.nan),
                        'ess_bulk_mean': conv_diag.get('ess_bulk_mean', np.nan),
                        'ess_tail_min': conv_diag.get('ess_tail_min', np.nan),
                        'ess_tail_mean': conv_diag.get('ess_tail_mean', np.nan),
                        'n_divergent': conv_diag.get('n_divergent', 0),
                        'n_problematic_params': conv_diag.get('n_problematic_params', 0)
                    }
                    convergence_data.append(conv_row)
                
                conv_df = pd.DataFrame(convergence_data)
                conv_filename = f"{output_prefix}_convergence_{timestamp}.csv"
                conv_df.to_csv(conv_filename, index=False, encoding='utf-8-sig')
                saved_files['convergence'] = conv_filename
                
                # 4. æ¨¡å‹è©•ä¼°æª”æ¡ˆ
                evaluation_data = []
                for result in successful_results:
                    eval_data = result.get('model_evaluation', {})
                    eval_row = {
                        'subject_id': result['subject_id'],
                        'waic': eval_data.get('waic', np.nan),
                        'waic_se': eval_data.get('waic_se', np.nan),
                        'loo': eval_data.get('loo', np.nan),
                        'loo_se': eval_data.get('loo_se', np.nan),
                        'mean_ess': eval_data.get('mean_ess', np.nan),
                        'mean_rhat': eval_data.get('mean_rhat', np.nan)
                    }
                    # æ·»åŠ è§€å¯Ÿçµ±è¨ˆ
                    eval_row.update({
                        'observed_accuracy': result.get('observed_accuracy', np.nan),
                        'observed_mean_rt': result.get('observed_mean_rt', np.nan),
                        'observed_std_rt': result.get('observed_std_rt', np.nan),
                        'observed_left_accuracy': result.get('observed_left_accuracy', np.nan),
                        'observed_right_accuracy': result.get('observed_right_accuracy', np.nan)
                    })
                    evaluation_data.append(eval_row)
                
                eval_df = pd.DataFrame(evaluation_data)
                eval_filename = f"{output_prefix}_evaluation_{timestamp}.csv"
                eval_df.to_csv(eval_filename, index=False, encoding='utf-8-sig')
                saved_files['evaluation'] = eval_filename
            
            print(f"   âœ… çµæœå·²å„²å­˜:")
            for file_type, filename in saved_files.items():
                print(f"      {file_type}: {filename}")
            
            return saved_files
            
        except Exception as e:
            print(f"   âŒ å„²å­˜çµæœå¤±æ•—: {e}")
            return {}
    
    def get_batch_summary(self, results):
        """ç²å¾—æ‰¹æ¬¡çµæœæ‘˜è¦"""
        
        total_subjects = len(results)
        successful_results = [r for r in results if r['success']]
        converged_results = [r for r in successful_results if r['converged']]
        
        summary = {
            'total_subjects': total_subjects,
            'successful_subjects': len(successful_results),
            'converged_subjects': len(converged_results),
            'success_rate': len(successful_results) / total_subjects if total_subjects > 0 else 0,
            'convergence_rate': len(converged_results) / len(successful_results) if successful_results else 0
        }
        
        if successful_results:
            # æ™‚é–“çµ±è¨ˆ
            times = [r['sampling_time_minutes'] for r in successful_results]
            summary.update({
                'mean_sampling_time': np.mean(times),
                'total_sampling_time': np.sum(times)
            })
            
            # æ”¶æ–‚çµ±è¨ˆ
            if converged_results:
                rhat_values = [r['convergence_diagnostics']['rhat_max'] for r in converged_results]
                ess_values = [r['convergence_diagnostics']['ess_bulk_min'] for r in converged_results]
                
                summary.update({
                    'mean_rhat': np.mean(rhat_values),
                    'max_rhat': np.max(rhat_values),
                    'min_ess': np.min(ess_values),
                    'mean_ess': np.mean(ess_values)
                })
        
        return summary

# ä¾¿åˆ©å‡½æ•¸
def create_fitter(first_side='left', time_split_ratio=0.6, **mcmc_kwargs):
    """å¿«é€Ÿå‰µå»ºæ“¬åˆå™¨"""
    return SequentialModelFitter(first_side, time_split_ratio, mcmc_kwargs)

def quick_fit_test(subject_data, first_side='left'):
    """å¿«é€Ÿæ“¬åˆæ¸¬è©¦"""
    quick_config = {
        'draws': 100,
        'tune': 100,
        'chains': 1,
        'target_accept': 0.80,
        'progressbar': True
    }
    
    fitter = SequentialModelFitter(first_side, 0.6, quick_config)
    return fitter.fit_subject(subject_data)

def test_model_fitting():
    """æ¸¬è©¦æ¨¡å‹æ“¬åˆåŠŸèƒ½"""
    
    print("ğŸ§ª æ¸¬è©¦åºåˆ—LBAæ“¬åˆå™¨...")
    
    try:
        # å‰µå»ºæ¸¬è©¦è³‡æ–™
        n_trials = 100
        np.random.seed(42)
        
        test_data = {
            'subject_id': 999,
            'n_trials': n_trials,
            'accuracy': 0.75,
            'choices': np.random.choice([0, 1, 2, 3], size=n_trials),
            'rt': np.random.uniform(0.3, 1.5, size=n_trials),
            'left_stimuli': np.random.choice([0, 1], size=n_trials),
            'left_choices': np.random.choice([0, 1], size=n_trials),
            'right_stimuli': np.random.choice([0, 1], size=n_trials),
            'right_choices': np.random.choice([0, 1], size=n_trials),
            'left_accuracy': 0.8,
            'right_accuracy': 0.7
        }
        
        # æ¸¬è©¦å¿«é€Ÿæ“¬åˆ
        print("   åŸ·è¡Œå¿«é€Ÿæ“¬åˆæ¸¬è©¦...")
        result = quick_fit_test(test_data)
        
        if result['success']:
            print("   âœ… æ“¬åˆæˆåŠŸ!")
            print(f"   æ”¶æ–‚: {'æ˜¯' if result['converged'] else 'å¦'}")
            print(f"   åƒæ•¸æ•¸: {len([v for v in result['posterior_means'].values() if not np.isnan(v)])}")
            print(f"   æ™‚é–“: {result['sampling_time_minutes']:.1f} åˆ†é˜")
        else:
            print(f"   âŒ æ“¬åˆå¤±æ•—: {result['error']}")
        
        return result['success']
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    test_model_fitting()
