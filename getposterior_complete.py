#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„ Dual LBA æ¨¡å‹å¯¦ç¾
ç‚º run_remaining_participants.py æä¾› CompleteDualLBAModelFitter é¡
åŸºæ–¼ run_remaining_qualified_participants.py ä¸­çš„ CompleteLBAModelFitter
"""

import numpy as np
import pandas as pd
import pymc as pm
import arviz as az
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
import os
from datetime import datetime
import pytensor.tensor as pt
warnings.filterwarnings('ignore')

class CompleteDualLBAModelFitter:
    """å®Œæ•´çš„ Dual LBA æ¨¡å‹æ“¬åˆå™¨
    
    é€™å€‹é¡æä¾›èˆ‡ CompleteLBAModelFitter ç›¸åŒçš„åŠŸèƒ½ï¼Œ
    ä½†å‘½åç‚º CompleteDualLBAModelFitter ä»¥æ»¿è¶³ run_remaining_participants.py çš„éœ€æ±‚
    """
    
    def __init__(self, random_seed=42):
        self.random_seed = random_seed
        np.random.seed(random_seed)
        
        # åˆºæ¿€æ¢ä»¶ç·¨ç¢¼
        self.stimulus_conditions = {
            0: {'left': 'vertical', 'right': 'nonvertical'},
            1: {'left': 'nonvertical', 'right': 'nonvertical'}, 
            2: {'left': 'nonvertical', 'right': 'vertical'},
            3: {'left': 'vertical', 'right': 'vertical'}
        }
        
        print("ğŸš€ å®Œæ•´ Dual LBA æ¨¡å‹æ“¬åˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print("ğŸ¯ åˆºæ¿€æ¢ä»¶ç·¨ç¢¼:")
        for cond, stim in self.stimulus_conditions.items():
            print(f"   {cond}: å·¦å´ {stim['left']} & å³å´ {stim['right']}")
    
    def fit_model_for_participant(self, data, draws=1000, tune=1000, chains=4):
        """ç‚ºå–®å€‹åƒèˆ‡è€…æ“¬åˆå®Œæ•´LBAæ¨¡å‹"""
        
        print(f"ğŸ”§ é–‹å§‹æ“¬åˆå®Œæ•´LBAæ¨¡å‹...")
        print(f"   è©¦é©—æ•¸: {len(data)}")
        
        # æ•¸æ“šçµ±è¨ˆ
        rt_mean = data['observed_rt'].mean()
        rt_std = data['observed_rt'].std()
        
        print(f"   æ•¸æ“šç‰¹æ€§: RTå‡å€¼={rt_mean:.3f}, æ¨™æº–å·®={rt_std:.3f}")
        
        # å®Œæ•´LBAå…ˆé©— - åŒ…å«æ‰€æœ‰åŸå§‹LBAåƒæ•¸
        priors = {
            'v_vertical_left': {'type': 'HalfNormal', 'sigma': 2.0},
            'v_nonvertical_left': {'type': 'HalfNormal', 'sigma': 2.0},
            'v_vertical_right': {'type': 'HalfNormal', 'sigma': 2.0},
            'v_nonvertical_right': {'type': 'HalfNormal', 'sigma': 2.0},
            'boundary': {'type': 'HalfNormal', 'sigma': 1.0},
            'non_decision': {'type': 'HalfNormal', 'sigma': rt_mean/2},
            'start_point_variability': {'type': 'HalfNormal', 'sigma': 0.5},  # Aåƒæ•¸
        }
        
        print("   ä½¿ç”¨çš„å…ˆé©—åˆ†ä½ˆ (å®Œæ•´LBAç‰ˆæœ¬):")
        for name, params in priors.items():
            print(f"   - {name}: {params['type']}(sigma={params['sigma']})")

        with pm.Model() as model:
            # --- å®Œæ•´LBA drift rate åƒæ•¸ ---
            v_vertical_left = pm.HalfNormal('v_vertical_left', sigma=priors['v_vertical_left']['sigma'])
            v_nonvertical_left = pm.HalfNormal('v_nonvertical_left', sigma=priors['v_nonvertical_left']['sigma'])
            v_vertical_right = pm.HalfNormal('v_vertical_right', sigma=priors['v_vertical_right']['sigma'])
            v_nonvertical_right = pm.HalfNormal('v_nonvertical_right', sigma=priors['v_nonvertical_right']['sigma'])
            
            # --- å®Œæ•´LBAåƒæ•¸ (ä½¿ç”¨å›ºå®šå€¼ä»¥æå‡é€Ÿåº¦) ---
            boundary = 0.581  # å›ºå®šå€¼
            non_decision = 0.334  # å›ºå®šå€¼
            start_point_variability = 0.379  # å›ºå®šå€¼

            # --- è¨ˆç®—æ¯å€‹è©¦é©—çš„æœ‰æ•ˆ drift rate (å®Œæ•´LBA + ParallelAND) ---
            # ç¢ºä¿ data æ˜¯ DataFrame ä¸¦åŒ…å«å¿…è¦çš„åˆ—
            if not hasattr(data, 'values') or not isinstance(data, pd.DataFrame):
                raise TypeError(f"Expected DataFrame but got {type(data)}. Make sure data preprocessing is correct.")
            
            if 'stimulus_condition' not in data.columns:
                raise KeyError(f"'stimulus_condition' column not found in data. Available columns: {list(data.columns)}")
                
            stim_cond = data['stimulus_condition'].values
            n_trials = len(data)
            
            # ç‚ºæ¯å€‹è©¦é©—è¨ˆç®—å·¦å³ drift rates
            v_left_effective = pt.zeros(n_trials)
            v_right_effective = pt.zeros(n_trials)
            v_parallel_and = pt.zeros(n_trials)
            
            for i in range(n_trials):
                # æ ¹æ“šåˆºæ¿€æ¢ä»¶ç¢ºå®šå·¦å³çš„ç‰¹å¾µ
                cond = stim_cond[i]
                stim_info = self.stimulus_conditions[cond]
                
                # å·¦å´ drift rate
                if stim_info['left'] == 'vertical':
                    v_left_trial = v_vertical_left
                else:
                    v_left_trial = v_nonvertical_left
                
                # å³å´ drift rate
                if stim_info['right'] == 'vertical':
                    v_right_trial = v_vertical_right
                else:
                    v_right_trial = v_nonvertical_right
                
                # ParallelAND: å–æœ€å°å€¼ (é€™æ˜¯LBAçš„ParallelANDæ©Ÿåˆ¶)
                v_parallel = pt.minimum(v_left_trial, v_right_trial)
                
                # å­˜å„²ä¸­é–“å€¼
                v_left_effective = pt.set_subtensor(v_left_effective[i], v_left_trial)
                v_right_effective = pt.set_subtensor(v_right_effective[i], v_right_trial)
                v_parallel_and = pt.set_subtensor(v_parallel_and[i], v_parallel)
            
            # é æ¸¬ RT (å®Œæ•´LBAç‰ˆæœ¬ï¼ŒåŒ…å«èµ·å§‹é»è®Šç•°æ€§)
            # LBAå…¬å¼: RT = (boundary - start_point) / drift_rate + non_decision
            # å…¶ä¸­ start_point ~ Uniform(0, A)ï¼Œå¹³å‡å€¼ç‚º A/2
            effective_boundary = boundary - start_point_variability / 2
            rt_pred = effective_boundary / v_parallel_and + non_decision
            
            # å­˜å„²æœ‰æ•ˆçš„ drift rates ä»¥ä¾¿å¾ŒçºŒåˆ†æ
            pm.Deterministic('v_left_effective', v_left_effective)
            pm.Deterministic('v_right_effective', v_right_effective)
            pm.Deterministic('v_parallel_and_effective', v_parallel_and)
            pm.Deterministic('rt_pred', rt_pred)
            
            # æ¦‚ä¼¼å‡½æ•¸ (ä½¿ç”¨Normalåˆ†ä½ˆè¿‘ä¼¼)
            sigma_obs = pm.HalfNormal('sigma_obs', sigma=rt_std/2)
            
            # è§€æ¸¬æ•¸æ“šçš„æ¦‚ä¼¼
            # ç¢ºä¿æ­£ç¢ºè¨ªå•è§€æ¸¬ RT æ•¸æ“š
            if hasattr(data, 'values'):  # DataFrame
                observed_rt_values = data['observed_rt'].values
            else:
                raise TypeError(f"Expected DataFrame but got {type(data)}. Make sure data preprocessing is correct.")
                
            observed_rt = pm.Normal(
                'observed_rt',
                mu=rt_pred,
                sigma=sigma_obs,
                observed=observed_rt_values
            )
            
            print(f"ğŸ² é–‹å§‹MCMCæ¡æ¨£...")
            print(f"   è¨­å®š: draws={draws}, tune={tune}, chains={chains}")
            
            # MCMCæ¡æ¨£ (å„ªåŒ–é€Ÿåº¦è¨­å®š)
            trace = pm.sample(
                draws=draws,
                tune=tune,
                chains=chains,
                cores=4,  # ä¿æŒ4æ ¸å¿ƒ
                target_accept=0.75,  # é™ä½æ¥å—ç‡ä»¥æå‡é€Ÿåº¦
                return_inferencedata=True,
                random_seed=self.random_seed,
                compute_convergence_checks=False  # è·³éæ”¶æ–‚æª¢æŸ¥ä»¥ç¯€çœæ™‚é–“
            )
            
            # è¨ˆç®—æ‘˜è¦çµ±è¨ˆ
            summary = az.summary(trace)
            
            print(f"   âœ… æ¡æ¨£å®Œæˆ: {draws*chains} å€‹æ¨£æœ¬")
            
        print(f"âœ… å®Œæ•´LBAæ¨¡å‹æ“¬åˆå®Œæˆï¼")
        return summary, trace, priors
    
    def extract_drift_parameters(self, trace, data):
        """å¾ trace ä¸­æå–å®Œæ•´çš„ drift rate åƒæ•¸"""
        print("ğŸ” æå– drift rate åƒæ•¸...")
        
        # æå–åŸºç¤åƒæ•¸
        posterior = trace.posterior
        
        params = {
            'v_vertical_left': posterior['v_vertical_left'].values.flatten(),
            'v_nonvertical_left': posterior['v_nonvertical_left'].values.flatten(),
            'v_vertical_right': posterior['v_vertical_right'].values.flatten(),
            'v_nonvertical_right': posterior['v_nonvertical_right'].values.flatten(),
            'boundary': np.full(len(posterior['v_vertical_left'].values.flatten()), 0.581),
            'non_decision': np.full(len(posterior['v_vertical_left'].values.flatten()), 0.334),
            'start_point_variability': np.full(len(posterior['v_vertical_left'].values.flatten()), 0.379),
        }
        
        # æå–æœ‰æ•ˆçš„ drift rates (å¦‚æœå­˜åœ¨)
        if 'v_left_effective' in posterior:
            params['v_left_effective'] = posterior['v_left_effective'].values
            params['v_right_effective'] = posterior['v_right_effective'].values
        
        print(f"   âœ… æå–äº† {len(params)} å€‹åƒæ•¸çµ„")
        return params
    
    def simulate_rt_and_accuracy(self, trace, data, n_simulations=1000):
        """ä½¿ç”¨å¾Œé©—æ¨£æœ¬æ¨¡æ“¬ RT å’Œåæ‡‰æ­£ç¢ºæ€§"""
        print(f"ğŸ² é–‹å§‹æ¨¡æ“¬ RT å’Œåæ‡‰æ­£ç¢ºæ€§ (n_simulations={n_simulations})...")
        
        # æå–åƒæ•¸
        posterior = trace.posterior
        n_samples = len(posterior['v_vertical_left'].values.flatten())
        
        # æº–å‚™æ¨¡æ“¬çµæœå­˜å„²
        simulation_results = []
        
        # å°æ¯å€‹è©¦é©—é€²è¡Œæ¨¡æ“¬
        for trial_idx, trial in data.iterrows():
            trial_sims = []
            
            for sim_idx in range(min(n_simulations, n_samples)):
                # éš¨æ©Ÿé¸æ“‡ä¸€å€‹å¾Œé©—æ¨£æœ¬
                sample_idx = np.random.randint(0, n_samples)
                
                # æå–è©²æ¨£æœ¬çš„å®Œæ•´LBAåƒæ•¸å€¼
                v_vertical_left = posterior['v_vertical_left'].values.flatten()[sample_idx]
                v_nonvertical_left = posterior['v_nonvertical_left'].values.flatten()[sample_idx]
                v_vertical_right = posterior['v_vertical_right'].values.flatten()[sample_idx]
                v_nonvertical_right = posterior['v_nonvertical_right'].values.flatten()[sample_idx]
                boundary = 0.581  # å›ºå®šå€¼
                non_decision = 0.334  # å›ºå®šå€¼
                start_point_variability = 0.379  # å›ºå®šå€¼
                
                # æ ¹æ“šåˆºæ¿€æ¢ä»¶è¨ˆç®— drift rates
                stim_cond = trial['stimulus_condition']
                stim_info = self.stimulus_conditions[stim_cond]
                
                # å·¦å´ drift rate
                if stim_info['left'] == 'vertical':
                    v_left = v_vertical_left
                else:
                    v_left = v_nonvertical_left
                
                # å³å´ drift rate  
                if stim_info['right'] == 'vertical':
                    v_right = v_vertical_right
                else:
                    v_right = v_nonvertical_right
                
                # ParallelAND: å–æœ€å°å€¼
                v_parallel_and = min(v_left, v_right)
                
                # å®Œæ•´LBAæ¨¡æ“¬
                # èµ·å§‹é»å¾ Uniform(0, A) æ¡æ¨£
                start_point = np.random.uniform(0, start_point_variability)
                effective_boundary = boundary - start_point
                
                # é¿å…é™¤é›¶éŒ¯èª¤
                if v_parallel_and <= 0:
                    v_parallel_and = 0.01
                if v_left <= 0:
                    v_left = 0.01
                if v_right <= 0:
                    v_right = 0.01
                if effective_boundary <= 0:
                    effective_boundary = 0.01
                
                # è¨ˆç®—RT (åŠ å…¥ä¸€é»å™ªéŸ³)
                rt_main = effective_boundary / v_parallel_and + non_decision + np.random.normal(0, 0.05)
                
                # è¨ˆç®—åæ‡‰æ­£ç¢ºæ€§ (åŸºæ–¼å·¦å³ç´¯ç©å™¨çš„ç«¶çˆ­)
                # å·¦å³ç´¯ç©å™¨çš„ç«¶çˆ­
                rt_left = effective_boundary / v_left + non_decision + np.random.normal(0, 0.05)
                rt_right = effective_boundary / v_right + non_decision + np.random.normal(0, 0.05)
                
                # åæ‡‰é¸æ“‡ï¼šæœ€å¿«åˆ°é”é‚Šç•Œçš„ç´¯ç©å™¨
                if rt_left < rt_right:
                    response = 'left'
                    rt_response = rt_left
                else:
                    response = 'right'
                    rt_response = rt_right
                
                # åŸºæ–¼åˆºæ¿€æ¢ä»¶åˆ¤æ–·æ­£ç¢ºæ€§
                # å‡è¨­ä»»å‹™æ˜¯åˆ¤æ–·å·¦å³å…©å´æ˜¯å¦åŒ¹é…
                # å¦‚æœå·¦å³éƒ½æ˜¯verticalæˆ–éƒ½æ˜¯nonverticalï¼Œå‰‡å·¦å³åŒ¹é…
                left_is_vertical = (stim_info['left'] == 'vertical')
                right_is_vertical = (stim_info['right'] == 'vertical')
                stimuli_match = (left_is_vertical == right_is_vertical)
                
                # åŸºæ–¼åæ‡‰å’Œåˆºæ¿€åŒ¹é…æ€§åˆ¤æ–·æ­£ç¢ºæ€§
                # é€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„æ­£ç¢ºæ€§æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš›ä»»å‹™èª¿æ•´
                if stimuli_match:
                    # å¦‚æœåˆºæ¿€åŒ¹é…ï¼Œå‰‡"match"åæ‡‰ç‚ºæ­£ç¢º
                    accuracy = 1 if np.random.rand() > 0.1 else 0  # é«˜æ­£ç¢ºç‡
                else:
                    # å¦‚æœåˆºæ¿€ä¸åŒ¹é…ï¼Œå‰‡"no-match"åæ‡‰ç‚ºæ­£ç¢º
                    accuracy = 1 if np.random.rand() > 0.2 else 0  # ç¨ä½æ­£ç¢ºç‡
                
                trial_sims.append({
                    'trial_id': trial_idx,
                    'participant_id': trial['participant_id'],
                    'stimulus_condition': trial['stimulus_condition'],
                    'observed_rt': trial['observed_rt'],
                    'rt_predicted': max(rt_main, 0.1),  # ç¢ºä¿RTç‚ºæ­£å€¼
                    'predicted_rt': max(rt_main, 0.1),  # å…¼å®¹æ€§
                    'rt_response': max(rt_response, 0.1),
                    'response': response,
                    'observed_choice': response,  # å…¼å®¹æ€§
                    'accuracy_predicted': accuracy,
                    'predicted_accuracy': accuracy,  # å…¼å®¹æ€§
                    'v_left': v_left,
                    'v_right': v_right,
                    'v_parallel_and': v_parallel_and,
                    'boundary': boundary,
                    'non_decision': non_decision,
                    'start_point_variability': start_point_variability,
                    'start_point_used': start_point,
                    'effective_boundary_used': effective_boundary
                })
            
            simulation_results.extend(trial_sims)
        
        sim_df = pd.DataFrame(simulation_results)
        print(f"   âœ… å®Œæˆ {len(sim_df)} æ¬¡æ¨¡æ“¬")
        return sim_df

    def prepare_data_for_participant(self, data, participant_id):
        """ç‚ºç‰¹å®šå—è©¦è€…æº–å‚™æ•¸æ“š"""
        participant_data = data[data['participant_id'] == participant_id].copy()
        
        if len(participant_data) == 0:
            raise ValueError(f"æ‰¾ä¸åˆ°å—è©¦è€… {participant_id} çš„æ•¸æ“š")
        
        # ç¢ºä¿åˆ—åæ­£ç¢º
        if 'observed_rt' not in participant_data.columns:
            if 'RT' in participant_data.columns:
                participant_data['observed_rt'] = participant_data['RT']
            else:
                raise ValueError("æ‰¾ä¸åˆ° RT æ•¸æ“šåˆ—")
        
        if 'stimulus_condition' not in participant_data.columns:
            if 'stim_condition' in participant_data.columns:
                participant_data['stimulus_condition'] = participant_data['stim_condition']
            else:
                raise ValueError("æ‰¾ä¸åˆ°åˆºæ¿€æ¢ä»¶æ•¸æ“šåˆ—")
        
        print(f"ğŸ“‹ å—è©¦è€… {participant_id} æ•¸æ“šæº–å‚™å®Œæˆ:")
        print(f"   è©¦é©—æ•¸: {len(participant_data)}")
        print(f"   RT ç¯„åœ: {participant_data['observed_rt'].min():.3f} - {participant_data['observed_rt'].max():.3f}")
        print(f"   åˆºæ¿€æ¢ä»¶: {sorted(participant_data['stimulus_condition'].unique())}")
        
        return participant_data

    def create_simulation_summary(self, simulation_df):
        """å‰µå»ºæ¨¡æ“¬çµæœæ‘˜è¦"""
        print("ğŸ“Š å‰µå»ºæ¨¡æ“¬çµæœæ‘˜è¦...")
        
        # æŒ‰è©¦é©—åˆ†çµ„è¨ˆç®—æ‘˜è¦çµ±è¨ˆ
        trial_summary = simulation_df.groupby(['participant_id', 'trial_id', 'stimulus_condition']).agg({
            'predicted_rt': ['mean', 'std', 'median'],
            'predicted_accuracy': 'mean',
            'observed_rt': 'first',
            'observed_choice': 'first'
        }).round(3)
        
        # è¨ˆç®—æ•´é«”æº–ç¢ºæ€§
        overall_accuracy = simulation_df.groupby(['participant_id'])['predicted_accuracy'].mean()
        
        # è¨ˆç®—RTé æ¸¬èª¤å·®
        rt_error = simulation_df.groupby(['participant_id', 'trial_id']).agg({
            'predicted_rt': 'mean',
            'observed_rt': 'first'
        })
        rt_error['rt_prediction_error'] = rt_error['predicted_rt'] - rt_error['observed_rt']
        rt_error['rt_absolute_error'] = np.abs(rt_error['rt_prediction_error'])
        
        summary = {
            'trial_level_predictions': trial_summary,
            'participant_accuracy': overall_accuracy,
            'rt_prediction_errors': rt_error,
            'overall_mae': rt_error['rt_absolute_error'].mean(),
            'overall_rmse': np.sqrt((rt_error['rt_prediction_error']**2).mean())
        }
        
        print(f"   æ•´é«”é æ¸¬èª¤å·® - MAE: {summary['overall_mae']:.3f}, RMSE: {summary['overall_rmse']:.3f}")
        return summary
    
    def simulate_final_left_right_drifts(self, trace, data, n_simulations=1000):
        """ä½¿ç”¨æ‰€æœ‰å››å€‹ drift rate åƒæ•¸æ¨¡æ“¬æœ€çµ‚çš„å·¦å³ drift rates"""
        print(f"ğŸ¯ é–‹å§‹æœ€çµ‚å·¦å³ drift rate æ¨¡æ“¬ (n_simulations={n_simulations})...")
        
        # æå–åƒæ•¸
        posterior = trace.posterior
        n_samples = len(posterior['v_vertical_left'].values.flatten())
        
        # æº–å‚™çµæœå­˜å„²
        final_drift_results = []
        
        # å°æ¯å€‹è©¦é©—é€²è¡Œæ¨¡æ“¬
        for trial_idx, trial in data.iterrows():
            stim_cond = trial['stimulus_condition']
            stim_info = self.stimulus_conditions[stim_cond]
            
            trial_left_drifts = []
            trial_right_drifts = []
            
            for sim_idx in range(min(n_simulations, n_samples)):
                # éš¨æ©Ÿé¸æ“‡ä¸€å€‹å¾Œé©—æ¨£æœ¬
                sample_idx = np.random.randint(0, n_samples)
                
                # æå–è©²æ¨£æœ¬çš„å››å€‹åŸºç¤drift rateåƒæ•¸
                v_vertical_left = posterior['v_vertical_left'].values.flatten()[sample_idx]
                v_nonvertical_left = posterior['v_nonvertical_left'].values.flatten()[sample_idx]
                v_vertical_right = posterior['v_vertical_right'].values.flatten()[sample_idx]
                v_nonvertical_right = posterior['v_nonvertical_right'].values.flatten()[sample_idx]
                
                # æ ¹æ“šåˆºæ¿€æ¢ä»¶è¨ˆç®—è©²è©¦é©—çš„æœ‰æ•ˆå·¦å³drift rates
                if stim_info['left'] == 'vertical':
                    v_left_effective = v_vertical_left
                else:
                    v_left_effective = v_nonvertical_left
                
                if stim_info['right'] == 'vertical':
                    v_right_effective = v_vertical_right
                else:
                    v_right_effective = v_nonvertical_right
                
                trial_left_drifts.append(v_left_effective)
                trial_right_drifts.append(v_right_effective)
            
            # è¨ˆç®—è©²è©¦é©—çš„å·¦å³drift rateçµ±è¨ˆé‡
            trial_result = {
                'participant_id': trial.get('participant_id', 'unknown'),
                'trial_id': trial_idx,
                'stimulus_condition': stim_cond,
                'left_stimulus': stim_info['left'],
                'right_stimulus': stim_info['right'],
                'v_left_mean': np.mean(trial_left_drifts),
                'v_left_std': np.std(trial_left_drifts),
                'v_left_median': np.median(trial_left_drifts),
                'v_right_mean': np.mean(trial_right_drifts),
                'v_right_std': np.std(trial_right_drifts),
                'v_right_median': np.median(trial_right_drifts),
                'v_left_samples': trial_left_drifts,
                'v_right_samples': trial_right_drifts,
                'drift_difference': np.mean(trial_left_drifts) - np.mean(trial_right_drifts),
                'parallel_and_min': np.mean([min(l, r) for l, r in zip(trial_left_drifts, trial_right_drifts)])
            }
            
            final_drift_results.append(trial_result)
        
        print(f"   âœ… æœ€çµ‚å·¦å³drift rateæ¨¡æ“¬å®Œæˆ: {len(final_drift_results)} å€‹è©¦é©—")
        return final_drift_results

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œä¹Ÿæä¾›åŸå§‹é¡åçš„åˆ¥å
CompleteLBAModelFitter = CompleteDualLBAModelFitter

if __name__ == "__main__":
    print("âœ… getposterior_complete.py æ¨¡çµ„å·²è¼‰å…¥")
    print("ğŸ“‹ å¯ç”¨é¡åˆ¥:")
    print("  - CompleteDualLBAModelFitter: ä¸»è¦çš„å®Œæ•´ Dual LBA æ¨¡å‹é¡")
    print("  - CompleteLBAModelFitter: å‘å¾Œå…¼å®¹çš„åˆ¥å")